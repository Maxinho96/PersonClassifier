{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-26 11:04:33.092504: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-04-26 11:04:33.116468: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200070000 Hz\n",
      "2020-04-26 11:04:33.116848: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dc684150e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-26 11:04:33.116875: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-26 11:04:33.116985: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "output\n",
      "Train for 462 steps, validate for 151 steps\n",
      "Epoch 1/1000\n",
      "2020-04-26 11:04:55.717546: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Filling up shuffle buffer (this may take a while): 780 of 1000\n",
      "2020-04-26 11:04:58.401275: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:199] Shuffle buffer filled.\n",
      "2020-04-26 11:04:59.190838: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "462/462 [==============================] - 229s 495ms/step - loss: 2.3830 - accuracy: 0.2200 - categorical_crossentropy: 2.3830 - val_loss: 3.1479 - val_accuracy: 0.1167 - val_categorical_crossentropy: 3.1479\n",
      "Epoch 2/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 2.0775 - accuracy: 0.3398 - categorical_crossentropy: 2.07752020-04-26 11:11:06.821893: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 202s 436ms/step - loss: 2.0769 - accuracy: 0.3398 - categorical_crossentropy: 2.0769 - val_loss: 3.5188 - val_accuracy: 0.1217 - val_categorical_crossentropy: 3.5187\n",
      "Epoch 3/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 2.0000 - accuracy: 0.3628 - categorical_crossentropy: 2.00002020-04-26 11:15:23.439204: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 267s 577ms/step - loss: 1.9999 - accuracy: 0.3628 - categorical_crossentropy: 1.9999 - val_loss: 3.9268 - val_accuracy: 0.1151 - val_categorical_crossentropy: 3.9268\n",
      "Epoch 4/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.9276 - accuracy: 0.3888 - categorical_crossentropy: 1.92762020-04-26 11:19:58.350647: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 281s 609ms/step - loss: 1.9271 - accuracy: 0.3893 - categorical_crossentropy: 1.9271 - val_loss: 3.7123 - val_accuracy: 0.1291 - val_categorical_crossentropy: 3.7123\n",
      "Epoch 5/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.8632 - accuracy: 0.4159 - categorical_crossentropy: 1.86322020-04-26 11:24:05.681569: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 265s 573ms/step - loss: 1.8633 - accuracy: 0.4159 - categorical_crossentropy: 1.8633 - val_loss: 4.0487 - val_accuracy: 0.1349 - val_categorical_crossentropy: 4.0487\n",
      "Epoch 6/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.8151 - accuracy: 0.4219 - categorical_crossentropy: 1.81512020-04-26 11:28:21.738088: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 255s 553ms/step - loss: 1.8143 - accuracy: 0.4221 - categorical_crossentropy: 1.8143 - val_loss: 3.8435 - val_accuracy: 0.1531 - val_categorical_crossentropy: 3.8435\n",
      "Epoch 7/1000\n",
      "277/462 [================>.............] - ETA: 1:04 - loss: 1.8149 - accuracy: 0.4224 - categorical_crossentropy: 1.81492020-04-26 11:31:17.758180: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Filling up shuffle buffer (this may take a while): 723 of 1000\n",
      "279/462 [=================>............] - ETA: 1:03 - loss: 1.8181 - accuracy: 0.4211 - categorical_crossentropy: 1.81812020-04-26 11:31:21.476413: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:199] Shuffle buffer filled.\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.8134 - accuracy: 0.4176 - categorical_crossentropy: 1.81342020-04-26 11:32:23.268377: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 253s 547ms/step - loss: 1.8126 - accuracy: 0.4183 - categorical_crossentropy: 1.8126 - val_loss: 4.0689 - val_accuracy: 0.1399 - val_categorical_crossentropy: 4.0689\n",
      "Epoch 8/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.8203 - accuracy: 0.4281 - categorical_crossentropy: 1.82032020-04-26 11:35:55.922659: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 227s 492ms/step - loss: 1.8197 - accuracy: 0.4286 - categorical_crossentropy: 1.8197 - val_loss: 4.0997 - val_accuracy: 0.1374 - val_categorical_crossentropy: 4.0997\n",
      "Epoch 9/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.7748 - accuracy: 0.4300 - categorical_crossentropy: 1.77482020-04-26 11:39:46.477812: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 206s 446ms/step - loss: 1.7761 - accuracy: 0.4294 - categorical_crossentropy: 1.7761 - val_loss: 4.4751 - val_accuracy: 0.1316 - val_categorical_crossentropy: 4.4750\n",
      "Epoch 10/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.7651 - accuracy: 0.4403 - categorical_crossentropy: 1.76512020-04-26 11:43:09.172111: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 210s 453ms/step - loss: 1.7635 - accuracy: 0.4407 - categorical_crossentropy: 1.7635 - val_loss: 4.3000 - val_accuracy: 0.1507 - val_categorical_crossentropy: 4.3000\n",
      "Epoch 11/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.7390 - accuracy: 0.4509 - categorical_crossentropy: 1.73902020-04-26 11:46:41.055464: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 212s 459ms/step - loss: 1.7384 - accuracy: 0.4513 - categorical_crossentropy: 1.7384 - val_loss: 4.9477 - val_accuracy: 0.1093 - val_categorical_crossentropy: 4.9477\n",
      "Epoch 12/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.7164 - accuracy: 0.4612 - categorical_crossentropy: 1.71642020-04-26 11:50:18.686204: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 234s 506ms/step - loss: 1.7150 - accuracy: 0.4621 - categorical_crossentropy: 1.7150 - val_loss: 4.9578 - val_accuracy: 0.1142 - val_categorical_crossentropy: 4.9578\n",
      "Epoch 13/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.7068 - accuracy: 0.4447 - categorical_crossentropy: 1.70682020-04-26 11:54:24.720371: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 193s 417ms/step - loss: 1.7072 - accuracy: 0.4445 - categorical_crossentropy: 1.7072 - val_loss: 4.9328 - val_accuracy: 0.1233 - val_categorical_crossentropy: 4.9328\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61/462 [==>...........................] - ETA: 1:57 - loss: 1.6623 - accuracy: 0.4506 - categorical_crossentropy: 1.66232020-04-26 11:55:33.829630: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 462000 batches). You may need to use the repeat() function when building your dataset.\n",
      "W0426 11:55:33.919927 140155385075520 training_v2.py:152] Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 462000 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "W0426 11:55:33.922087 140155385075520 callbacks.py:1018] Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,categorical_crossentropy\n",
      "W0426 11:55:33.922249 140155385075520 callbacks.py:1286] Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,categorical_crossentropy\n",
      " 61/462 [==>...........................] - ETA: 1:57 - loss: 1.6623 - accuracy: 0.4506 - categorical_crossentropy: 1.66232020-04-26 11:55:33.931038: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    }
   ],
   "source": [
    "# Questo è stato fatto con il dataset non ridotto e senza unfreeze batchnorm.\n",
    "!python train.py \\\n",
    "--exp=1 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000 \\\n",
    "--cache_train=False \\\n",
    "--cache_val=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-30 17:12:55.919619: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-04-30 17:12:55.943301: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199790000 Hz\n",
      "2020-04-30 17:12:55.943618: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56215cdd5960 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-30 17:12:55.943710: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-30 17:12:55.943821: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 20s 0us/step\n",
      "Trainable layers:\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-04-30 17:13:22.697321: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 74s 400ms/step - loss: 2.6009 - accuracy: 0.1216 - categorical_crossentropy: 2.6009 - val_loss: 2.5426 - val_accuracy: 0.1648 - val_categorical_crossentropy: 2.5426\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.4489 - accuracy: 0.2042 - categorical_crossentropy: 2.44892020-04-30 17:15:41.215463: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 74s 404ms/step - loss: 2.4501 - accuracy: 0.2031 - categorical_crossentropy: 2.4501 - val_loss: 2.8778 - val_accuracy: 0.0966 - val_categorical_crossentropy: 2.8778\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.3378 - accuracy: 0.2486 - categorical_crossentropy: 2.33782020-04-30 17:16:49.068167: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 66s 361ms/step - loss: 2.3372 - accuracy: 0.2486 - categorical_crossentropy: 2.3372 - val_loss: 2.5825 - val_accuracy: 0.1420 - val_categorical_crossentropy: 2.5825\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.2787 - accuracy: 0.2589 - categorical_crossentropy: 2.27872020-04-30 17:17:57.010727: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 68s 369ms/step - loss: 2.2799 - accuracy: 0.2582 - categorical_crossentropy: 2.2799 - val_loss: 2.7533 - val_accuracy: 0.1193 - val_categorical_crossentropy: 2.7533\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.2384 - accuracy: 0.2835 - categorical_crossentropy: 2.23842020-04-30 17:19:02.070510: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 66s 358ms/step - loss: 2.2390 - accuracy: 0.2826 - categorical_crossentropy: 2.2390 - val_loss: 2.7745 - val_accuracy: 0.1023 - val_categorical_crossentropy: 2.7745\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.1835 - accuracy: 0.2964 - categorical_crossentropy: 2.18352020-04-30 17:20:08.343369: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 65s 355ms/step - loss: 2.1844 - accuracy: 0.2962 - categorical_crossentropy: 2.1844 - val_loss: 3.0780 - val_accuracy: 0.1477 - val_categorical_crossentropy: 3.0780\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.1795 - accuracy: 0.3142 - categorical_crossentropy: 2.17952020-04-30 17:21:19.597059: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 71s 387ms/step - loss: 2.1798 - accuracy: 0.3139 - categorical_crossentropy: 2.1798 - val_loss: 2.7941 - val_accuracy: 0.1534 - val_categorical_crossentropy: 2.7941\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.1387 - accuracy: 0.3176 - categorical_crossentropy: 2.13872020-04-30 17:22:31.624813: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 73s 395ms/step - loss: 2.1378 - accuracy: 0.3173 - categorical_crossentropy: 2.1378 - val_loss: 2.9973 - val_accuracy: 0.1818 - val_categorical_crossentropy: 2.9973\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.1185 - accuracy: 0.3279 - categorical_crossentropy: 2.11852020-04-30 17:23:40.768251: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 69s 376ms/step - loss: 2.1179 - accuracy: 0.3281 - categorical_crossentropy: 2.1179 - val_loss: 3.0585 - val_accuracy: 0.1250 - val_categorical_crossentropy: 3.0585\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0876 - accuracy: 0.3265 - categorical_crossentropy: 2.08762020-04-30 17:24:54.998647: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 75s 410ms/step - loss: 2.0889 - accuracy: 0.3268 - categorical_crossentropy: 2.0889 - val_loss: 3.0201 - val_accuracy: 0.1648 - val_categorical_crossentropy: 3.0201\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0665 - accuracy: 0.3586 - categorical_crossentropy: 2.06652020-04-30 17:26:05.494488: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 69s 375ms/step - loss: 2.0680 - accuracy: 0.3587 - categorical_crossentropy: 2.0680 - val_loss: 3.0780 - val_accuracy: 0.1875 - val_categorical_crossentropy: 3.0780\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0463 - accuracy: 0.3374 - categorical_crossentropy: 2.04632020-04-30 17:27:09.791169: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 65s 353ms/step - loss: 2.0492 - accuracy: 0.3356 - categorical_crossentropy: 2.0492 - val_loss: 3.1986 - val_accuracy: 0.1364 - val_categorical_crossentropy: 3.1986\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0777 - accuracy: 0.3559 - categorical_crossentropy: 2.07772020-04-30 17:28:22.318019: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 72s 390ms/step - loss: 2.0795 - accuracy: 0.3546 - categorical_crossentropy: 2.0795 - val_loss: 3.3237 - val_accuracy: 0.1591 - val_categorical_crossentropy: 3.3237\n",
      "Epoch 14/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0790 - accuracy: 0.3354 - categorical_crossentropy: 2.07902020-04-30 17:29:31.230192: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 69s 377ms/step - loss: 2.0781 - accuracy: 0.3342 - categorical_crossentropy: 2.0781 - val_loss: 3.5350 - val_accuracy: 0.1705 - val_categorical_crossentropy: 3.5350\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 2.0073 - accuracy: 0.3490 - categorical_crossentropy: 2.00732020-04-30 17:30:39.608007: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 68s 370ms/step - loss: 2.0078 - accuracy: 0.3478 - categorical_crossentropy: 2.0078 - val_loss: 3.4281 - val_accuracy: 0.1477 - val_categorical_crossentropy: 3.4281\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0495 - accuracy: 0.3286 - categorical_crossentropy: 2.04952020-04-30 17:31:58.863827: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 80s 433ms/step - loss: 2.0501 - accuracy: 0.3295 - categorical_crossentropy: 2.0501 - val_loss: 3.3558 - val_accuracy: 0.1534 - val_categorical_crossentropy: 3.3558\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0342 - accuracy: 0.3449 - categorical_crossentropy: 2.03422020-04-30 17:33:08.128903: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 69s 375ms/step - loss: 2.0342 - accuracy: 0.3465 - categorical_crossentropy: 2.0342 - val_loss: 3.5189 - val_accuracy: 0.1989 - val_categorical_crossentropy: 3.5189\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0348 - accuracy: 0.3531 - categorical_crossentropy: 2.03482020-04-30 17:34:19.599680: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 72s 393ms/step - loss: 2.0356 - accuracy: 0.3526 - categorical_crossentropy: 2.0356 - val_loss: 3.3492 - val_accuracy: 0.1534 - val_categorical_crossentropy: 3.3492\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0292 - accuracy: 0.3531 - categorical_crossentropy: 2.02922020-04-30 17:35:37.504461: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 78s 425ms/step - loss: 2.0294 - accuracy: 0.3533 - categorical_crossentropy: 2.0294 - val_loss: 3.4180 - val_accuracy: 0.1193 - val_categorical_crossentropy: 3.4180\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9816 - accuracy: 0.3627 - categorical_crossentropy: 1.98162020-04-30 17:36:48.463800: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 70s 380ms/step - loss: 1.9824 - accuracy: 0.3621 - categorical_crossentropy: 1.9824 - val_loss: 3.5652 - val_accuracy: 0.1534 - val_categorical_crossentropy: 3.5652\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0027 - accuracy: 0.3579 - categorical_crossentropy: 2.00272020-04-30 17:37:58.687324: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 70s 381ms/step - loss: 2.0063 - accuracy: 0.3580 - categorical_crossentropy: 2.0063 - val_loss: 3.3032 - val_accuracy: 0.1136 - val_categorical_crossentropy: 3.3032\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9475 - accuracy: 0.3600 - categorical_crossentropy: 1.94752020-04-30 17:39:13.166056: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 75s 410ms/step - loss: 1.9455 - accuracy: 0.3614 - categorical_crossentropy: 1.9455 - val_loss: 3.4284 - val_accuracy: 0.1761 - val_categorical_crossentropy: 3.4284\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9685 - accuracy: 0.3784 - categorical_crossentropy: 1.96852020-04-30 17:40:29.515543: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 75s 410ms/step - loss: 1.9695 - accuracy: 0.3777 - categorical_crossentropy: 1.9695 - val_loss: 3.2337 - val_accuracy: 0.1591 - val_categorical_crossentropy: 3.2337\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9483 - accuracy: 0.3818 - categorical_crossentropy: 1.94832020-04-30 17:41:50.484602: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 440ms/step - loss: 1.9486 - accuracy: 0.3818 - categorical_crossentropy: 1.9486 - val_loss: 3.2158 - val_accuracy: 0.1364 - val_categorical_crossentropy: 3.2158\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9367 - accuracy: 0.3832 - categorical_crossentropy: 1.93672020-04-30 17:43:01.258256: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 72s 389ms/step - loss: 1.9353 - accuracy: 0.3838 - categorical_crossentropy: 1.9353 - val_loss: 3.7523 - val_accuracy: 0.1193 - val_categorical_crossentropy: 3.7523\n",
      "Epoch 26/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9674 - accuracy: 0.3818 - categorical_crossentropy: 1.96742020-04-30 17:44:06.189509: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 64s 345ms/step - loss: 1.9681 - accuracy: 0.3811 - categorical_crossentropy: 1.9681 - val_loss: 3.5906 - val_accuracy: 0.1364 - val_categorical_crossentropy: 3.5906\n",
      "Epoch 27/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9601 - accuracy: 0.3695 - categorical_crossentropy: 1.96012020-04-30 17:45:17.490270: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 71s 387ms/step - loss: 1.9603 - accuracy: 0.3689 - categorical_crossentropy: 1.9603 - val_loss: 3.5907 - val_accuracy: 0.1193 - val_categorical_crossentropy: 3.5907\n",
      "2020-04-30 17:45:22.143800: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-04-30 17:45:22.144378: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-04-30 17:45:22.620494: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.627610: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.630805: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.634008: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.637161: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.641573: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.645077: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.648902: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.651696: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.655181: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-30 17:45:22.667451: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.671498: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.675588: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.678767: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.682643: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.686120: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.691553: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.694854: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.698483: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.702469: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.705980: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.711033: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.713781: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.716925: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.720307: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.724778: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.728404: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Da qua in poi ho usato il dataset ridotto e ho fatto varie prove (senza unfreeze batchnorm).\n",
    "!python train.py \\\n",
    "--exp=2 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-30 17:46:39.025656: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-04-30 17:46:39.059332: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199790000 Hz\n",
      "2020-04-30 17:46:39.059979: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bd8176f2a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-30 17:46:39.060006: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-30 17:46:39.060419: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-04-30 17:46:44.344331: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 79s 427ms/step - loss: 2.4896 - accuracy: 0.1753 - categorical_crossentropy: 2.4896 - val_loss: 2.6497 - val_accuracy: 0.1307 - val_categorical_crossentropy: 2.6497\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.2807 - accuracy: 0.2910 - categorical_crossentropy: 2.28072020-04-30 17:48:56.089284: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 61s 331ms/step - loss: 2.2802 - accuracy: 0.2901 - categorical_crossentropy: 2.2802 - val_loss: 2.6362 - val_accuracy: 0.1477 - val_categorical_crossentropy: 2.6362\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.1164 - accuracy: 0.3579 - categorical_crossentropy: 2.11642020-04-30 17:50:01.593665: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 65s 356ms/step - loss: 2.1176 - accuracy: 0.3567 - categorical_crossentropy: 2.1176 - val_loss: 2.6546 - val_accuracy: 0.1818 - val_categorical_crossentropy: 2.6546\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9908 - accuracy: 0.3811 - categorical_crossentropy: 1.99082020-04-30 17:51:11.292488: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 70s 379ms/step - loss: 1.9903 - accuracy: 0.3818 - categorical_crossentropy: 1.9903 - val_loss: 2.7017 - val_accuracy: 0.1648 - val_categorical_crossentropy: 2.7017\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9852 - accuracy: 0.3805 - categorical_crossentropy: 1.98522020-04-30 17:52:14.415875: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 63s 343ms/step - loss: 1.9858 - accuracy: 0.3791 - categorical_crossentropy: 1.9858 - val_loss: 3.0216 - val_accuracy: 0.1136 - val_categorical_crossentropy: 3.0216\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9550 - accuracy: 0.3934 - categorical_crossentropy: 1.95502020-04-30 17:53:17.754936: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 64s 346ms/step - loss: 1.9541 - accuracy: 0.3933 - categorical_crossentropy: 1.9541 - val_loss: 2.8129 - val_accuracy: 0.1932 - val_categorical_crossentropy: 2.8129\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8683 - accuracy: 0.4153 - categorical_crossentropy: 1.86832020-04-30 17:54:21.156355: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 63s 341ms/step - loss: 1.8679 - accuracy: 0.4151 - categorical_crossentropy: 1.8679 - val_loss: 3.1456 - val_accuracy: 0.1534 - val_categorical_crossentropy: 3.1456\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8354 - accuracy: 0.4385 - categorical_crossentropy: 1.83542020-04-30 17:55:27.325411: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 66s 360ms/step - loss: 1.8343 - accuracy: 0.4395 - categorical_crossentropy: 1.8343 - val_loss: 3.5741 - val_accuracy: 0.1080 - val_categorical_crossentropy: 3.5741\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8168 - accuracy: 0.4317 - categorical_crossentropy: 1.81682020-04-30 17:56:33.689064: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 67s 366ms/step - loss: 1.8141 - accuracy: 0.4321 - categorical_crossentropy: 1.8141 - val_loss: 3.1131 - val_accuracy: 0.1534 - val_categorical_crossentropy: 3.1131\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8175 - accuracy: 0.4385 - categorical_crossentropy: 1.81752020-04-30 17:57:47.675547: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 73s 396ms/step - loss: 1.8201 - accuracy: 0.4368 - categorical_crossentropy: 1.8201 - val_loss: 3.0564 - val_accuracy: 0.1364 - val_categorical_crossentropy: 3.0564\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7857 - accuracy: 0.4351 - categorical_crossentropy: 1.78572020-04-30 17:58:49.586565: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 62s 339ms/step - loss: 1.7893 - accuracy: 0.4341 - categorical_crossentropy: 1.7893 - val_loss: 3.4810 - val_accuracy: 0.1193 - val_categorical_crossentropy: 3.4810\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8074 - accuracy: 0.4358 - categorical_crossentropy: 1.80742020-04-30 17:59:50.900858: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 62s 335ms/step - loss: 1.8051 - accuracy: 0.4368 - categorical_crossentropy: 1.8051 - val_loss: 3.6933 - val_accuracy: 0.1307 - val_categorical_crossentropy: 3.6933\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7609 - accuracy: 0.4426 - categorical_crossentropy: 1.76092020-04-30 18:00:58.048298: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 67s 362ms/step - loss: 1.7594 - accuracy: 0.4416 - categorical_crossentropy: 1.7594 - val_loss: 3.3446 - val_accuracy: 0.1591 - val_categorical_crossentropy: 3.3446\n",
      "Epoch 14/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7370 - accuracy: 0.4563 - categorical_crossentropy: 1.73702020-04-30 18:02:07.667605: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 70s 380ms/step - loss: 1.7380 - accuracy: 0.4565 - categorical_crossentropy: 1.7380 - val_loss: 3.4829 - val_accuracy: 0.1477 - val_categorical_crossentropy: 3.4829\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7323 - accuracy: 0.4624 - categorical_crossentropy: 1.73232020-04-30 18:03:15.411343: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 373ms/step - loss: 1.7321 - accuracy: 0.4620 - categorical_crossentropy: 1.7321 - val_loss: 3.4060 - val_accuracy: 0.1705 - val_categorical_crossentropy: 3.4060\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6594 - accuracy: 0.4945 - categorical_crossentropy: 1.65942020-04-30 18:04:29.557191: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 73s 397ms/step - loss: 1.6572 - accuracy: 0.4946 - categorical_crossentropy: 1.6572 - val_loss: 3.3573 - val_accuracy: 0.1818 - val_categorical_crossentropy: 3.3573\n",
      "2020-04-30 18:04:34.742594: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-04-30 18:04:34.743033: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-04-30 18:04:35.226489: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.229506: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.232697: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.235354: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.239444: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.242707: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.245924: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.250596: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.253885: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.256963: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.266669: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.269660: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.273012: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.278988: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.282035: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.284478: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Ho provato senza data augmentation ma è aumentato l'overfitting.\n",
    "!python train.py \\\n",
    "--exp=3 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000 \\\n",
    "--random_flip=False \\\n",
    "--random_hue=False \\\n",
    "--random_saturation=False \\\n",
    "--random_contrast=False \\\n",
    "--random_brightness=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-30 18:05:32.735607: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-04-30 18:05:32.763279: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199790000 Hz\n",
      "2020-04-30 18:05:32.763549: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55abbecdd5e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-30 18:05:32.763568: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-30 18:05:32.763657: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-04-30 18:05:39.619454: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 314s 2s/step - loss: 2.5929 - accuracy: 0.1304 - categorical_crossentropy: 2.5929 - val_loss: 2.6309 - val_accuracy: 0.0909 - val_categorical_crossentropy: 2.6309\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 2.3910 - accuracy: 0.2172 - categorical_crossentropy: 2.39102020-04-30 18:15:46.720185: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 323s 2s/step - loss: 2.3907 - accuracy: 0.2167 - categorical_crossentropy: 2.3907 - val_loss: 2.5762 - val_accuracy: 0.1250 - val_categorical_crossentropy: 2.5762\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 2.3231 - accuracy: 0.2575 - categorical_crossentropy: 2.32312020-04-30 18:21:16.457872: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 330s 2s/step - loss: 2.3222 - accuracy: 0.2588 - categorical_crossentropy: 2.3222 - val_loss: 2.6798 - val_accuracy: 0.1250 - val_categorical_crossentropy: 2.6798\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 2.1705 - accuracy: 0.3142 - categorical_crossentropy: 2.17052020-04-30 18:27:00.793447: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 345s 2s/step - loss: 2.1709 - accuracy: 0.3132 - categorical_crossentropy: 2.1709 - val_loss: 2.5897 - val_accuracy: 0.1250 - val_categorical_crossentropy: 2.5897\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 2.1176 - accuracy: 0.3210 - categorical_crossentropy: 2.11762020-04-30 18:32:38.643825: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 337s 2s/step - loss: 2.1151 - accuracy: 0.3220 - categorical_crossentropy: 2.1151 - val_loss: 2.6782 - val_accuracy: 0.1761 - val_categorical_crossentropy: 2.6782\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 2.1108 - accuracy: 0.3169 - categorical_crossentropy: 2.11082020-04-30 18:37:51.719886: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 313s 2s/step - loss: 2.1115 - accuracy: 0.3173 - categorical_crossentropy: 2.1115 - val_loss: 2.8802 - val_accuracy: 0.1705 - val_categorical_crossentropy: 2.8802\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 2.0068 - accuracy: 0.3422 - categorical_crossentropy: 2.00682020-04-30 18:43:03.700728: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 312s 2s/step - loss: 2.0063 - accuracy: 0.3424 - categorical_crossentropy: 2.0063 - val_loss: 2.9601 - val_accuracy: 0.1080 - val_categorical_crossentropy: 2.9601\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 2.0127 - accuracy: 0.3436 - categorical_crossentropy: 2.01272020-04-30 18:50:17.602785: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 451s 2s/step - loss: 2.0143 - accuracy: 0.3431 - categorical_crossentropy: 2.0143 - val_loss: 2.5472 - val_accuracy: 0.1875 - val_categorical_crossentropy: 2.5472\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 1.9882 - accuracy: 0.3572 - categorical_crossentropy: 1.98822020-04-30 18:57:18.838402: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 405s 2s/step - loss: 1.9861 - accuracy: 0.3580 - categorical_crossentropy: 1.9861 - val_loss: 2.5476 - val_accuracy: 0.1591 - val_categorical_crossentropy: 2.5476\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.9354 - accuracy: 0.3866 - categorical_crossentropy: 1.93542020-04-30 19:02:33.351863: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 314s 2s/step - loss: 1.9342 - accuracy: 0.3872 - categorical_crossentropy: 1.9342 - val_loss: 2.8218 - val_accuracy: 0.1477 - val_categorical_crossentropy: 2.8218\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.9124 - accuracy: 0.4044 - categorical_crossentropy: 1.91242020-04-30 19:08:05.589390: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 333s 2s/step - loss: 1.9159 - accuracy: 0.4035 - categorical_crossentropy: 1.9159 - val_loss: 2.8382 - val_accuracy: 0.1534 - val_categorical_crossentropy: 2.8382\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.8635 - accuracy: 0.3982 - categorical_crossentropy: 1.86352020-04-30 19:13:34.778990: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 328s 2s/step - loss: 1.8650 - accuracy: 0.3974 - categorical_crossentropy: 1.8650 - val_loss: 2.6259 - val_accuracy: 0.1875 - val_categorical_crossentropy: 2.6259\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.9027 - accuracy: 0.3969 - categorical_crossentropy: 1.90272020-04-30 19:19:06.116092: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 331s 2s/step - loss: 1.9010 - accuracy: 0.3981 - categorical_crossentropy: 1.9010 - val_loss: 2.9251 - val_accuracy: 0.0909 - val_categorical_crossentropy: 2.9251\n",
      "Epoch 14/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.8591 - accuracy: 0.4119 - categorical_crossentropy: 1.85912020-04-30 19:24:23.667518: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 318s 2s/step - loss: 1.8596 - accuracy: 0.4124 - categorical_crossentropy: 1.8596 - val_loss: 2.9293 - val_accuracy: 0.1477 - val_categorical_crossentropy: 2.9293\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.8619 - accuracy: 0.3866 - categorical_crossentropy: 1.86192020-04-30 19:29:51.833638: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 328s 2s/step - loss: 1.8625 - accuracy: 0.3859 - categorical_crossentropy: 1.8625 - val_loss: 3.0461 - val_accuracy: 0.1477 - val_categorical_crossentropy: 3.0461\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.8613 - accuracy: 0.3989 - categorical_crossentropy: 1.86132020-04-30 19:35:09.757514: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 318s 2s/step - loss: 1.8582 - accuracy: 0.4001 - categorical_crossentropy: 1.8582 - val_loss: 2.8132 - val_accuracy: 0.1761 - val_categorical_crossentropy: 2.8132\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.8040 - accuracy: 0.4173 - categorical_crossentropy: 1.80402020-04-30 19:40:27.598433: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 318s 2s/step - loss: 1.8038 - accuracy: 0.4171 - categorical_crossentropy: 1.8038 - val_loss: 3.0858 - val_accuracy: 0.1989 - val_categorical_crossentropy: 3.0858\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.8795 - accuracy: 0.3996 - categorical_crossentropy: 1.87952020-04-30 19:45:47.212426: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 320s 2s/step - loss: 1.8828 - accuracy: 0.3981 - categorical_crossentropy: 1.8828 - val_loss: 3.0339 - val_accuracy: 0.1307 - val_categorical_crossentropy: 3.0339\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7751 - accuracy: 0.4153 - categorical_crossentropy: 1.77512020-04-30 19:51:02.843661: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 316s 2s/step - loss: 1.7728 - accuracy: 0.4164 - categorical_crossentropy: 1.7728 - val_loss: 2.5727 - val_accuracy: 0.1705 - val_categorical_crossentropy: 2.5727\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7567 - accuracy: 0.4399 - categorical_crossentropy: 1.75672020-04-30 19:56:20.714727: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 318s 2s/step - loss: 1.7574 - accuracy: 0.4395 - categorical_crossentropy: 1.7574 - val_loss: 2.8315 - val_accuracy: 0.1989 - val_categorical_crossentropy: 2.8315\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7615 - accuracy: 0.4344 - categorical_crossentropy: 1.76152020-04-30 20:01:43.744358: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 323s 2s/step - loss: 1.7580 - accuracy: 0.4355 - categorical_crossentropy: 1.7580 - val_loss: 2.7219 - val_accuracy: 0.1932 - val_categorical_crossentropy: 2.7219\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7325 - accuracy: 0.4358 - categorical_crossentropy: 1.73252020-04-30 20:07:34.328994: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 357s 2s/step - loss: 1.7326 - accuracy: 0.4361 - categorical_crossentropy: 1.7326 - val_loss: 2.9582 - val_accuracy: 0.1648 - val_categorical_crossentropy: 2.9582\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7273 - accuracy: 0.4481 - categorical_crossentropy: 1.72732020-04-30 20:13:54.552468: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 375s 2s/step - loss: 1.7271 - accuracy: 0.4484 - categorical_crossentropy: 1.7271 - val_loss: 2.9245 - val_accuracy: 0.1534 - val_categorical_crossentropy: 2.9245\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7035 - accuracy: 0.4495 - categorical_crossentropy: 1.70352020-04-30 20:19:24.765419: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 330s 2s/step - loss: 1.7021 - accuracy: 0.4490 - categorical_crossentropy: 1.7021 - val_loss: 2.9019 - val_accuracy: 0.1250 - val_categorical_crossentropy: 2.9019\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7483 - accuracy: 0.4337 - categorical_crossentropy: 1.74832020-04-30 20:24:53.749308: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 331s 2s/step - loss: 1.7488 - accuracy: 0.4334 - categorical_crossentropy: 1.7488 - val_loss: 3.2691 - val_accuracy: 0.1705 - val_categorical_crossentropy: 3.2691\n",
      "Epoch 26/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.6943 - accuracy: 0.4529 - categorical_crossentropy: 1.69432020-04-30 20:30:20.750015: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 325s 2s/step - loss: 1.6935 - accuracy: 0.4524 - categorical_crossentropy: 1.6935 - val_loss: 3.0405 - val_accuracy: 0.1534 - val_categorical_crossentropy: 3.0405\n",
      "Epoch 27/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7050 - accuracy: 0.4447 - categorical_crossentropy: 1.70502020-04-30 20:35:44.454940: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 323s 2s/step - loss: 1.7040 - accuracy: 0.4443 - categorical_crossentropy: 1.7040 - val_loss: 2.9027 - val_accuracy: 0.1932 - val_categorical_crossentropy: 2.9027\n",
      "2020-04-30 20:36:10.544809: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-04-30 20:36:10.545400: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-04-30 20:36:11.021052: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.023876: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.026673: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.029283: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.031909: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.035619: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.039572: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.042844: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.045312: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.047839: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.056312: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-30 20:36:11.059210: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.063000: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.065407: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.068289: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.071327: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.073598: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.076025: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.078619: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.082507: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.084740: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.088910: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.091574: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.094050: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.096373: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.098927: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.101166: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n"
     ]
    }
   ],
   "source": [
    "# Proviamo con la dimensione fissa, risultati leggermente migliori.\n",
    "!python train.py \\\n",
    "--exp=4 \\\n",
    "--size=299 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-01 09:40:55.845672: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-01 09:40:55.868843: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200090000 Hz\n",
      "2020-05-01 09:40:55.869184: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aa45e79800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-01 09:40:55.869210: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-01 09:40:55.869325: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block14_sepconv2\n",
      "block14_sepconv2_bn\n",
      "block14_sepconv2_act\n",
      "global_average_pooling2d\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-01 09:41:01.714499: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 89s 486ms/step - loss: 2.3899 - accuracy: 0.2527 - categorical_crossentropy: 2.3899 - val_loss: 5.9552 - val_accuracy: 0.1080 - val_categorical_crossentropy: 5.9552\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9675 - accuracy: 0.3456 - categorical_crossentropy: 1.96752020-05-01 09:43:42.634552: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 439ms/step - loss: 1.9669 - accuracy: 0.3451 - categorical_crossentropy: 1.9669 - val_loss: 5.6519 - val_accuracy: 0.1193 - val_categorical_crossentropy: 5.6519\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8374 - accuracy: 0.3921 - categorical_crossentropy: 1.83742020-05-01 09:45:01.920685: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 78s 426ms/step - loss: 1.8369 - accuracy: 0.3927 - categorical_crossentropy: 1.8369 - val_loss: 6.2486 - val_accuracy: 0.1307 - val_categorical_crossentropy: 6.2486\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7658 - accuracy: 0.4187 - categorical_crossentropy: 1.76582020-05-01 09:46:21.080975: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 79s 430ms/step - loss: 1.7709 - accuracy: 0.4171 - categorical_crossentropy: 1.7709 - val_loss: 6.9091 - val_accuracy: 0.1307 - val_categorical_crossentropy: 6.9091\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6972 - accuracy: 0.4283 - categorical_crossentropy: 1.69722020-05-01 09:47:41.932559: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 438ms/step - loss: 1.6964 - accuracy: 0.4287 - categorical_crossentropy: 1.6964 - val_loss: 6.5268 - val_accuracy: 0.1136 - val_categorical_crossentropy: 6.5268\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6489 - accuracy: 0.4686 - categorical_crossentropy: 1.64892020-05-01 09:48:57.867740: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 77s 418ms/step - loss: 1.6543 - accuracy: 0.4660 - categorical_crossentropy: 1.6543 - val_loss: 5.1818 - val_accuracy: 0.1705 - val_categorical_crossentropy: 5.1818\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6391 - accuracy: 0.4447 - categorical_crossentropy: 1.63912020-05-01 09:50:19.654959: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 441ms/step - loss: 1.6376 - accuracy: 0.4463 - categorical_crossentropy: 1.6376 - val_loss: 7.9445 - val_accuracy: 0.0795 - val_categorical_crossentropy: 7.9445\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6062 - accuracy: 0.4652 - categorical_crossentropy: 1.60622020-05-01 09:51:41.886301: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 82s 446ms/step - loss: 1.6083 - accuracy: 0.4647 - categorical_crossentropy: 1.6083 - val_loss: 5.9199 - val_accuracy: 0.0909 - val_categorical_crossentropy: 5.9199\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6006 - accuracy: 0.4802 - categorical_crossentropy: 1.60062020-05-01 09:53:02.705517: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 442ms/step - loss: 1.6018 - accuracy: 0.4789 - categorical_crossentropy: 1.6018 - val_loss: 6.1704 - val_accuracy: 0.0795 - val_categorical_crossentropy: 6.1704\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.5049 - accuracy: 0.4939 - categorical_crossentropy: 1.50492020-05-01 09:54:21.062640: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 78s 421ms/step - loss: 1.5034 - accuracy: 0.4939 - categorical_crossentropy: 1.5034 - val_loss: 5.0346 - val_accuracy: 0.1307 - val_categorical_crossentropy: 5.0346\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4672 - accuracy: 0.5102 - categorical_crossentropy: 1.46722020-05-01 09:55:37.473085: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 77s 416ms/step - loss: 1.4644 - accuracy: 0.5115 - categorical_crossentropy: 1.4644 - val_loss: 6.0157 - val_accuracy: 0.1193 - val_categorical_crossentropy: 6.0157\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4756 - accuracy: 0.5007 - categorical_crossentropy: 1.47562020-05-01 09:56:59.928051: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 83s 449ms/step - loss: 1.4729 - accuracy: 0.5014 - categorical_crossentropy: 1.4729 - val_loss: 5.4723 - val_accuracy: 0.1136 - val_categorical_crossentropy: 5.4723\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4656 - accuracy: 0.5171 - categorical_crossentropy: 1.46562020-05-01 09:58:20.922158: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 442ms/step - loss: 1.4638 - accuracy: 0.5170 - categorical_crossentropy: 1.4638 - val_loss: 6.4379 - val_accuracy: 0.1023 - val_categorical_crossentropy: 6.4379\n",
      "Epoch 14/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4295 - accuracy: 0.5000 - categorical_crossentropy: 1.42952020-05-01 09:59:42.120597: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 441ms/step - loss: 1.4323 - accuracy: 0.4993 - categorical_crossentropy: 1.4323 - val_loss: 5.4126 - val_accuracy: 0.1420 - val_categorical_crossentropy: 5.4126\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4153 - accuracy: 0.5307 - categorical_crossentropy: 1.41532020-05-01 10:01:04.008815: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 82s 446ms/step - loss: 1.4175 - accuracy: 0.5306 - categorical_crossentropy: 1.4175 - val_loss: 5.5739 - val_accuracy: 0.1420 - val_categorical_crossentropy: 5.5739\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4171 - accuracy: 0.5273 - categorical_crossentropy: 1.41712020-05-01 10:02:22.169058: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 78s 424ms/step - loss: 1.4177 - accuracy: 0.5272 - categorical_crossentropy: 1.4177 - val_loss: 4.6474 - val_accuracy: 0.1591 - val_categorical_crossentropy: 4.6474\n",
      "2020-05-01 10:02:27.463093: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-01 10:02:27.464706: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-01 10:02:27.934164: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.939460: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.943298: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.947268: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.951664: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.957556: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.960898: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.966737: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.970240: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.973755: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.989045: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.996031: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.999865: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:28.003623: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:28.007078: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:28.011288: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Proviamo a riaddestrare anche il penultimo layer. Sul training migliora ma sul validation no.\n",
    "!python train.py \\\n",
    "--exp=5 \\\n",
    "--weights=\"checkpoints/exp2/best_weights.ckpt\" \\\n",
    "--trainable_layers=5 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-01 10:07:48.857835: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-01 10:07:48.884725: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200090000 Hz\n",
      "2020-05-01 10:07:48.885024: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5619d6905800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-01 10:07:48.885050: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-01 10:07:48.885173: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block14_sepconv1\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv1_act\n",
      "block14_sepconv2\n",
      "block14_sepconv2_bn\n",
      "block14_sepconv2_act\n",
      "global_average_pooling2d\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-01 10:07:55.353607: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 87s 475ms/step - loss: 2.2046 - accuracy: 0.2887 - categorical_crossentropy: 2.2046 - val_loss: 8.1723 - val_accuracy: 0.1477 - val_categorical_crossentropy: 8.1723\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8012 - accuracy: 0.4290 - categorical_crossentropy: 1.80122020-05-01 10:10:42.591390: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 480ms/step - loss: 1.8022 - accuracy: 0.4287 - categorical_crossentropy: 1.8022 - val_loss: 6.1380 - val_accuracy: 0.1193 - val_categorical_crossentropy: 6.1380\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6019 - accuracy: 0.4556 - categorical_crossentropy: 1.60192020-05-01 10:12:09.686654: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 477ms/step - loss: 1.6011 - accuracy: 0.4558 - categorical_crossentropy: 1.6011 - val_loss: 6.0240 - val_accuracy: 0.1080 - val_categorical_crossentropy: 6.0240\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4405 - accuracy: 0.5157 - categorical_crossentropy: 1.44052020-05-01 10:13:45.807175: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 523ms/step - loss: 1.4400 - accuracy: 0.5163 - categorical_crossentropy: 1.4400 - val_loss: 5.5125 - val_accuracy: 0.1080 - val_categorical_crossentropy: 5.5125\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.3596 - accuracy: 0.5512 - categorical_crossentropy: 1.35962020-05-01 10:15:15.069539: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 483ms/step - loss: 1.3598 - accuracy: 0.5496 - categorical_crossentropy: 1.3598 - val_loss: 6.6608 - val_accuracy: 0.1420 - val_categorical_crossentropy: 6.6608\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.2422 - accuracy: 0.5786 - categorical_crossentropy: 1.24222020-05-01 10:16:40.419611: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 86s 467ms/step - loss: 1.2402 - accuracy: 0.5802 - categorical_crossentropy: 1.2402 - val_loss: 4.0777 - val_accuracy: 0.1648 - val_categorical_crossentropy: 4.0777\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.2565 - accuracy: 0.5786 - categorical_crossentropy: 1.25652020-05-01 10:18:09.274596: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 481ms/step - loss: 1.2619 - accuracy: 0.5781 - categorical_crossentropy: 1.2619 - val_loss: 4.8929 - val_accuracy: 0.1193 - val_categorical_crossentropy: 4.8929\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.1292 - accuracy: 0.6189 - categorical_crossentropy: 1.12922020-05-01 10:19:48.637833: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 101s 549ms/step - loss: 1.1297 - accuracy: 0.6182 - categorical_crossentropy: 1.1297 - val_loss: 6.2386 - val_accuracy: 0.0739 - val_categorical_crossentropy: 6.2386\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0524 - accuracy: 0.6667 - categorical_crossentropy: 1.05242020-05-01 10:21:34.796527: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 104s 567ms/step - loss: 1.0514 - accuracy: 0.6671 - categorical_crossentropy: 1.0514 - val_loss: 7.3997 - val_accuracy: 0.0966 - val_categorical_crossentropy: 7.3997\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0808 - accuracy: 0.6387 - categorical_crossentropy: 1.08082020-05-01 10:23:58.779772: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 151s 819ms/step - loss: 1.0806 - accuracy: 0.6379 - categorical_crossentropy: 1.0806 - val_loss: 7.1974 - val_accuracy: 0.1193 - val_categorical_crossentropy: 7.1974\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0198 - accuracy: 0.6537 - categorical_crossentropy: 1.01982020-05-01 10:25:44.034713: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 99s 535ms/step - loss: 1.0217 - accuracy: 0.6529 - categorical_crossentropy: 1.0217 - val_loss: 3.9079 - val_accuracy: 0.1591 - val_categorical_crossentropy: 3.9079\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9843 - accuracy: 0.6708 - categorical_crossentropy: 0.98432020-05-01 10:27:13.256279: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 484ms/step - loss: 0.9825 - accuracy: 0.6705 - categorical_crossentropy: 0.9825 - val_loss: 4.1246 - val_accuracy: 0.1534 - val_categorical_crossentropy: 4.1246\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9626 - accuracy: 0.6660 - categorical_crossentropy: 0.96262020-05-01 10:28:41.528178: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 483ms/step - loss: 0.9612 - accuracy: 0.6664 - categorical_crossentropy: 0.9612 - val_loss: 3.8742 - val_accuracy: 0.1989 - val_categorical_crossentropy: 3.8742\n",
      "Epoch 14/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9422 - accuracy: 0.6796 - categorical_crossentropy: 0.94222020-05-01 10:30:05.327114: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 84s 456ms/step - loss: 0.9401 - accuracy: 0.6807 - categorical_crossentropy: 0.9401 - val_loss: 4.9692 - val_accuracy: 0.0966 - val_categorical_crossentropy: 4.9692\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9408 - accuracy: 0.6755 - categorical_crossentropy: 0.94082020-05-01 10:31:33.036824: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 478ms/step - loss: 0.9437 - accuracy: 0.6732 - categorical_crossentropy: 0.9437 - val_loss: 3.9914 - val_accuracy: 0.2330 - val_categorical_crossentropy: 3.9914\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8920 - accuracy: 0.6967 - categorical_crossentropy: 0.89202020-05-01 10:33:01.827921: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 481ms/step - loss: 0.8926 - accuracy: 0.6963 - categorical_crossentropy: 0.8926 - val_loss: 4.6255 - val_accuracy: 0.1705 - val_categorical_crossentropy: 4.6255\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8600 - accuracy: 0.7111 - categorical_crossentropy: 0.86002020-05-01 10:34:26.395430: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 84s 458ms/step - loss: 0.8594 - accuracy: 0.7113 - categorical_crossentropy: 0.8594 - val_loss: 4.7223 - val_accuracy: 0.1193 - val_categorical_crossentropy: 4.7223\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8433 - accuracy: 0.7206 - categorical_crossentropy: 0.84332020-05-01 10:35:49.654354: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 83s 450ms/step - loss: 0.8450 - accuracy: 0.7194 - categorical_crossentropy: 0.8450 - val_loss: 4.4745 - val_accuracy: 0.1477 - val_categorical_crossentropy: 4.4745\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8650 - accuracy: 0.7124 - categorical_crossentropy: 0.86502020-05-01 10:37:18.151319: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 481ms/step - loss: 0.8611 - accuracy: 0.7140 - categorical_crossentropy: 0.8611 - val_loss: 4.2204 - val_accuracy: 0.1932 - val_categorical_crossentropy: 4.2204\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8396 - accuracy: 0.7117 - categorical_crossentropy: 0.83962020-05-01 10:38:45.717170: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 477ms/step - loss: 0.8392 - accuracy: 0.7120 - categorical_crossentropy: 0.8392 - val_loss: 5.3249 - val_accuracy: 0.1591 - val_categorical_crossentropy: 5.3249\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7831 - accuracy: 0.7391 - categorical_crossentropy: 0.78312020-05-01 10:40:11.024881: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 85s 463ms/step - loss: 0.7843 - accuracy: 0.7385 - categorical_crossentropy: 0.7843 - val_loss: 3.9600 - val_accuracy: 0.1477 - val_categorical_crossentropy: 3.9600\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8225 - accuracy: 0.7220 - categorical_crossentropy: 0.82252020-05-01 10:41:37.287886: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 86s 469ms/step - loss: 0.8232 - accuracy: 0.7221 - categorical_crossentropy: 0.8232 - val_loss: 4.3810 - val_accuracy: 0.1364 - val_categorical_crossentropy: 4.3810\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7480 - accuracy: 0.7384 - categorical_crossentropy: 0.74802020-05-01 10:43:05.784018: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 482ms/step - loss: 0.7513 - accuracy: 0.7378 - categorical_crossentropy: 0.7513 - val_loss: 6.1971 - val_accuracy: 0.1364 - val_categorical_crossentropy: 6.1971\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7804 - accuracy: 0.7336 - categorical_crossentropy: 0.78042020-05-01 10:44:30.677982: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 85s 460ms/step - loss: 0.7794 - accuracy: 0.7337 - categorical_crossentropy: 0.7794 - val_loss: 5.8262 - val_accuracy: 0.1591 - val_categorical_crossentropy: 5.8262\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7400 - accuracy: 0.7582 - categorical_crossentropy: 0.74002020-05-01 10:45:58.336311: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 476ms/step - loss: 0.7394 - accuracy: 0.7588 - categorical_crossentropy: 0.7394 - val_loss: 5.1596 - val_accuracy: 0.1364 - val_categorical_crossentropy: 5.1596\n",
      "2020-05-01 10:46:03.318088: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-01 10:46:03.319592: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-01 10:46:03.820540: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.825883: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.829358: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.832323: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.836147: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.839984: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.844025: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.848276: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.851336: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.860165: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-01 10:46:03.864382: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.868817: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.874671: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.880253: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.883511: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.888930: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.892274: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.896059: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.899521: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.904781: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.908445: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.911921: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.916071: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.919861: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.922836: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Proviamo a riaddestrare anche il terzultimo layer. Sul training migliora ancora ma sul validation no.\n",
    "!python train.py \\\n",
    "--exp=6 \\\n",
    "--weights=\"checkpoints/exp5/best_weights.ckpt\" \\\n",
    "--trainable_layers=8 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 17:45:07.068741: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-03 17:45:07.104777: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200035000 Hz\n",
      "2020-05-03 17:45:07.105447: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55845970e810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-03 17:45:07.105477: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-03 17:45:07.106661: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-03 17:45:20.174958: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 105s 572ms/step - loss: 2.5501 - accuracy: 0.1508 - categorical_crossentropy: 2.5501 - val_loss: 2.3871 - val_accuracy: 0.2045 - val_categorical_crossentropy: 2.3871\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.2250 - accuracy: 0.2691 - categorical_crossentropy: 2.22502020-05-03 17:48:26.410174: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 95s 516ms/step - loss: 2.2238 - accuracy: 0.2697 - categorical_crossentropy: 2.2238 - val_loss: 2.0416 - val_accuracy: 0.3409 - val_categorical_crossentropy: 2.0416\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9130 - accuracy: 0.3709 - categorical_crossentropy: 1.91302020-05-03 17:50:02.122855: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 523ms/step - loss: 1.9125 - accuracy: 0.3702 - categorical_crossentropy: 1.9125 - val_loss: 1.7609 - val_accuracy: 0.4489 - val_categorical_crossentropy: 1.7609\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7102 - accuracy: 0.4310 - categorical_crossentropy: 1.71022020-05-03 17:51:44.132286: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 102s 552ms/step - loss: 1.7068 - accuracy: 0.4321 - categorical_crossentropy: 1.7068 - val_loss: 1.5048 - val_accuracy: 0.5341 - val_categorical_crossentropy: 1.5048\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.5174 - accuracy: 0.4966 - categorical_crossentropy: 1.51742020-05-03 17:53:21.131385: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 530ms/step - loss: 1.5165 - accuracy: 0.4973 - categorical_crossentropy: 1.5165 - val_loss: 1.3383 - val_accuracy: 0.5284 - val_categorical_crossentropy: 1.3383\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.3642 - accuracy: 0.5266 - categorical_crossentropy: 1.36422020-05-03 17:54:57.951630: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 525ms/step - loss: 1.3627 - accuracy: 0.5258 - categorical_crossentropy: 1.3627 - val_loss: 1.1677 - val_accuracy: 0.6136 - val_categorical_crossentropy: 1.1677\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.2317 - accuracy: 0.5840 - categorical_crossentropy: 1.23172020-05-03 17:56:34.010213: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 520ms/step - loss: 1.2329 - accuracy: 0.5822 - categorical_crossentropy: 1.2329 - val_loss: 1.2043 - val_accuracy: 0.5909 - val_categorical_crossentropy: 1.2043\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.1147 - accuracy: 0.6366 - categorical_crossentropy: 1.11472020-05-03 17:58:10.743580: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 528ms/step - loss: 1.1188 - accuracy: 0.6359 - categorical_crossentropy: 1.1188 - val_loss: 0.8774 - val_accuracy: 0.7557 - val_categorical_crossentropy: 0.8774\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0740 - accuracy: 0.6523 - categorical_crossentropy: 1.07402020-05-03 17:59:45.040192: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 511ms/step - loss: 1.0723 - accuracy: 0.6529 - categorical_crossentropy: 1.0723 - val_loss: 0.7549 - val_accuracy: 0.7557 - val_categorical_crossentropy: 0.7549\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8897 - accuracy: 0.7077 - categorical_crossentropy: 0.88972020-05-03 18:01:13.709321: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 482ms/step - loss: 0.8904 - accuracy: 0.7072 - categorical_crossentropy: 0.8904 - val_loss: 0.8202 - val_accuracy: 0.7216 - val_categorical_crossentropy: 0.8202\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9194 - accuracy: 0.6913 - categorical_crossentropy: 0.91942020-05-03 18:02:50.249566: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 525ms/step - loss: 0.9168 - accuracy: 0.6923 - categorical_crossentropy: 0.9168 - val_loss: 0.7064 - val_accuracy: 0.7727 - val_categorical_crossentropy: 0.7064\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8613 - accuracy: 0.7042 - categorical_crossentropy: 0.86132020-05-03 18:04:22.546770: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 502ms/step - loss: 0.8615 - accuracy: 0.7045 - categorical_crossentropy: 0.8615 - val_loss: 0.6271 - val_accuracy: 0.7955 - val_categorical_crossentropy: 0.6271\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7765 - accuracy: 0.7432 - categorical_crossentropy: 0.77652020-05-03 18:05:50.671897: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 478ms/step - loss: 0.7782 - accuracy: 0.7432 - categorical_crossentropy: 0.7782 - val_loss: 0.6307 - val_accuracy: 0.7955 - val_categorical_crossentropy: 0.6307\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.7158 - accuracy: 0.7500 - categorical_crossentropy: 0.71582020-05-03 18:07:22.858246: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 503ms/step - loss: 0.7163 - accuracy: 0.7493 - categorical_crossentropy: 0.7163 - val_loss: 0.7495 - val_accuracy: 0.7330 - val_categorical_crossentropy: 0.7495\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.6628 - accuracy: 0.7780 - categorical_crossentropy: 0.66282020-05-03 18:08:51.030704: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 480ms/step - loss: 0.6631 - accuracy: 0.7785 - categorical_crossentropy: 0.6631 - val_loss: 0.4969 - val_accuracy: 0.8125 - val_categorical_crossentropy: 0.4969\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.6033 - accuracy: 0.7923 - categorical_crossentropy: 0.60332020-05-03 18:10:22.345390: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 91s 497ms/step - loss: 0.6043 - accuracy: 0.7914 - categorical_crossentropy: 0.6043 - val_loss: 0.4972 - val_accuracy: 0.8182 - val_categorical_crossentropy: 0.4972\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5880 - accuracy: 0.7930 - categorical_crossentropy: 0.58802020-05-03 18:11:52.367577: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 90s 487ms/step - loss: 0.5858 - accuracy: 0.7935 - categorical_crossentropy: 0.5858 - val_loss: 0.5101 - val_accuracy: 0.8352 - val_categorical_crossentropy: 0.5101\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5757 - accuracy: 0.8087 - categorical_crossentropy: 0.57572020-05-03 18:13:27.812718: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 519ms/step - loss: 0.5842 - accuracy: 0.8071 - categorical_crossentropy: 0.5842 - val_loss: 0.3624 - val_accuracy: 0.8750 - val_categorical_crossentropy: 0.3624\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5101 - accuracy: 0.8204 - categorical_crossentropy: 0.51012020-05-03 18:15:01.757073: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 511ms/step - loss: 0.5086 - accuracy: 0.8207 - categorical_crossentropy: 0.5086 - val_loss: 0.4444 - val_accuracy: 0.8182 - val_categorical_crossentropy: 0.4444\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5347 - accuracy: 0.8210 - categorical_crossentropy: 0.53472020-05-03 18:16:31.032058: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 484ms/step - loss: 0.5326 - accuracy: 0.8220 - categorical_crossentropy: 0.5326 - val_loss: 0.3601 - val_accuracy: 0.8693 - val_categorical_crossentropy: 0.3601\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4938 - accuracy: 0.8306 - categorical_crossentropy: 0.49382020-05-03 18:18:03.967800: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 505ms/step - loss: 0.4948 - accuracy: 0.8295 - categorical_crossentropy: 0.4948 - val_loss: 0.4233 - val_accuracy: 0.8409 - val_categorical_crossentropy: 0.4233\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4517 - accuracy: 0.8429 - categorical_crossentropy: 0.45172020-05-03 18:19:34.896075: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 91s 494ms/step - loss: 0.4518 - accuracy: 0.8417 - categorical_crossentropy: 0.4518 - val_loss: 0.3082 - val_accuracy: 0.8750 - val_categorical_crossentropy: 0.3082\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4646 - accuracy: 0.8538 - categorical_crossentropy: 0.46462020-05-03 18:21:08.597166: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 510ms/step - loss: 0.4648 - accuracy: 0.8533 - categorical_crossentropy: 0.4648 - val_loss: 0.2582 - val_accuracy: 0.9091 - val_categorical_crossentropy: 0.2582\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4605 - accuracy: 0.8395 - categorical_crossentropy: 0.46052020-05-03 18:22:43.949885: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 519ms/step - loss: 0.4588 - accuracy: 0.8404 - categorical_crossentropy: 0.4588 - val_loss: 0.2815 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.2815\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4055 - accuracy: 0.8566 - categorical_crossentropy: 0.40552020-05-03 18:24:17.628048: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 509ms/step - loss: 0.4037 - accuracy: 0.8573 - categorical_crossentropy: 0.4037 - val_loss: 0.2828 - val_accuracy: 0.9091 - val_categorical_crossentropy: 0.2828\n",
      "Epoch 26/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3322 - accuracy: 0.8818 - categorical_crossentropy: 0.33222020-05-03 18:25:50.493782: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 505ms/step - loss: 0.3307 - accuracy: 0.8825 - categorical_crossentropy: 0.3307 - val_loss: 0.3208 - val_accuracy: 0.8693 - val_categorical_crossentropy: 0.3208\n",
      "Epoch 27/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8641 - categorical_crossentropy: 0.38102020-05-03 18:27:23.577803: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 508ms/step - loss: 0.3792 - accuracy: 0.8648 - categorical_crossentropy: 0.3792 - val_loss: 0.3229 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.3229\n",
      "Epoch 28/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4187 - accuracy: 0.8600 - categorical_crossentropy: 0.41872020-05-03 18:28:55.584472: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 500ms/step - loss: 0.4166 - accuracy: 0.8607 - categorical_crossentropy: 0.4166 - val_loss: 0.2313 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.2313\n",
      "Epoch 29/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2949 - accuracy: 0.8975 - categorical_crossentropy: 0.29492020-05-03 18:30:27.282742: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 499ms/step - loss: 0.2945 - accuracy: 0.8974 - categorical_crossentropy: 0.2945 - val_loss: 0.2699 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.2699\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.8948 - categorical_crossentropy: 0.33292020-05-03 18:31:58.477830: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 91s 495ms/step - loss: 0.3312 - accuracy: 0.8954 - categorical_crossentropy: 0.3312 - val_loss: 0.4019 - val_accuracy: 0.8580 - val_categorical_crossentropy: 0.4019\n",
      "Epoch 31/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3224 - accuracy: 0.8934 - categorical_crossentropy: 0.32242020-05-03 18:33:34.629053: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 521ms/step - loss: 0.3234 - accuracy: 0.8933 - categorical_crossentropy: 0.3234 - val_loss: 0.2600 - val_accuracy: 0.8920 - val_categorical_crossentropy: 0.2600\n",
      "Epoch 32/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2975 - accuracy: 0.9030 - categorical_crossentropy: 0.29752020-05-03 18:35:09.854121: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 95s 517ms/step - loss: 0.2999 - accuracy: 0.9015 - categorical_crossentropy: 0.2999 - val_loss: 0.2086 - val_accuracy: 0.9034 - val_categorical_crossentropy: 0.2086\n",
      "Epoch 33/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3085 - accuracy: 0.8975 - categorical_crossentropy: 0.30852020-05-03 18:36:43.041895: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 507ms/step - loss: 0.3087 - accuracy: 0.8974 - categorical_crossentropy: 0.3087 - val_loss: 0.3093 - val_accuracy: 0.9205 - val_categorical_crossentropy: 0.3093\n",
      "Epoch 34/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2903 - accuracy: 0.8996 - categorical_crossentropy: 0.29032020-05-03 18:38:30.193884: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 107s 583ms/step - loss: 0.2939 - accuracy: 0.8988 - categorical_crossentropy: 0.2939 - val_loss: 0.2787 - val_accuracy: 0.9034 - val_categorical_crossentropy: 0.2787\n",
      "Epoch 35/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3095 - accuracy: 0.8907 - categorical_crossentropy: 0.30952020-05-03 18:40:02.319869: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 501ms/step - loss: 0.3080 - accuracy: 0.8913 - categorical_crossentropy: 0.3080 - val_loss: 0.3136 - val_accuracy: 0.8977 - val_categorical_crossentropy: 0.3136\n",
      "Epoch 36/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2891 - accuracy: 0.8948 - categorical_crossentropy: 0.28912020-05-03 18:41:36.990505: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 95s 515ms/step - loss: 0.2880 - accuracy: 0.8954 - categorical_crossentropy: 0.2880 - val_loss: 0.1334 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.1334\n",
      "Epoch 37/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.9085 - categorical_crossentropy: 0.29012020-05-03 18:43:04.476826: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 87s 475ms/step - loss: 0.2914 - accuracy: 0.9076 - categorical_crossentropy: 0.2914 - val_loss: 0.2488 - val_accuracy: 0.9091 - val_categorical_crossentropy: 0.2488\n",
      "Epoch 38/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.9112 - categorical_crossentropy: 0.27312020-05-03 18:44:41.537090: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 527ms/step - loss: 0.2758 - accuracy: 0.9103 - categorical_crossentropy: 0.2758 - val_loss: 0.2899 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.2899\n",
      "Epoch 39/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2966 - accuracy: 0.9051 - categorical_crossentropy: 0.29662020-05-03 18:46:16.597745: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 519ms/step - loss: 0.2953 - accuracy: 0.9056 - categorical_crossentropy: 0.2953 - val_loss: 0.1887 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1887\n",
      "Epoch 40/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2357 - accuracy: 0.9290 - categorical_crossentropy: 0.23572020-05-03 18:47:47.036519: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 90s 488ms/step - loss: 0.2373 - accuracy: 0.9280 - categorical_crossentropy: 0.2373 - val_loss: 0.2035 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.2035\n",
      "Epoch 41/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2642 - accuracy: 0.9133 - categorical_crossentropy: 0.26422020-05-03 18:49:20.301110: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 507ms/step - loss: 0.2674 - accuracy: 0.9117 - categorical_crossentropy: 0.2674 - val_loss: 0.1668 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1668\n",
      "Epoch 42/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.9208 - categorical_crossentropy: 0.23602020-05-03 18:50:49.639457: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 486ms/step - loss: 0.2349 - accuracy: 0.9212 - categorical_crossentropy: 0.2349 - val_loss: 0.1883 - val_accuracy: 0.9375 - val_categorical_crossentropy: 0.1883\n",
      "Epoch 43/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2019 - accuracy: 0.9296 - categorical_crossentropy: 0.20192020-05-03 18:52:25.567571: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 522ms/step - loss: 0.2019 - accuracy: 0.9300 - categorical_crossentropy: 0.2019 - val_loss: 0.2205 - val_accuracy: 0.9318 - val_categorical_crossentropy: 0.2205\n",
      "Epoch 44/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2239 - accuracy: 0.9249 - categorical_crossentropy: 0.22392020-05-03 18:53:52.366988: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 87s 470ms/step - loss: 0.2228 - accuracy: 0.9253 - categorical_crossentropy: 0.2228 - val_loss: 0.1716 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.1716\n",
      "Epoch 45/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9180 - categorical_crossentropy: 0.23062020-05-03 18:55:30.627729: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 98s 534ms/step - loss: 0.2302 - accuracy: 0.9185 - categorical_crossentropy: 0.2302 - val_loss: 0.1841 - val_accuracy: 0.9318 - val_categorical_crossentropy: 0.1841\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.1934 - accuracy: 0.9385 - categorical_crossentropy: 0.19342020-05-03 18:57:05.145310: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 95s 515ms/step - loss: 0.1926 - accuracy: 0.9389 - categorical_crossentropy: 0.1926 - val_loss: 0.2946 - val_accuracy: 0.8864 - val_categorical_crossentropy: 0.2946\n",
      "Epoch 47/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9214 - categorical_crossentropy: 0.24622020-05-03 18:58:34.633061: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 486ms/step - loss: 0.2485 - accuracy: 0.9212 - categorical_crossentropy: 0.2485 - val_loss: 0.1635 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1635\n",
      "Epoch 48/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2234 - accuracy: 0.9214 - categorical_crossentropy: 0.22342020-05-03 19:00:08.087381: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 505ms/step - loss: 0.2226 - accuracy: 0.9219 - categorical_crossentropy: 0.2226 - val_loss: 0.1920 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1920\n",
      "Epoch 49/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9214 - categorical_crossentropy: 0.24622020-05-03 19:01:40.092230: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 503ms/step - loss: 0.2449 - accuracy: 0.9219 - categorical_crossentropy: 0.2449 - val_loss: 0.1676 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1676\n",
      "Epoch 50/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1994 - accuracy: 0.9276 - categorical_crossentropy: 0.19942020-05-03 19:03:13.199048: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 506ms/step - loss: 0.1993 - accuracy: 0.9273 - categorical_crossentropy: 0.1993 - val_loss: 0.1898 - val_accuracy: 0.9375 - val_categorical_crossentropy: 0.1898\n",
      "Epoch 51/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9324 - categorical_crossentropy: 0.21612020-05-03 19:04:47.050780: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 509ms/step - loss: 0.2185 - accuracy: 0.9321 - categorical_crossentropy: 0.2185 - val_loss: 0.2358 - val_accuracy: 0.8977 - val_categorical_crossentropy: 0.2358\n",
      "Epoch 52/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2036 - accuracy: 0.9290 - categorical_crossentropy: 0.20362020-05-03 19:06:25.501203: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 98s 534ms/step - loss: 0.2028 - accuracy: 0.9293 - categorical_crossentropy: 0.2028 - val_loss: 0.2039 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.2039\n",
      "Epoch 53/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1712 - accuracy: 0.9419 - categorical_crossentropy: 0.17122020-05-03 19:08:04.004588: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 99s 540ms/step - loss: 0.1712 - accuracy: 0.9416 - categorical_crossentropy: 0.1712 - val_loss: 0.1210 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.1210\n",
      "Epoch 54/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1776 - accuracy: 0.9447 - categorical_crossentropy: 0.17762020-05-03 19:09:35.279461: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 91s 495ms/step - loss: 0.1784 - accuracy: 0.9443 - categorical_crossentropy: 0.1784 - val_loss: 0.3264 - val_accuracy: 0.8977 - val_categorical_crossentropy: 0.3264\n",
      "Epoch 55/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2169 - accuracy: 0.9296 - categorical_crossentropy: 0.21692020-05-03 19:11:12.398628: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 525ms/step - loss: 0.2159 - accuracy: 0.9300 - categorical_crossentropy: 0.2159 - val_loss: 0.1461 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1461\n",
      "Epoch 56/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9413 - categorical_crossentropy: 0.17162020-05-03 19:12:48.630844: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 524ms/step - loss: 0.1708 - accuracy: 0.9416 - categorical_crossentropy: 0.1708 - val_loss: 0.1857 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.1857\n",
      "Epoch 57/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9392 - categorical_crossentropy: 0.16662020-05-03 19:14:20.839284: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 502ms/step - loss: 0.1683 - accuracy: 0.9389 - categorical_crossentropy: 0.1683 - val_loss: 0.1141 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1141\n",
      "Epoch 58/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1718 - accuracy: 0.9419 - categorical_crossentropy: 0.17182020-05-03 19:15:53.724399: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 505ms/step - loss: 0.1709 - accuracy: 0.9423 - categorical_crossentropy: 0.1709 - val_loss: 0.1172 - val_accuracy: 0.9659 - val_categorical_crossentropy: 0.1172\n",
      "Epoch 59/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2087 - accuracy: 0.9276 - categorical_crossentropy: 0.20872020-05-03 19:17:33.979250: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 100s 543ms/step - loss: 0.2079 - accuracy: 0.9280 - categorical_crossentropy: 0.2079 - val_loss: 0.2006 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.2006\n",
      "Epoch 60/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1783 - accuracy: 0.9433 - categorical_crossentropy: 0.17832020-05-03 19:19:09.273799: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 520ms/step - loss: 0.1783 - accuracy: 0.9429 - categorical_crossentropy: 0.1783 - val_loss: 0.2197 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.2197\n",
      "Epoch 61/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1877 - accuracy: 0.9433 - categorical_crossentropy: 0.18772020-05-03 19:20:37.933400: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 481ms/step - loss: 0.1905 - accuracy: 0.9429 - categorical_crossentropy: 0.1905 - val_loss: 0.0890 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.0890\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.1893 - accuracy: 0.9440 - categorical_crossentropy: 0.18932020-05-03 19:22:09.821908: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 499ms/step - loss: 0.1883 - accuracy: 0.9443 - categorical_crossentropy: 0.1883 - val_loss: 0.1470 - val_accuracy: 0.9205 - val_categorical_crossentropy: 0.1470\n",
      "Epoch 63/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1674 - accuracy: 0.9406 - categorical_crossentropy: 0.16742020-05-03 19:23:44.126164: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 512ms/step - loss: 0.1671 - accuracy: 0.9409 - categorical_crossentropy: 0.1671 - val_loss: 0.1622 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.1622\n",
      "Epoch 64/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9508 - categorical_crossentropy: 0.14152020-05-03 19:25:13.206291: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 483ms/step - loss: 0.1468 - accuracy: 0.9497 - categorical_crossentropy: 0.1468 - val_loss: 0.1277 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.1277\n",
      "Epoch 65/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9447 - categorical_crossentropy: 0.15482020-05-03 19:26:48.420757: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 95s 517ms/step - loss: 0.1551 - accuracy: 0.9443 - categorical_crossentropy: 0.1551 - val_loss: 0.2119 - val_accuracy: 0.9375 - val_categorical_crossentropy: 0.2119\n",
      "Epoch 66/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1655 - accuracy: 0.9440 - categorical_crossentropy: 0.16552020-05-03 19:28:20.586687: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 501ms/step - loss: 0.1648 - accuracy: 0.9443 - categorical_crossentropy: 0.1648 - val_loss: 0.1190 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1190\n",
      "Epoch 67/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1397 - accuracy: 0.9536 - categorical_crossentropy: 0.13972020-05-03 19:29:49.996684: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 90s 488ms/step - loss: 0.1408 - accuracy: 0.9531 - categorical_crossentropy: 0.1408 - val_loss: 0.0798 - val_accuracy: 0.9659 - val_categorical_crossentropy: 0.0798\n",
      "Epoch 68/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1482 - accuracy: 0.9577 - categorical_crossentropy: 0.14822020-05-03 19:31:19.947632: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 90s 487ms/step - loss: 0.1487 - accuracy: 0.9572 - categorical_crossentropy: 0.1487 - val_loss: 0.1299 - val_accuracy: 0.9375 - val_categorical_crossentropy: 0.1299\n",
      "2020-05-03 19:31:23.632801: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-03 19:31:23.643066: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-03 19:31:28.665503: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.677005: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.685335: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.691836: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.697776: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.704274: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.712255: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.718764: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.723763: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.729203: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.743271: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.748982: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 19:31:28.754626: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.760436: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.770232: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.775692: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.784651: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.796240: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.804461: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.821631: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.834739: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.842983: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.851875: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.880249: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.893636: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.904294: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.912936: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.920111: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.925593: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.941152: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.947392: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.952950: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.964278: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 19:31:29.034795: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.060606: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.082531: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.107562: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.113179: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.119145: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.141064: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.156806: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.164238: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.173184: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.181324: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.189599: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.195593: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.203326: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.209436: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.216411: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.222522: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.227501: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.235805: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.241926: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.248265: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.258579: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 19:31:29.268609: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.275074: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.281706: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.287208: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.295936: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.300503: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.306697: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.313820: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.321200: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.326775: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.331782: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.339375: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.344907: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Riproviamo l'exp 2 ma con unfreeze di tutti i layer di batch normalization. L'overfitting è SCOMPARSO!.\n",
    "# Tutti gli esperimenti d'ora in poi faranno l'unfreeze della batch normalization.\n",
    "!python train.py \\\n",
    "--exp=7 \\\n",
    "--weights=\"imagenet\" \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 19:36:01.418151: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-03 19:36:01.448768: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200035000 Hz\n",
      "2020-05-03 19:36:01.449420: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5600a7438810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-03 19:36:01.449513: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-03 19:36:01.449990: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-03 19:36:10.651524: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 125s 678ms/step - loss: 2.5851 - accuracy: 0.1420 - categorical_crossentropy: 2.5851 - val_loss: 2.4336 - val_accuracy: 0.2102 - val_categorical_crossentropy: 2.4336\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.2517 - accuracy: 0.2439 - categorical_crossentropy: 2.25172020-05-03 19:40:18.083271: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 134s 731ms/step - loss: 2.2489 - accuracy: 0.2446 - categorical_crossentropy: 2.2489 - val_loss: 2.2343 - val_accuracy: 0.3125 - val_categorical_crossentropy: 2.2343\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9768 - accuracy: 0.3245 - categorical_crossentropy: 1.97682020-05-03 19:42:25.027331: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 127s 689ms/step - loss: 1.9741 - accuracy: 0.3247 - categorical_crossentropy: 1.9741 - val_loss: 2.5488 - val_accuracy: 0.4148 - val_categorical_crossentropy: 2.5488\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7954 - accuracy: 0.4023 - categorical_crossentropy: 1.79542020-05-03 19:44:33.137534: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 128s 694ms/step - loss: 1.7957 - accuracy: 0.4015 - categorical_crossentropy: 1.7957 - val_loss: 1.8102 - val_accuracy: 0.4091 - val_categorical_crossentropy: 1.8102\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.5961 - accuracy: 0.4672 - categorical_crossentropy: 1.59612020-05-03 19:46:43.167071: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 131s 710ms/step - loss: 1.5985 - accuracy: 0.4654 - categorical_crossentropy: 1.5985 - val_loss: 1.2164 - val_accuracy: 0.5852 - val_categorical_crossentropy: 1.2164\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4002 - accuracy: 0.5171 - categorical_crossentropy: 1.40022020-05-03 19:48:47.034549: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 124s 672ms/step - loss: 1.4001 - accuracy: 0.5170 - categorical_crossentropy: 1.4001 - val_loss: 0.9936 - val_accuracy: 0.6875 - val_categorical_crossentropy: 0.9936\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.3115 - accuracy: 0.5704 - categorical_crossentropy: 1.31152020-05-03 19:50:50.033773: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 122s 665ms/step - loss: 1.3087 - accuracy: 0.5713 - categorical_crossentropy: 1.3087 - val_loss: 1.0116 - val_accuracy: 0.6364 - val_categorical_crossentropy: 1.0116\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.2262 - accuracy: 0.5888 - categorical_crossentropy: 1.22622020-05-03 19:52:47.343674: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 117s 638ms/step - loss: 1.2238 - accuracy: 0.5890 - categorical_crossentropy: 1.2238 - val_loss: 1.0621 - val_accuracy: 0.6534 - val_categorical_crossentropy: 1.0621\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0733 - accuracy: 0.6428 - categorical_crossentropy: 1.07332020-05-03 19:54:51.592516: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 125s 678ms/step - loss: 1.0722 - accuracy: 0.6433 - categorical_crossentropy: 1.0722 - val_loss: 0.8592 - val_accuracy: 0.7159 - val_categorical_crossentropy: 0.8592\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0203 - accuracy: 0.6571 - categorical_crossentropy: 1.02032020-05-03 19:56:55.743462: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 124s 673ms/step - loss: 1.0169 - accuracy: 0.6583 - categorical_crossentropy: 1.0169 - val_loss: 0.8764 - val_accuracy: 0.6875 - val_categorical_crossentropy: 0.8764\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9016 - accuracy: 0.6960 - categorical_crossentropy: 0.90162020-05-03 19:59:04.679071: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 129s 702ms/step - loss: 0.9027 - accuracy: 0.6943 - categorical_crossentropy: 0.9027 - val_loss: 0.8346 - val_accuracy: 0.6648 - val_categorical_crossentropy: 0.8346\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8340 - accuracy: 0.7138 - categorical_crossentropy: 0.83402020-05-03 20:01:21.816936: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 137s 745ms/step - loss: 0.8352 - accuracy: 0.7133 - categorical_crossentropy: 0.8352 - val_loss: 0.7836 - val_accuracy: 0.7386 - val_categorical_crossentropy: 0.7836\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7975 - accuracy: 0.7234 - categorical_crossentropy: 0.79752020-05-03 20:03:17.042692: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 116s 629ms/step - loss: 0.7947 - accuracy: 0.7242 - categorical_crossentropy: 0.7947 - val_loss: 0.5744 - val_accuracy: 0.8182 - val_categorical_crossentropy: 0.5744\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.7116 - accuracy: 0.7616 - categorical_crossentropy: 0.71162020-05-03 20:05:09.899432: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 113s 612ms/step - loss: 0.7125 - accuracy: 0.7609 - categorical_crossentropy: 0.7125 - val_loss: 0.6271 - val_accuracy: 0.8011 - val_categorical_crossentropy: 0.6271\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7173 - accuracy: 0.7466 - categorical_crossentropy: 0.71732020-05-03 20:07:28.328849: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 138s 750ms/step - loss: 0.7217 - accuracy: 0.7452 - categorical_crossentropy: 0.7217 - val_loss: 0.5829 - val_accuracy: 0.8011 - val_categorical_crossentropy: 0.5829\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.6969 - accuracy: 0.7643 - categorical_crossentropy: 0.69692020-05-03 20:09:26.726025: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 119s 647ms/step - loss: 0.6954 - accuracy: 0.7649 - categorical_crossentropy: 0.6954 - val_loss: 0.5814 - val_accuracy: 0.8068 - val_categorical_crossentropy: 0.5814\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.6474 - accuracy: 0.7794 - categorical_crossentropy: 0.64742020-05-03 20:11:23.145007: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 116s 630ms/step - loss: 0.6488 - accuracy: 0.7779 - categorical_crossentropy: 0.6488 - val_loss: 0.5582 - val_accuracy: 0.8295 - val_categorical_crossentropy: 0.5582\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5682 - accuracy: 0.8108 - categorical_crossentropy: 0.56822020-05-03 20:13:31.637203: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 129s 700ms/step - loss: 0.5662 - accuracy: 0.8111 - categorical_crossentropy: 0.5662 - val_loss: 0.5558 - val_accuracy: 0.8636 - val_categorical_crossentropy: 0.5558\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4981 - accuracy: 0.8292 - categorical_crossentropy: 0.49812020-05-03 20:15:30.073842: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 118s 641ms/step - loss: 0.4964 - accuracy: 0.8302 - categorical_crossentropy: 0.4964 - val_loss: 0.5174 - val_accuracy: 0.8125 - val_categorical_crossentropy: 0.5174\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5232 - accuracy: 0.8169 - categorical_crossentropy: 0.52322020-05-03 20:17:25.800297: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 116s 629ms/step - loss: 0.5216 - accuracy: 0.8173 - categorical_crossentropy: 0.5216 - val_loss: 0.4591 - val_accuracy: 0.8523 - val_categorical_crossentropy: 0.4590\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.8361 - categorical_crossentropy: 0.49552020-05-03 20:19:26.428650: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 121s 658ms/step - loss: 0.4945 - accuracy: 0.8363 - categorical_crossentropy: 0.4945 - val_loss: 0.3471 - val_accuracy: 0.8920 - val_categorical_crossentropy: 0.3471\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4732 - accuracy: 0.8347 - categorical_crossentropy: 0.47322020-05-03 20:21:25.220677: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 118s 642ms/step - loss: 0.4708 - accuracy: 0.8356 - categorical_crossentropy: 0.4708 - val_loss: 0.3560 - val_accuracy: 0.8750 - val_categorical_crossentropy: 0.3560\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5088 - accuracy: 0.8340 - categorical_crossentropy: 0.50882020-05-03 20:23:32.140873: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 127s 690ms/step - loss: 0.5102 - accuracy: 0.8329 - categorical_crossentropy: 0.5102 - val_loss: 0.4285 - val_accuracy: 0.8636 - val_categorical_crossentropy: 0.4285\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4333 - accuracy: 0.8586 - categorical_crossentropy: 0.43332020-05-03 20:25:30.725652: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 119s 645ms/step - loss: 0.4316 - accuracy: 0.8594 - categorical_crossentropy: 0.4316 - val_loss: 0.4278 - val_accuracy: 0.8636 - val_categorical_crossentropy: 0.4278\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4378 - accuracy: 0.8607 - categorical_crossentropy: 0.43782020-05-03 20:27:38.728003: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 128s 697ms/step - loss: 0.4409 - accuracy: 0.8594 - categorical_crossentropy: 0.4409 - val_loss: 0.3664 - val_accuracy: 0.8693 - val_categorical_crossentropy: 0.3664\n",
      "Epoch 26/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3719 - accuracy: 0.8743 - categorical_crossentropy: 0.37192020-05-03 20:29:40.659722: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 122s 664ms/step - loss: 0.3701 - accuracy: 0.8750 - categorical_crossentropy: 0.3701 - val_loss: 0.2735 - val_accuracy: 0.9034 - val_categorical_crossentropy: 0.2735\n",
      "Epoch 27/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3786 - accuracy: 0.8757 - categorical_crossentropy: 0.37862020-05-03 20:31:47.830400: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 127s 689ms/step - loss: 0.3770 - accuracy: 0.8764 - categorical_crossentropy: 0.3770 - val_loss: 0.1942 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.1942\n",
      "Epoch 28/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8805 - categorical_crossentropy: 0.38672020-05-03 20:33:58.066310: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 130s 709ms/step - loss: 0.3848 - accuracy: 0.8811 - categorical_crossentropy: 0.3848 - val_loss: 0.4616 - val_accuracy: 0.8068 - val_categorical_crossentropy: 0.4616\n",
      "Epoch 29/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3680 - accuracy: 0.8716 - categorical_crossentropy: 0.36802020-05-03 20:36:12.159311: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 134s 728ms/step - loss: 0.3674 - accuracy: 0.8709 - categorical_crossentropy: 0.3674 - val_loss: 0.3706 - val_accuracy: 0.8807 - val_categorical_crossentropy: 0.3706\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.3686 - accuracy: 0.8839 - categorical_crossentropy: 0.36862020-05-03 20:38:21.640593: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 130s 705ms/step - loss: 0.3701 - accuracy: 0.8825 - categorical_crossentropy: 0.3701 - val_loss: 0.3840 - val_accuracy: 0.8693 - val_categorical_crossentropy: 0.3840\n",
      "Epoch 31/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3462 - accuracy: 0.8880 - categorical_crossentropy: 0.34622020-05-03 20:40:28.053217: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 126s 684ms/step - loss: 0.3472 - accuracy: 0.8872 - categorical_crossentropy: 0.3472 - val_loss: 0.3177 - val_accuracy: 0.8864 - val_categorical_crossentropy: 0.3177\n",
      "Epoch 32/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3428 - accuracy: 0.8941 - categorical_crossentropy: 0.34282020-05-03 20:42:39.957479: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 133s 720ms/step - loss: 0.3415 - accuracy: 0.8947 - categorical_crossentropy: 0.3415 - val_loss: 0.2898 - val_accuracy: 0.9091 - val_categorical_crossentropy: 0.2898\n",
      "Epoch 33/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3149 - accuracy: 0.8955 - categorical_crossentropy: 0.31492020-05-03 20:44:42.736166: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 122s 664ms/step - loss: 0.3153 - accuracy: 0.8954 - categorical_crossentropy: 0.3153 - val_loss: 0.2137 - val_accuracy: 0.9205 - val_categorical_crossentropy: 0.2137\n",
      "Epoch 34/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3591 - accuracy: 0.8859 - categorical_crossentropy: 0.35912020-05-03 20:46:45.353096: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 123s 667ms/step - loss: 0.3581 - accuracy: 0.8859 - categorical_crossentropy: 0.3581 - val_loss: 0.2300 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.2300\n",
      "Epoch 35/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.8989 - categorical_crossentropy: 0.28972020-05-03 20:48:34.430111: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 110s 596ms/step - loss: 0.2927 - accuracy: 0.8981 - categorical_crossentropy: 0.2927 - val_loss: 0.2083 - val_accuracy: 0.9318 - val_categorical_crossentropy: 0.2083\n",
      "Epoch 36/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2494 - accuracy: 0.9153 - categorical_crossentropy: 0.24942020-05-03 20:50:38.568984: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 124s 674ms/step - loss: 0.2497 - accuracy: 0.9144 - categorical_crossentropy: 0.2497 - val_loss: 0.1472 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.1472\n",
      "Epoch 37/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2863 - accuracy: 0.9071 - categorical_crossentropy: 0.28632020-05-03 20:52:44.670196: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 125s 682ms/step - loss: 0.2850 - accuracy: 0.9076 - categorical_crossentropy: 0.2850 - val_loss: 0.4163 - val_accuracy: 0.8920 - val_categorical_crossentropy: 0.4163\n",
      "Epoch 38/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2736 - accuracy: 0.9064 - categorical_crossentropy: 0.27362020-05-03 20:54:58.232012: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 133s 726ms/step - loss: 0.2735 - accuracy: 0.9062 - categorical_crossentropy: 0.2735 - val_loss: 0.2695 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.2695\n",
      "Epoch 39/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2414 - accuracy: 0.9255 - categorical_crossentropy: 0.24142020-05-03 20:57:09.498956: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 131s 714ms/step - loss: 0.2403 - accuracy: 0.9260 - categorical_crossentropy: 0.2403 - val_loss: 0.2222 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.2222\n",
      "Epoch 40/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.8989 - categorical_crossentropy: 0.27312020-05-03 20:59:35.209646: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 146s 793ms/step - loss: 0.2722 - accuracy: 0.8995 - categorical_crossentropy: 0.2722 - val_loss: 0.1622 - val_accuracy: 0.9318 - val_categorical_crossentropy: 0.1622\n",
      "Epoch 41/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9187 - categorical_crossentropy: 0.23332020-05-03 21:01:50.745028: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 136s 742ms/step - loss: 0.2329 - accuracy: 0.9192 - categorical_crossentropy: 0.2329 - val_loss: 0.2421 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.2421\n",
      "Epoch 42/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.9092 - categorical_crossentropy: 0.28552020-05-03 21:04:02.373756: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 131s 713ms/step - loss: 0.2842 - accuracy: 0.9096 - categorical_crossentropy: 0.2842 - val_loss: 0.1715 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1715\n",
      "Epoch 43/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2428 - accuracy: 0.9194 - categorical_crossentropy: 0.24282020-05-03 21:06:17.416424: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 134s 731ms/step - loss: 0.2417 - accuracy: 0.9198 - categorical_crossentropy: 0.2417 - val_loss: 0.2283 - val_accuracy: 0.9205 - val_categorical_crossentropy: 0.2283\n",
      "Epoch 44/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2270 - accuracy: 0.9317 - categorical_crossentropy: 0.22702020-05-03 21:08:21.687094: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 124s 676ms/step - loss: 0.2265 - accuracy: 0.9321 - categorical_crossentropy: 0.2265 - val_loss: 0.1330 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.1330\n",
      "Epoch 45/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2451 - accuracy: 0.9249 - categorical_crossentropy: 0.24512020-05-03 21:10:34.362949: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 133s 721ms/step - loss: 0.2439 - accuracy: 0.9253 - categorical_crossentropy: 0.2439 - val_loss: 0.1801 - val_accuracy: 0.9375 - val_categorical_crossentropy: 0.1801\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.2232 - accuracy: 0.9214 - categorical_crossentropy: 0.22322020-05-03 21:12:43.200947: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 129s 701ms/step - loss: 0.2221 - accuracy: 0.9219 - categorical_crossentropy: 0.2221 - val_loss: 0.1689 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1689\n",
      "2020-05-03 21:12:48.225544: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-03 21:12:48.227167: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-03 21:12:52.100387: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.107804: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.114143: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.120668: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.125788: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.130435: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.135437: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.140960: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.153135: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.164132: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.170871: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.177277: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.183261: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.192127: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.196927: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.202860: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.260688: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.267956: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.277140: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.283009: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.292135: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.297159: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 21:12:52.303286: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.315321: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.321941: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.327022: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.334526: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.339950: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.344506: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.350340: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.354854: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.359532: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.371311: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.377853: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.383903: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.388651: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.396354: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.401705: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.409297: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.414702: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.424306: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.431396: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.437498: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.442290: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.447877: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 21:12:52.452501: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n"
     ]
    }
   ],
   "source": [
    "# Riproviamo l'exp 7 ma con Adam.\n",
    "!python train.py \\\n",
    "--exp=8 \\\n",
    "--weights=\"imagenet\" \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"adam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riproviamo l'exp 7 ma con Adadelta.\n",
    "!python train.py \\\n",
    "--exp=9 \\\n",
    "--weights=\"imagenet\" \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"adadelta\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riproviamo l'exp 7 ma con RMSProp.\n",
    "!python train.py \\\n",
    "--exp=10 \\\n",
    "--weights=\"imagenet\" \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"rmsprop\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
