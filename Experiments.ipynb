{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-26 11:04:33.092504: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-04-26 11:04:33.116468: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200070000 Hz\n",
      "2020-04-26 11:04:33.116848: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dc684150e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-26 11:04:33.116875: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-26 11:04:33.116985: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "output\n",
      "Train for 462 steps, validate for 151 steps\n",
      "Epoch 1/1000\n",
      "2020-04-26 11:04:55.717546: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Filling up shuffle buffer (this may take a while): 780 of 1000\n",
      "2020-04-26 11:04:58.401275: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:199] Shuffle buffer filled.\n",
      "2020-04-26 11:04:59.190838: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "462/462 [==============================] - 229s 495ms/step - loss: 2.3830 - accuracy: 0.2200 - categorical_crossentropy: 2.3830 - val_loss: 3.1479 - val_accuracy: 0.1167 - val_categorical_crossentropy: 3.1479\n",
      "Epoch 2/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 2.0775 - accuracy: 0.3398 - categorical_crossentropy: 2.07752020-04-26 11:11:06.821893: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 202s 436ms/step - loss: 2.0769 - accuracy: 0.3398 - categorical_crossentropy: 2.0769 - val_loss: 3.5188 - val_accuracy: 0.1217 - val_categorical_crossentropy: 3.5187\n",
      "Epoch 3/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 2.0000 - accuracy: 0.3628 - categorical_crossentropy: 2.00002020-04-26 11:15:23.439204: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 267s 577ms/step - loss: 1.9999 - accuracy: 0.3628 - categorical_crossentropy: 1.9999 - val_loss: 3.9268 - val_accuracy: 0.1151 - val_categorical_crossentropy: 3.9268\n",
      "Epoch 4/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.9276 - accuracy: 0.3888 - categorical_crossentropy: 1.92762020-04-26 11:19:58.350647: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 281s 609ms/step - loss: 1.9271 - accuracy: 0.3893 - categorical_crossentropy: 1.9271 - val_loss: 3.7123 - val_accuracy: 0.1291 - val_categorical_crossentropy: 3.7123\n",
      "Epoch 5/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.8632 - accuracy: 0.4159 - categorical_crossentropy: 1.86322020-04-26 11:24:05.681569: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 265s 573ms/step - loss: 1.8633 - accuracy: 0.4159 - categorical_crossentropy: 1.8633 - val_loss: 4.0487 - val_accuracy: 0.1349 - val_categorical_crossentropy: 4.0487\n",
      "Epoch 6/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.8151 - accuracy: 0.4219 - categorical_crossentropy: 1.81512020-04-26 11:28:21.738088: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 255s 553ms/step - loss: 1.8143 - accuracy: 0.4221 - categorical_crossentropy: 1.8143 - val_loss: 3.8435 - val_accuracy: 0.1531 - val_categorical_crossentropy: 3.8435\n",
      "Epoch 7/1000\n",
      "277/462 [================>.............] - ETA: 1:04 - loss: 1.8149 - accuracy: 0.4224 - categorical_crossentropy: 1.81492020-04-26 11:31:17.758180: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Filling up shuffle buffer (this may take a while): 723 of 1000\n",
      "279/462 [=================>............] - ETA: 1:03 - loss: 1.8181 - accuracy: 0.4211 - categorical_crossentropy: 1.81812020-04-26 11:31:21.476413: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:199] Shuffle buffer filled.\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.8134 - accuracy: 0.4176 - categorical_crossentropy: 1.81342020-04-26 11:32:23.268377: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 253s 547ms/step - loss: 1.8126 - accuracy: 0.4183 - categorical_crossentropy: 1.8126 - val_loss: 4.0689 - val_accuracy: 0.1399 - val_categorical_crossentropy: 4.0689\n",
      "Epoch 8/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.8203 - accuracy: 0.4281 - categorical_crossentropy: 1.82032020-04-26 11:35:55.922659: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 227s 492ms/step - loss: 1.8197 - accuracy: 0.4286 - categorical_crossentropy: 1.8197 - val_loss: 4.0997 - val_accuracy: 0.1374 - val_categorical_crossentropy: 4.0997\n",
      "Epoch 9/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.7748 - accuracy: 0.4300 - categorical_crossentropy: 1.77482020-04-26 11:39:46.477812: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 206s 446ms/step - loss: 1.7761 - accuracy: 0.4294 - categorical_crossentropy: 1.7761 - val_loss: 4.4751 - val_accuracy: 0.1316 - val_categorical_crossentropy: 4.4750\n",
      "Epoch 10/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.7651 - accuracy: 0.4403 - categorical_crossentropy: 1.76512020-04-26 11:43:09.172111: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 210s 453ms/step - loss: 1.7635 - accuracy: 0.4407 - categorical_crossentropy: 1.7635 - val_loss: 4.3000 - val_accuracy: 0.1507 - val_categorical_crossentropy: 4.3000\n",
      "Epoch 11/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.7390 - accuracy: 0.4509 - categorical_crossentropy: 1.73902020-04-26 11:46:41.055464: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 212s 459ms/step - loss: 1.7384 - accuracy: 0.4513 - categorical_crossentropy: 1.7384 - val_loss: 4.9477 - val_accuracy: 0.1093 - val_categorical_crossentropy: 4.9477\n",
      "Epoch 12/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.7164 - accuracy: 0.4612 - categorical_crossentropy: 1.71642020-04-26 11:50:18.686204: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 234s 506ms/step - loss: 1.7150 - accuracy: 0.4621 - categorical_crossentropy: 1.7150 - val_loss: 4.9578 - val_accuracy: 0.1142 - val_categorical_crossentropy: 4.9578\n",
      "Epoch 13/1000\n",
      "461/462 [============================>.] - ETA: 0s - loss: 1.7068 - accuracy: 0.4447 - categorical_crossentropy: 1.70682020-04-26 11:54:24.720371: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "462/462 [==============================] - 193s 417ms/step - loss: 1.7072 - accuracy: 0.4445 - categorical_crossentropy: 1.7072 - val_loss: 4.9328 - val_accuracy: 0.1233 - val_categorical_crossentropy: 4.9328\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61/462 [==>...........................] - ETA: 1:57 - loss: 1.6623 - accuracy: 0.4506 - categorical_crossentropy: 1.66232020-04-26 11:55:33.829630: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 462000 batches). You may need to use the repeat() function when building your dataset.\n",
      "W0426 11:55:33.919927 140155385075520 training_v2.py:152] Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 462000 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "W0426 11:55:33.922087 140155385075520 callbacks.py:1018] Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,categorical_crossentropy\n",
      "W0426 11:55:33.922249 140155385075520 callbacks.py:1286] Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,categorical_crossentropy\n",
      " 61/462 [==>...........................] - ETA: 1:57 - loss: 1.6623 - accuracy: 0.4506 - categorical_crossentropy: 1.66232020-04-26 11:55:33.931038: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    }
   ],
   "source": [
    "# Questo è stato fatto con il dataset non ridotto e senza unfreeze batchnorm.\n",
    "!python train.py \\\n",
    "--exp=1 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000 \\\n",
    "--cache_train=False \\\n",
    "--cache_val=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-30 17:12:55.919619: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-04-30 17:12:55.943301: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199790000 Hz\n",
      "2020-04-30 17:12:55.943618: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56215cdd5960 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-30 17:12:55.943710: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-30 17:12:55.943821: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 20s 0us/step\n",
      "Trainable layers:\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-04-30 17:13:22.697321: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 74s 400ms/step - loss: 2.6009 - accuracy: 0.1216 - categorical_crossentropy: 2.6009 - val_loss: 2.5426 - val_accuracy: 0.1648 - val_categorical_crossentropy: 2.5426\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.4489 - accuracy: 0.2042 - categorical_crossentropy: 2.44892020-04-30 17:15:41.215463: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 74s 404ms/step - loss: 2.4501 - accuracy: 0.2031 - categorical_crossentropy: 2.4501 - val_loss: 2.8778 - val_accuracy: 0.0966 - val_categorical_crossentropy: 2.8778\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.3378 - accuracy: 0.2486 - categorical_crossentropy: 2.33782020-04-30 17:16:49.068167: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 66s 361ms/step - loss: 2.3372 - accuracy: 0.2486 - categorical_crossentropy: 2.3372 - val_loss: 2.5825 - val_accuracy: 0.1420 - val_categorical_crossentropy: 2.5825\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.2787 - accuracy: 0.2589 - categorical_crossentropy: 2.27872020-04-30 17:17:57.010727: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 68s 369ms/step - loss: 2.2799 - accuracy: 0.2582 - categorical_crossentropy: 2.2799 - val_loss: 2.7533 - val_accuracy: 0.1193 - val_categorical_crossentropy: 2.7533\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.2384 - accuracy: 0.2835 - categorical_crossentropy: 2.23842020-04-30 17:19:02.070510: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 66s 358ms/step - loss: 2.2390 - accuracy: 0.2826 - categorical_crossentropy: 2.2390 - val_loss: 2.7745 - val_accuracy: 0.1023 - val_categorical_crossentropy: 2.7745\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.1835 - accuracy: 0.2964 - categorical_crossentropy: 2.18352020-04-30 17:20:08.343369: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 65s 355ms/step - loss: 2.1844 - accuracy: 0.2962 - categorical_crossentropy: 2.1844 - val_loss: 3.0780 - val_accuracy: 0.1477 - val_categorical_crossentropy: 3.0780\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.1795 - accuracy: 0.3142 - categorical_crossentropy: 2.17952020-04-30 17:21:19.597059: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 71s 387ms/step - loss: 2.1798 - accuracy: 0.3139 - categorical_crossentropy: 2.1798 - val_loss: 2.7941 - val_accuracy: 0.1534 - val_categorical_crossentropy: 2.7941\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.1387 - accuracy: 0.3176 - categorical_crossentropy: 2.13872020-04-30 17:22:31.624813: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 73s 395ms/step - loss: 2.1378 - accuracy: 0.3173 - categorical_crossentropy: 2.1378 - val_loss: 2.9973 - val_accuracy: 0.1818 - val_categorical_crossentropy: 2.9973\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.1185 - accuracy: 0.3279 - categorical_crossentropy: 2.11852020-04-30 17:23:40.768251: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 69s 376ms/step - loss: 2.1179 - accuracy: 0.3281 - categorical_crossentropy: 2.1179 - val_loss: 3.0585 - val_accuracy: 0.1250 - val_categorical_crossentropy: 3.0585\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0876 - accuracy: 0.3265 - categorical_crossentropy: 2.08762020-04-30 17:24:54.998647: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 75s 410ms/step - loss: 2.0889 - accuracy: 0.3268 - categorical_crossentropy: 2.0889 - val_loss: 3.0201 - val_accuracy: 0.1648 - val_categorical_crossentropy: 3.0201\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0665 - accuracy: 0.3586 - categorical_crossentropy: 2.06652020-04-30 17:26:05.494488: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 69s 375ms/step - loss: 2.0680 - accuracy: 0.3587 - categorical_crossentropy: 2.0680 - val_loss: 3.0780 - val_accuracy: 0.1875 - val_categorical_crossentropy: 3.0780\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0463 - accuracy: 0.3374 - categorical_crossentropy: 2.04632020-04-30 17:27:09.791169: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 65s 353ms/step - loss: 2.0492 - accuracy: 0.3356 - categorical_crossentropy: 2.0492 - val_loss: 3.1986 - val_accuracy: 0.1364 - val_categorical_crossentropy: 3.1986\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0777 - accuracy: 0.3559 - categorical_crossentropy: 2.07772020-04-30 17:28:22.318019: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 72s 390ms/step - loss: 2.0795 - accuracy: 0.3546 - categorical_crossentropy: 2.0795 - val_loss: 3.3237 - val_accuracy: 0.1591 - val_categorical_crossentropy: 3.3237\n",
      "Epoch 14/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0790 - accuracy: 0.3354 - categorical_crossentropy: 2.07902020-04-30 17:29:31.230192: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 69s 377ms/step - loss: 2.0781 - accuracy: 0.3342 - categorical_crossentropy: 2.0781 - val_loss: 3.5350 - val_accuracy: 0.1705 - val_categorical_crossentropy: 3.5350\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 2.0073 - accuracy: 0.3490 - categorical_crossentropy: 2.00732020-04-30 17:30:39.608007: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 68s 370ms/step - loss: 2.0078 - accuracy: 0.3478 - categorical_crossentropy: 2.0078 - val_loss: 3.4281 - val_accuracy: 0.1477 - val_categorical_crossentropy: 3.4281\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0495 - accuracy: 0.3286 - categorical_crossentropy: 2.04952020-04-30 17:31:58.863827: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 80s 433ms/step - loss: 2.0501 - accuracy: 0.3295 - categorical_crossentropy: 2.0501 - val_loss: 3.3558 - val_accuracy: 0.1534 - val_categorical_crossentropy: 3.3558\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0342 - accuracy: 0.3449 - categorical_crossentropy: 2.03422020-04-30 17:33:08.128903: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 69s 375ms/step - loss: 2.0342 - accuracy: 0.3465 - categorical_crossentropy: 2.0342 - val_loss: 3.5189 - val_accuracy: 0.1989 - val_categorical_crossentropy: 3.5189\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0348 - accuracy: 0.3531 - categorical_crossentropy: 2.03482020-04-30 17:34:19.599680: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 72s 393ms/step - loss: 2.0356 - accuracy: 0.3526 - categorical_crossentropy: 2.0356 - val_loss: 3.3492 - val_accuracy: 0.1534 - val_categorical_crossentropy: 3.3492\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0292 - accuracy: 0.3531 - categorical_crossentropy: 2.02922020-04-30 17:35:37.504461: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 78s 425ms/step - loss: 2.0294 - accuracy: 0.3533 - categorical_crossentropy: 2.0294 - val_loss: 3.4180 - val_accuracy: 0.1193 - val_categorical_crossentropy: 3.4180\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9816 - accuracy: 0.3627 - categorical_crossentropy: 1.98162020-04-30 17:36:48.463800: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 70s 380ms/step - loss: 1.9824 - accuracy: 0.3621 - categorical_crossentropy: 1.9824 - val_loss: 3.5652 - val_accuracy: 0.1534 - val_categorical_crossentropy: 3.5652\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.0027 - accuracy: 0.3579 - categorical_crossentropy: 2.00272020-04-30 17:37:58.687324: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 70s 381ms/step - loss: 2.0063 - accuracy: 0.3580 - categorical_crossentropy: 2.0063 - val_loss: 3.3032 - val_accuracy: 0.1136 - val_categorical_crossentropy: 3.3032\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9475 - accuracy: 0.3600 - categorical_crossentropy: 1.94752020-04-30 17:39:13.166056: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 75s 410ms/step - loss: 1.9455 - accuracy: 0.3614 - categorical_crossentropy: 1.9455 - val_loss: 3.4284 - val_accuracy: 0.1761 - val_categorical_crossentropy: 3.4284\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9685 - accuracy: 0.3784 - categorical_crossentropy: 1.96852020-04-30 17:40:29.515543: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 75s 410ms/step - loss: 1.9695 - accuracy: 0.3777 - categorical_crossentropy: 1.9695 - val_loss: 3.2337 - val_accuracy: 0.1591 - val_categorical_crossentropy: 3.2337\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9483 - accuracy: 0.3818 - categorical_crossentropy: 1.94832020-04-30 17:41:50.484602: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 440ms/step - loss: 1.9486 - accuracy: 0.3818 - categorical_crossentropy: 1.9486 - val_loss: 3.2158 - val_accuracy: 0.1364 - val_categorical_crossentropy: 3.2158\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9367 - accuracy: 0.3832 - categorical_crossentropy: 1.93672020-04-30 17:43:01.258256: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 72s 389ms/step - loss: 1.9353 - accuracy: 0.3838 - categorical_crossentropy: 1.9353 - val_loss: 3.7523 - val_accuracy: 0.1193 - val_categorical_crossentropy: 3.7523\n",
      "Epoch 26/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9674 - accuracy: 0.3818 - categorical_crossentropy: 1.96742020-04-30 17:44:06.189509: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 64s 345ms/step - loss: 1.9681 - accuracy: 0.3811 - categorical_crossentropy: 1.9681 - val_loss: 3.5906 - val_accuracy: 0.1364 - val_categorical_crossentropy: 3.5906\n",
      "Epoch 27/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9601 - accuracy: 0.3695 - categorical_crossentropy: 1.96012020-04-30 17:45:17.490270: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 71s 387ms/step - loss: 1.9603 - accuracy: 0.3689 - categorical_crossentropy: 1.9603 - val_loss: 3.5907 - val_accuracy: 0.1193 - val_categorical_crossentropy: 3.5907\n",
      "2020-04-30 17:45:22.143800: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-04-30 17:45:22.144378: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-04-30 17:45:22.620494: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.627610: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.630805: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.634008: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.637161: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.641573: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.645077: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.648902: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.651696: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.655181: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-30 17:45:22.667451: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.671498: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.675588: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.678767: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.682643: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.686120: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.691553: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.694854: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.698483: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.702469: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.705980: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.711033: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.713781: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.716925: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.720307: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.724778: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 17:45:22.728404: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Da qua in poi ho usato il dataset ridotto e ho fatto varie prove (senza unfreeze batchnorm).\n",
    "!python train.py \\\n",
    "--exp=2 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-30 17:46:39.025656: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-04-30 17:46:39.059332: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199790000 Hz\n",
      "2020-04-30 17:46:39.059979: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bd8176f2a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-30 17:46:39.060006: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-30 17:46:39.060419: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-04-30 17:46:44.344331: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 79s 427ms/step - loss: 2.4896 - accuracy: 0.1753 - categorical_crossentropy: 2.4896 - val_loss: 2.6497 - val_accuracy: 0.1307 - val_categorical_crossentropy: 2.6497\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.2807 - accuracy: 0.2910 - categorical_crossentropy: 2.28072020-04-30 17:48:56.089284: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 61s 331ms/step - loss: 2.2802 - accuracy: 0.2901 - categorical_crossentropy: 2.2802 - val_loss: 2.6362 - val_accuracy: 0.1477 - val_categorical_crossentropy: 2.6362\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.1164 - accuracy: 0.3579 - categorical_crossentropy: 2.11642020-04-30 17:50:01.593665: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 65s 356ms/step - loss: 2.1176 - accuracy: 0.3567 - categorical_crossentropy: 2.1176 - val_loss: 2.6546 - val_accuracy: 0.1818 - val_categorical_crossentropy: 2.6546\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9908 - accuracy: 0.3811 - categorical_crossentropy: 1.99082020-04-30 17:51:11.292488: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 70s 379ms/step - loss: 1.9903 - accuracy: 0.3818 - categorical_crossentropy: 1.9903 - val_loss: 2.7017 - val_accuracy: 0.1648 - val_categorical_crossentropy: 2.7017\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9852 - accuracy: 0.3805 - categorical_crossentropy: 1.98522020-04-30 17:52:14.415875: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 63s 343ms/step - loss: 1.9858 - accuracy: 0.3791 - categorical_crossentropy: 1.9858 - val_loss: 3.0216 - val_accuracy: 0.1136 - val_categorical_crossentropy: 3.0216\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9550 - accuracy: 0.3934 - categorical_crossentropy: 1.95502020-04-30 17:53:17.754936: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 64s 346ms/step - loss: 1.9541 - accuracy: 0.3933 - categorical_crossentropy: 1.9541 - val_loss: 2.8129 - val_accuracy: 0.1932 - val_categorical_crossentropy: 2.8129\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8683 - accuracy: 0.4153 - categorical_crossentropy: 1.86832020-04-30 17:54:21.156355: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 63s 341ms/step - loss: 1.8679 - accuracy: 0.4151 - categorical_crossentropy: 1.8679 - val_loss: 3.1456 - val_accuracy: 0.1534 - val_categorical_crossentropy: 3.1456\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8354 - accuracy: 0.4385 - categorical_crossentropy: 1.83542020-04-30 17:55:27.325411: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 66s 360ms/step - loss: 1.8343 - accuracy: 0.4395 - categorical_crossentropy: 1.8343 - val_loss: 3.5741 - val_accuracy: 0.1080 - val_categorical_crossentropy: 3.5741\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8168 - accuracy: 0.4317 - categorical_crossentropy: 1.81682020-04-30 17:56:33.689064: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 67s 366ms/step - loss: 1.8141 - accuracy: 0.4321 - categorical_crossentropy: 1.8141 - val_loss: 3.1131 - val_accuracy: 0.1534 - val_categorical_crossentropy: 3.1131\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8175 - accuracy: 0.4385 - categorical_crossentropy: 1.81752020-04-30 17:57:47.675547: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 73s 396ms/step - loss: 1.8201 - accuracy: 0.4368 - categorical_crossentropy: 1.8201 - val_loss: 3.0564 - val_accuracy: 0.1364 - val_categorical_crossentropy: 3.0564\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7857 - accuracy: 0.4351 - categorical_crossentropy: 1.78572020-04-30 17:58:49.586565: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 62s 339ms/step - loss: 1.7893 - accuracy: 0.4341 - categorical_crossentropy: 1.7893 - val_loss: 3.4810 - val_accuracy: 0.1193 - val_categorical_crossentropy: 3.4810\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8074 - accuracy: 0.4358 - categorical_crossentropy: 1.80742020-04-30 17:59:50.900858: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 62s 335ms/step - loss: 1.8051 - accuracy: 0.4368 - categorical_crossentropy: 1.8051 - val_loss: 3.6933 - val_accuracy: 0.1307 - val_categorical_crossentropy: 3.6933\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7609 - accuracy: 0.4426 - categorical_crossentropy: 1.76092020-04-30 18:00:58.048298: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 67s 362ms/step - loss: 1.7594 - accuracy: 0.4416 - categorical_crossentropy: 1.7594 - val_loss: 3.3446 - val_accuracy: 0.1591 - val_categorical_crossentropy: 3.3446\n",
      "Epoch 14/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7370 - accuracy: 0.4563 - categorical_crossentropy: 1.73702020-04-30 18:02:07.667605: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 70s 380ms/step - loss: 1.7380 - accuracy: 0.4565 - categorical_crossentropy: 1.7380 - val_loss: 3.4829 - val_accuracy: 0.1477 - val_categorical_crossentropy: 3.4829\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7323 - accuracy: 0.4624 - categorical_crossentropy: 1.73232020-04-30 18:03:15.411343: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 69s 373ms/step - loss: 1.7321 - accuracy: 0.4620 - categorical_crossentropy: 1.7321 - val_loss: 3.4060 - val_accuracy: 0.1705 - val_categorical_crossentropy: 3.4060\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6594 - accuracy: 0.4945 - categorical_crossentropy: 1.65942020-04-30 18:04:29.557191: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 73s 397ms/step - loss: 1.6572 - accuracy: 0.4946 - categorical_crossentropy: 1.6572 - val_loss: 3.3573 - val_accuracy: 0.1818 - val_categorical_crossentropy: 3.3573\n",
      "2020-04-30 18:04:34.742594: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-04-30 18:04:34.743033: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-04-30 18:04:35.226489: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.229506: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.232697: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.235354: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.239444: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.242707: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.245924: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.250596: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.253885: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.256963: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.266669: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.269660: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.273012: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.278988: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.282035: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 18:04:35.284478: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Ho provato senza data augmentation ma è aumentato l'overfitting.\n",
    "!python train.py \\\n",
    "--exp=3 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000 \\\n",
    "--random_flip=False \\\n",
    "--random_hue=False \\\n",
    "--random_saturation=False \\\n",
    "--random_contrast=False \\\n",
    "--random_brightness=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-30 18:05:32.735607: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-04-30 18:05:32.763279: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199790000 Hz\n",
      "2020-04-30 18:05:32.763549: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55abbecdd5e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-30 18:05:32.763568: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-30 18:05:32.763657: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-04-30 18:05:39.619454: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 314s 2s/step - loss: 2.5929 - accuracy: 0.1304 - categorical_crossentropy: 2.5929 - val_loss: 2.6309 - val_accuracy: 0.0909 - val_categorical_crossentropy: 2.6309\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 2.3910 - accuracy: 0.2172 - categorical_crossentropy: 2.39102020-04-30 18:15:46.720185: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 323s 2s/step - loss: 2.3907 - accuracy: 0.2167 - categorical_crossentropy: 2.3907 - val_loss: 2.5762 - val_accuracy: 0.1250 - val_categorical_crossentropy: 2.5762\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 2.3231 - accuracy: 0.2575 - categorical_crossentropy: 2.32312020-04-30 18:21:16.457872: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 330s 2s/step - loss: 2.3222 - accuracy: 0.2588 - categorical_crossentropy: 2.3222 - val_loss: 2.6798 - val_accuracy: 0.1250 - val_categorical_crossentropy: 2.6798\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 2.1705 - accuracy: 0.3142 - categorical_crossentropy: 2.17052020-04-30 18:27:00.793447: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 345s 2s/step - loss: 2.1709 - accuracy: 0.3132 - categorical_crossentropy: 2.1709 - val_loss: 2.5897 - val_accuracy: 0.1250 - val_categorical_crossentropy: 2.5897\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 2.1176 - accuracy: 0.3210 - categorical_crossentropy: 2.11762020-04-30 18:32:38.643825: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 337s 2s/step - loss: 2.1151 - accuracy: 0.3220 - categorical_crossentropy: 2.1151 - val_loss: 2.6782 - val_accuracy: 0.1761 - val_categorical_crossentropy: 2.6782\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 2.1108 - accuracy: 0.3169 - categorical_crossentropy: 2.11082020-04-30 18:37:51.719886: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 313s 2s/step - loss: 2.1115 - accuracy: 0.3173 - categorical_crossentropy: 2.1115 - val_loss: 2.8802 - val_accuracy: 0.1705 - val_categorical_crossentropy: 2.8802\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 2.0068 - accuracy: 0.3422 - categorical_crossentropy: 2.00682020-04-30 18:43:03.700728: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 312s 2s/step - loss: 2.0063 - accuracy: 0.3424 - categorical_crossentropy: 2.0063 - val_loss: 2.9601 - val_accuracy: 0.1080 - val_categorical_crossentropy: 2.9601\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 2.0127 - accuracy: 0.3436 - categorical_crossentropy: 2.01272020-04-30 18:50:17.602785: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 451s 2s/step - loss: 2.0143 - accuracy: 0.3431 - categorical_crossentropy: 2.0143 - val_loss: 2.5472 - val_accuracy: 0.1875 - val_categorical_crossentropy: 2.5472\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 1.9882 - accuracy: 0.3572 - categorical_crossentropy: 1.98822020-04-30 18:57:18.838402: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 405s 2s/step - loss: 1.9861 - accuracy: 0.3580 - categorical_crossentropy: 1.9861 - val_loss: 2.5476 - val_accuracy: 0.1591 - val_categorical_crossentropy: 2.5476\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.9354 - accuracy: 0.3866 - categorical_crossentropy: 1.93542020-04-30 19:02:33.351863: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 314s 2s/step - loss: 1.9342 - accuracy: 0.3872 - categorical_crossentropy: 1.9342 - val_loss: 2.8218 - val_accuracy: 0.1477 - val_categorical_crossentropy: 2.8218\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.9124 - accuracy: 0.4044 - categorical_crossentropy: 1.91242020-04-30 19:08:05.589390: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 333s 2s/step - loss: 1.9159 - accuracy: 0.4035 - categorical_crossentropy: 1.9159 - val_loss: 2.8382 - val_accuracy: 0.1534 - val_categorical_crossentropy: 2.8382\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.8635 - accuracy: 0.3982 - categorical_crossentropy: 1.86352020-04-30 19:13:34.778990: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 328s 2s/step - loss: 1.8650 - accuracy: 0.3974 - categorical_crossentropy: 1.8650 - val_loss: 2.6259 - val_accuracy: 0.1875 - val_categorical_crossentropy: 2.6259\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.9027 - accuracy: 0.3969 - categorical_crossentropy: 1.90272020-04-30 19:19:06.116092: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 331s 2s/step - loss: 1.9010 - accuracy: 0.3981 - categorical_crossentropy: 1.9010 - val_loss: 2.9251 - val_accuracy: 0.0909 - val_categorical_crossentropy: 2.9251\n",
      "Epoch 14/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.8591 - accuracy: 0.4119 - categorical_crossentropy: 1.85912020-04-30 19:24:23.667518: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 318s 2s/step - loss: 1.8596 - accuracy: 0.4124 - categorical_crossentropy: 1.8596 - val_loss: 2.9293 - val_accuracy: 0.1477 - val_categorical_crossentropy: 2.9293\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.8619 - accuracy: 0.3866 - categorical_crossentropy: 1.86192020-04-30 19:29:51.833638: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 328s 2s/step - loss: 1.8625 - accuracy: 0.3859 - categorical_crossentropy: 1.8625 - val_loss: 3.0461 - val_accuracy: 0.1477 - val_categorical_crossentropy: 3.0461\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.8613 - accuracy: 0.3989 - categorical_crossentropy: 1.86132020-04-30 19:35:09.757514: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 318s 2s/step - loss: 1.8582 - accuracy: 0.4001 - categorical_crossentropy: 1.8582 - val_loss: 2.8132 - val_accuracy: 0.1761 - val_categorical_crossentropy: 2.8132\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.8040 - accuracy: 0.4173 - categorical_crossentropy: 1.80402020-04-30 19:40:27.598433: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 318s 2s/step - loss: 1.8038 - accuracy: 0.4171 - categorical_crossentropy: 1.8038 - val_loss: 3.0858 - val_accuracy: 0.1989 - val_categorical_crossentropy: 3.0858\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.8795 - accuracy: 0.3996 - categorical_crossentropy: 1.87952020-04-30 19:45:47.212426: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 320s 2s/step - loss: 1.8828 - accuracy: 0.3981 - categorical_crossentropy: 1.8828 - val_loss: 3.0339 - val_accuracy: 0.1307 - val_categorical_crossentropy: 3.0339\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7751 - accuracy: 0.4153 - categorical_crossentropy: 1.77512020-04-30 19:51:02.843661: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 316s 2s/step - loss: 1.7728 - accuracy: 0.4164 - categorical_crossentropy: 1.7728 - val_loss: 2.5727 - val_accuracy: 0.1705 - val_categorical_crossentropy: 2.5727\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7567 - accuracy: 0.4399 - categorical_crossentropy: 1.75672020-04-30 19:56:20.714727: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 318s 2s/step - loss: 1.7574 - accuracy: 0.4395 - categorical_crossentropy: 1.7574 - val_loss: 2.8315 - val_accuracy: 0.1989 - val_categorical_crossentropy: 2.8315\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7615 - accuracy: 0.4344 - categorical_crossentropy: 1.76152020-04-30 20:01:43.744358: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 323s 2s/step - loss: 1.7580 - accuracy: 0.4355 - categorical_crossentropy: 1.7580 - val_loss: 2.7219 - val_accuracy: 0.1932 - val_categorical_crossentropy: 2.7219\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7325 - accuracy: 0.4358 - categorical_crossentropy: 1.73252020-04-30 20:07:34.328994: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 357s 2s/step - loss: 1.7326 - accuracy: 0.4361 - categorical_crossentropy: 1.7326 - val_loss: 2.9582 - val_accuracy: 0.1648 - val_categorical_crossentropy: 2.9582\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7273 - accuracy: 0.4481 - categorical_crossentropy: 1.72732020-04-30 20:13:54.552468: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 375s 2s/step - loss: 1.7271 - accuracy: 0.4484 - categorical_crossentropy: 1.7271 - val_loss: 2.9245 - val_accuracy: 0.1534 - val_categorical_crossentropy: 2.9245\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7035 - accuracy: 0.4495 - categorical_crossentropy: 1.70352020-04-30 20:19:24.765419: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 330s 2s/step - loss: 1.7021 - accuracy: 0.4490 - categorical_crossentropy: 1.7021 - val_loss: 2.9019 - val_accuracy: 0.1250 - val_categorical_crossentropy: 2.9019\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7483 - accuracy: 0.4337 - categorical_crossentropy: 1.74832020-04-30 20:24:53.749308: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 331s 2s/step - loss: 1.7488 - accuracy: 0.4334 - categorical_crossentropy: 1.7488 - val_loss: 3.2691 - val_accuracy: 0.1705 - val_categorical_crossentropy: 3.2691\n",
      "Epoch 26/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.6943 - accuracy: 0.4529 - categorical_crossentropy: 1.69432020-04-30 20:30:20.750015: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 325s 2s/step - loss: 1.6935 - accuracy: 0.4524 - categorical_crossentropy: 1.6935 - val_loss: 3.0405 - val_accuracy: 0.1534 - val_categorical_crossentropy: 3.0405\n",
      "Epoch 27/1000\n",
      "183/184 [============================>.] - ETA: 1s - loss: 1.7050 - accuracy: 0.4447 - categorical_crossentropy: 1.70502020-04-30 20:35:44.454940: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 323s 2s/step - loss: 1.7040 - accuracy: 0.4443 - categorical_crossentropy: 1.7040 - val_loss: 2.9027 - val_accuracy: 0.1932 - val_categorical_crossentropy: 2.9027\n",
      "2020-04-30 20:36:10.544809: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-04-30 20:36:10.545400: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-04-30 20:36:11.021052: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.023876: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.026673: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.029283: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.031909: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.035619: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.039572: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.042844: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.045312: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.047839: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-04-30 20:36:11.056312: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-30 20:36:11.059210: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.063000: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.065407: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.068289: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.071327: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.073598: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.076025: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.078619: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.082507: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.084740: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.088910: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.091574: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.094050: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.096373: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.098927: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-04-30 20:36:11.101166: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n"
     ]
    }
   ],
   "source": [
    "# Proviamo con la dimensione fissa, risultati leggermente migliori.\n",
    "!python train.py \\\n",
    "--exp=4 \\\n",
    "--size=299 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-01 09:40:55.845672: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-01 09:40:55.868843: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200090000 Hz\n",
      "2020-05-01 09:40:55.869184: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aa45e79800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-01 09:40:55.869210: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-01 09:40:55.869325: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block14_sepconv2\n",
      "block14_sepconv2_bn\n",
      "block14_sepconv2_act\n",
      "global_average_pooling2d\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-01 09:41:01.714499: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 89s 486ms/step - loss: 2.3899 - accuracy: 0.2527 - categorical_crossentropy: 2.3899 - val_loss: 5.9552 - val_accuracy: 0.1080 - val_categorical_crossentropy: 5.9552\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9675 - accuracy: 0.3456 - categorical_crossentropy: 1.96752020-05-01 09:43:42.634552: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 439ms/step - loss: 1.9669 - accuracy: 0.3451 - categorical_crossentropy: 1.9669 - val_loss: 5.6519 - val_accuracy: 0.1193 - val_categorical_crossentropy: 5.6519\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8374 - accuracy: 0.3921 - categorical_crossentropy: 1.83742020-05-01 09:45:01.920685: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 78s 426ms/step - loss: 1.8369 - accuracy: 0.3927 - categorical_crossentropy: 1.8369 - val_loss: 6.2486 - val_accuracy: 0.1307 - val_categorical_crossentropy: 6.2486\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7658 - accuracy: 0.4187 - categorical_crossentropy: 1.76582020-05-01 09:46:21.080975: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 79s 430ms/step - loss: 1.7709 - accuracy: 0.4171 - categorical_crossentropy: 1.7709 - val_loss: 6.9091 - val_accuracy: 0.1307 - val_categorical_crossentropy: 6.9091\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6972 - accuracy: 0.4283 - categorical_crossentropy: 1.69722020-05-01 09:47:41.932559: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 438ms/step - loss: 1.6964 - accuracy: 0.4287 - categorical_crossentropy: 1.6964 - val_loss: 6.5268 - val_accuracy: 0.1136 - val_categorical_crossentropy: 6.5268\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6489 - accuracy: 0.4686 - categorical_crossentropy: 1.64892020-05-01 09:48:57.867740: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 77s 418ms/step - loss: 1.6543 - accuracy: 0.4660 - categorical_crossentropy: 1.6543 - val_loss: 5.1818 - val_accuracy: 0.1705 - val_categorical_crossentropy: 5.1818\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6391 - accuracy: 0.4447 - categorical_crossentropy: 1.63912020-05-01 09:50:19.654959: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 441ms/step - loss: 1.6376 - accuracy: 0.4463 - categorical_crossentropy: 1.6376 - val_loss: 7.9445 - val_accuracy: 0.0795 - val_categorical_crossentropy: 7.9445\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6062 - accuracy: 0.4652 - categorical_crossentropy: 1.60622020-05-01 09:51:41.886301: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 82s 446ms/step - loss: 1.6083 - accuracy: 0.4647 - categorical_crossentropy: 1.6083 - val_loss: 5.9199 - val_accuracy: 0.0909 - val_categorical_crossentropy: 5.9199\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6006 - accuracy: 0.4802 - categorical_crossentropy: 1.60062020-05-01 09:53:02.705517: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 442ms/step - loss: 1.6018 - accuracy: 0.4789 - categorical_crossentropy: 1.6018 - val_loss: 6.1704 - val_accuracy: 0.0795 - val_categorical_crossentropy: 6.1704\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.5049 - accuracy: 0.4939 - categorical_crossentropy: 1.50492020-05-01 09:54:21.062640: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 78s 421ms/step - loss: 1.5034 - accuracy: 0.4939 - categorical_crossentropy: 1.5034 - val_loss: 5.0346 - val_accuracy: 0.1307 - val_categorical_crossentropy: 5.0346\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4672 - accuracy: 0.5102 - categorical_crossentropy: 1.46722020-05-01 09:55:37.473085: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 77s 416ms/step - loss: 1.4644 - accuracy: 0.5115 - categorical_crossentropy: 1.4644 - val_loss: 6.0157 - val_accuracy: 0.1193 - val_categorical_crossentropy: 6.0157\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4756 - accuracy: 0.5007 - categorical_crossentropy: 1.47562020-05-01 09:56:59.928051: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 83s 449ms/step - loss: 1.4729 - accuracy: 0.5014 - categorical_crossentropy: 1.4729 - val_loss: 5.4723 - val_accuracy: 0.1136 - val_categorical_crossentropy: 5.4723\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4656 - accuracy: 0.5171 - categorical_crossentropy: 1.46562020-05-01 09:58:20.922158: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 442ms/step - loss: 1.4638 - accuracy: 0.5170 - categorical_crossentropy: 1.4638 - val_loss: 6.4379 - val_accuracy: 0.1023 - val_categorical_crossentropy: 6.4379\n",
      "Epoch 14/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4295 - accuracy: 0.5000 - categorical_crossentropy: 1.42952020-05-01 09:59:42.120597: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 81s 441ms/step - loss: 1.4323 - accuracy: 0.4993 - categorical_crossentropy: 1.4323 - val_loss: 5.4126 - val_accuracy: 0.1420 - val_categorical_crossentropy: 5.4126\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4153 - accuracy: 0.5307 - categorical_crossentropy: 1.41532020-05-01 10:01:04.008815: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 82s 446ms/step - loss: 1.4175 - accuracy: 0.5306 - categorical_crossentropy: 1.4175 - val_loss: 5.5739 - val_accuracy: 0.1420 - val_categorical_crossentropy: 5.5739\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4171 - accuracy: 0.5273 - categorical_crossentropy: 1.41712020-05-01 10:02:22.169058: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 78s 424ms/step - loss: 1.4177 - accuracy: 0.5272 - categorical_crossentropy: 1.4177 - val_loss: 4.6474 - val_accuracy: 0.1591 - val_categorical_crossentropy: 4.6474\n",
      "2020-05-01 10:02:27.463093: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-01 10:02:27.464706: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-01 10:02:27.934164: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.939460: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.943298: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.947268: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.951664: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.957556: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.960898: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.966737: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.970240: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.973755: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.989045: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.996031: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:27.999865: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:28.003623: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:28.007078: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:02:28.011288: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Proviamo a riaddestrare anche il penultimo layer. Sul training migliora ma sul validation no.\n",
    "!python train.py \\\n",
    "--exp=5 \\\n",
    "--weights=\"checkpoints/exp2/best_weights.ckpt\" \\\n",
    "--trainable_layers=5 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-01 10:07:48.857835: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-01 10:07:48.884725: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200090000 Hz\n",
      "2020-05-01 10:07:48.885024: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5619d6905800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-01 10:07:48.885050: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-01 10:07:48.885173: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block14_sepconv1\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv1_act\n",
      "block14_sepconv2\n",
      "block14_sepconv2_bn\n",
      "block14_sepconv2_act\n",
      "global_average_pooling2d\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-01 10:07:55.353607: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 87s 475ms/step - loss: 2.2046 - accuracy: 0.2887 - categorical_crossentropy: 2.2046 - val_loss: 8.1723 - val_accuracy: 0.1477 - val_categorical_crossentropy: 8.1723\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.8012 - accuracy: 0.4290 - categorical_crossentropy: 1.80122020-05-01 10:10:42.591390: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 480ms/step - loss: 1.8022 - accuracy: 0.4287 - categorical_crossentropy: 1.8022 - val_loss: 6.1380 - val_accuracy: 0.1193 - val_categorical_crossentropy: 6.1380\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6019 - accuracy: 0.4556 - categorical_crossentropy: 1.60192020-05-01 10:12:09.686654: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 477ms/step - loss: 1.6011 - accuracy: 0.4558 - categorical_crossentropy: 1.6011 - val_loss: 6.0240 - val_accuracy: 0.1080 - val_categorical_crossentropy: 6.0240\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4405 - accuracy: 0.5157 - categorical_crossentropy: 1.44052020-05-01 10:13:45.807175: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 523ms/step - loss: 1.4400 - accuracy: 0.5163 - categorical_crossentropy: 1.4400 - val_loss: 5.5125 - val_accuracy: 0.1080 - val_categorical_crossentropy: 5.5125\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.3596 - accuracy: 0.5512 - categorical_crossentropy: 1.35962020-05-01 10:15:15.069539: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 483ms/step - loss: 1.3598 - accuracy: 0.5496 - categorical_crossentropy: 1.3598 - val_loss: 6.6608 - val_accuracy: 0.1420 - val_categorical_crossentropy: 6.6608\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.2422 - accuracy: 0.5786 - categorical_crossentropy: 1.24222020-05-01 10:16:40.419611: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 86s 467ms/step - loss: 1.2402 - accuracy: 0.5802 - categorical_crossentropy: 1.2402 - val_loss: 4.0777 - val_accuracy: 0.1648 - val_categorical_crossentropy: 4.0777\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.2565 - accuracy: 0.5786 - categorical_crossentropy: 1.25652020-05-01 10:18:09.274596: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 481ms/step - loss: 1.2619 - accuracy: 0.5781 - categorical_crossentropy: 1.2619 - val_loss: 4.8929 - val_accuracy: 0.1193 - val_categorical_crossentropy: 4.8929\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.1292 - accuracy: 0.6189 - categorical_crossentropy: 1.12922020-05-01 10:19:48.637833: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 101s 549ms/step - loss: 1.1297 - accuracy: 0.6182 - categorical_crossentropy: 1.1297 - val_loss: 6.2386 - val_accuracy: 0.0739 - val_categorical_crossentropy: 6.2386\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0524 - accuracy: 0.6667 - categorical_crossentropy: 1.05242020-05-01 10:21:34.796527: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 104s 567ms/step - loss: 1.0514 - accuracy: 0.6671 - categorical_crossentropy: 1.0514 - val_loss: 7.3997 - val_accuracy: 0.0966 - val_categorical_crossentropy: 7.3997\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0808 - accuracy: 0.6387 - categorical_crossentropy: 1.08082020-05-01 10:23:58.779772: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 151s 819ms/step - loss: 1.0806 - accuracy: 0.6379 - categorical_crossentropy: 1.0806 - val_loss: 7.1974 - val_accuracy: 0.1193 - val_categorical_crossentropy: 7.1974\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0198 - accuracy: 0.6537 - categorical_crossentropy: 1.01982020-05-01 10:25:44.034713: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 99s 535ms/step - loss: 1.0217 - accuracy: 0.6529 - categorical_crossentropy: 1.0217 - val_loss: 3.9079 - val_accuracy: 0.1591 - val_categorical_crossentropy: 3.9079\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9843 - accuracy: 0.6708 - categorical_crossentropy: 0.98432020-05-01 10:27:13.256279: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 484ms/step - loss: 0.9825 - accuracy: 0.6705 - categorical_crossentropy: 0.9825 - val_loss: 4.1246 - val_accuracy: 0.1534 - val_categorical_crossentropy: 4.1246\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9626 - accuracy: 0.6660 - categorical_crossentropy: 0.96262020-05-01 10:28:41.528178: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 483ms/step - loss: 0.9612 - accuracy: 0.6664 - categorical_crossentropy: 0.9612 - val_loss: 3.8742 - val_accuracy: 0.1989 - val_categorical_crossentropy: 3.8742\n",
      "Epoch 14/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9422 - accuracy: 0.6796 - categorical_crossentropy: 0.94222020-05-01 10:30:05.327114: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 84s 456ms/step - loss: 0.9401 - accuracy: 0.6807 - categorical_crossentropy: 0.9401 - val_loss: 4.9692 - val_accuracy: 0.0966 - val_categorical_crossentropy: 4.9692\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9408 - accuracy: 0.6755 - categorical_crossentropy: 0.94082020-05-01 10:31:33.036824: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 478ms/step - loss: 0.9437 - accuracy: 0.6732 - categorical_crossentropy: 0.9437 - val_loss: 3.9914 - val_accuracy: 0.2330 - val_categorical_crossentropy: 3.9914\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8920 - accuracy: 0.6967 - categorical_crossentropy: 0.89202020-05-01 10:33:01.827921: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 481ms/step - loss: 0.8926 - accuracy: 0.6963 - categorical_crossentropy: 0.8926 - val_loss: 4.6255 - val_accuracy: 0.1705 - val_categorical_crossentropy: 4.6255\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8600 - accuracy: 0.7111 - categorical_crossentropy: 0.86002020-05-01 10:34:26.395430: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 84s 458ms/step - loss: 0.8594 - accuracy: 0.7113 - categorical_crossentropy: 0.8594 - val_loss: 4.7223 - val_accuracy: 0.1193 - val_categorical_crossentropy: 4.7223\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8433 - accuracy: 0.7206 - categorical_crossentropy: 0.84332020-05-01 10:35:49.654354: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 83s 450ms/step - loss: 0.8450 - accuracy: 0.7194 - categorical_crossentropy: 0.8450 - val_loss: 4.4745 - val_accuracy: 0.1477 - val_categorical_crossentropy: 4.4745\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8650 - accuracy: 0.7124 - categorical_crossentropy: 0.86502020-05-01 10:37:18.151319: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 481ms/step - loss: 0.8611 - accuracy: 0.7140 - categorical_crossentropy: 0.8611 - val_loss: 4.2204 - val_accuracy: 0.1932 - val_categorical_crossentropy: 4.2204\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8396 - accuracy: 0.7117 - categorical_crossentropy: 0.83962020-05-01 10:38:45.717170: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 477ms/step - loss: 0.8392 - accuracy: 0.7120 - categorical_crossentropy: 0.8392 - val_loss: 5.3249 - val_accuracy: 0.1591 - val_categorical_crossentropy: 5.3249\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7831 - accuracy: 0.7391 - categorical_crossentropy: 0.78312020-05-01 10:40:11.024881: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 85s 463ms/step - loss: 0.7843 - accuracy: 0.7385 - categorical_crossentropy: 0.7843 - val_loss: 3.9600 - val_accuracy: 0.1477 - val_categorical_crossentropy: 3.9600\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8225 - accuracy: 0.7220 - categorical_crossentropy: 0.82252020-05-01 10:41:37.287886: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 86s 469ms/step - loss: 0.8232 - accuracy: 0.7221 - categorical_crossentropy: 0.8232 - val_loss: 4.3810 - val_accuracy: 0.1364 - val_categorical_crossentropy: 4.3810\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7480 - accuracy: 0.7384 - categorical_crossentropy: 0.74802020-05-01 10:43:05.784018: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 482ms/step - loss: 0.7513 - accuracy: 0.7378 - categorical_crossentropy: 0.7513 - val_loss: 6.1971 - val_accuracy: 0.1364 - val_categorical_crossentropy: 6.1971\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7804 - accuracy: 0.7336 - categorical_crossentropy: 0.78042020-05-01 10:44:30.677982: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 85s 460ms/step - loss: 0.7794 - accuracy: 0.7337 - categorical_crossentropy: 0.7794 - val_loss: 5.8262 - val_accuracy: 0.1591 - val_categorical_crossentropy: 5.8262\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7400 - accuracy: 0.7582 - categorical_crossentropy: 0.74002020-05-01 10:45:58.336311: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 476ms/step - loss: 0.7394 - accuracy: 0.7588 - categorical_crossentropy: 0.7394 - val_loss: 5.1596 - val_accuracy: 0.1364 - val_categorical_crossentropy: 5.1596\n",
      "2020-05-01 10:46:03.318088: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-01 10:46:03.319592: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-01 10:46:03.820540: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.825883: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.829358: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.832323: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.836147: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.839984: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.844025: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.848276: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.851336: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.860165: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-01 10:46:03.864382: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.868817: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.874671: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.880253: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.883511: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.888930: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.892274: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.896059: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.899521: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.904781: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.908445: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.911921: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.916071: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.919861: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-01 10:46:03.922836: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Proviamo a riaddestrare anche il terzultimo layer. Sul training migliora ancora ma sul validation no.\n",
    "!python train.py \\\n",
    "--exp=6 \\\n",
    "--weights=\"checkpoints/exp5/best_weights.ckpt\" \\\n",
    "--trainable_layers=8 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 17:45:07.068741: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-03 17:45:07.104777: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200035000 Hz\n",
      "2020-05-03 17:45:07.105447: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55845970e810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-03 17:45:07.105477: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-03 17:45:07.106661: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-03 17:45:20.174958: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 105s 572ms/step - loss: 2.5501 - accuracy: 0.1508 - categorical_crossentropy: 2.5501 - val_loss: 2.3871 - val_accuracy: 0.2045 - val_categorical_crossentropy: 2.3871\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.2250 - accuracy: 0.2691 - categorical_crossentropy: 2.22502020-05-03 17:48:26.410174: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 95s 516ms/step - loss: 2.2238 - accuracy: 0.2697 - categorical_crossentropy: 2.2238 - val_loss: 2.0416 - val_accuracy: 0.3409 - val_categorical_crossentropy: 2.0416\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9130 - accuracy: 0.3709 - categorical_crossentropy: 1.91302020-05-03 17:50:02.122855: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 523ms/step - loss: 1.9125 - accuracy: 0.3702 - categorical_crossentropy: 1.9125 - val_loss: 1.7609 - val_accuracy: 0.4489 - val_categorical_crossentropy: 1.7609\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7102 - accuracy: 0.4310 - categorical_crossentropy: 1.71022020-05-03 17:51:44.132286: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 102s 552ms/step - loss: 1.7068 - accuracy: 0.4321 - categorical_crossentropy: 1.7068 - val_loss: 1.5048 - val_accuracy: 0.5341 - val_categorical_crossentropy: 1.5048\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.5174 - accuracy: 0.4966 - categorical_crossentropy: 1.51742020-05-03 17:53:21.131385: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 530ms/step - loss: 1.5165 - accuracy: 0.4973 - categorical_crossentropy: 1.5165 - val_loss: 1.3383 - val_accuracy: 0.5284 - val_categorical_crossentropy: 1.3383\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.3642 - accuracy: 0.5266 - categorical_crossentropy: 1.36422020-05-03 17:54:57.951630: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 525ms/step - loss: 1.3627 - accuracy: 0.5258 - categorical_crossentropy: 1.3627 - val_loss: 1.1677 - val_accuracy: 0.6136 - val_categorical_crossentropy: 1.1677\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.2317 - accuracy: 0.5840 - categorical_crossentropy: 1.23172020-05-03 17:56:34.010213: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 520ms/step - loss: 1.2329 - accuracy: 0.5822 - categorical_crossentropy: 1.2329 - val_loss: 1.2043 - val_accuracy: 0.5909 - val_categorical_crossentropy: 1.2043\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.1147 - accuracy: 0.6366 - categorical_crossentropy: 1.11472020-05-03 17:58:10.743580: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 528ms/step - loss: 1.1188 - accuracy: 0.6359 - categorical_crossentropy: 1.1188 - val_loss: 0.8774 - val_accuracy: 0.7557 - val_categorical_crossentropy: 0.8774\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0740 - accuracy: 0.6523 - categorical_crossentropy: 1.07402020-05-03 17:59:45.040192: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 511ms/step - loss: 1.0723 - accuracy: 0.6529 - categorical_crossentropy: 1.0723 - val_loss: 0.7549 - val_accuracy: 0.7557 - val_categorical_crossentropy: 0.7549\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8897 - accuracy: 0.7077 - categorical_crossentropy: 0.88972020-05-03 18:01:13.709321: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 482ms/step - loss: 0.8904 - accuracy: 0.7072 - categorical_crossentropy: 0.8904 - val_loss: 0.8202 - val_accuracy: 0.7216 - val_categorical_crossentropy: 0.8202\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9194 - accuracy: 0.6913 - categorical_crossentropy: 0.91942020-05-03 18:02:50.249566: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 525ms/step - loss: 0.9168 - accuracy: 0.6923 - categorical_crossentropy: 0.9168 - val_loss: 0.7064 - val_accuracy: 0.7727 - val_categorical_crossentropy: 0.7064\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8613 - accuracy: 0.7042 - categorical_crossentropy: 0.86132020-05-03 18:04:22.546770: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 502ms/step - loss: 0.8615 - accuracy: 0.7045 - categorical_crossentropy: 0.8615 - val_loss: 0.6271 - val_accuracy: 0.7955 - val_categorical_crossentropy: 0.6271\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7765 - accuracy: 0.7432 - categorical_crossentropy: 0.77652020-05-03 18:05:50.671897: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 478ms/step - loss: 0.7782 - accuracy: 0.7432 - categorical_crossentropy: 0.7782 - val_loss: 0.6307 - val_accuracy: 0.7955 - val_categorical_crossentropy: 0.6307\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.7158 - accuracy: 0.7500 - categorical_crossentropy: 0.71582020-05-03 18:07:22.858246: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 503ms/step - loss: 0.7163 - accuracy: 0.7493 - categorical_crossentropy: 0.7163 - val_loss: 0.7495 - val_accuracy: 0.7330 - val_categorical_crossentropy: 0.7495\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.6628 - accuracy: 0.7780 - categorical_crossentropy: 0.66282020-05-03 18:08:51.030704: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 88s 480ms/step - loss: 0.6631 - accuracy: 0.7785 - categorical_crossentropy: 0.6631 - val_loss: 0.4969 - val_accuracy: 0.8125 - val_categorical_crossentropy: 0.4969\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.6033 - accuracy: 0.7923 - categorical_crossentropy: 0.60332020-05-03 18:10:22.345390: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 91s 497ms/step - loss: 0.6043 - accuracy: 0.7914 - categorical_crossentropy: 0.6043 - val_loss: 0.4972 - val_accuracy: 0.8182 - val_categorical_crossentropy: 0.4972\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5880 - accuracy: 0.7930 - categorical_crossentropy: 0.58802020-05-03 18:11:52.367577: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 90s 487ms/step - loss: 0.5858 - accuracy: 0.7935 - categorical_crossentropy: 0.5858 - val_loss: 0.5101 - val_accuracy: 0.8352 - val_categorical_crossentropy: 0.5101\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5757 - accuracy: 0.8087 - categorical_crossentropy: 0.57572020-05-03 18:13:27.812718: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 519ms/step - loss: 0.5842 - accuracy: 0.8071 - categorical_crossentropy: 0.5842 - val_loss: 0.3624 - val_accuracy: 0.8750 - val_categorical_crossentropy: 0.3624\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5101 - accuracy: 0.8204 - categorical_crossentropy: 0.51012020-05-03 18:15:01.757073: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 511ms/step - loss: 0.5086 - accuracy: 0.8207 - categorical_crossentropy: 0.5086 - val_loss: 0.4444 - val_accuracy: 0.8182 - val_categorical_crossentropy: 0.4444\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5347 - accuracy: 0.8210 - categorical_crossentropy: 0.53472020-05-03 18:16:31.032058: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 484ms/step - loss: 0.5326 - accuracy: 0.8220 - categorical_crossentropy: 0.5326 - val_loss: 0.3601 - val_accuracy: 0.8693 - val_categorical_crossentropy: 0.3601\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4938 - accuracy: 0.8306 - categorical_crossentropy: 0.49382020-05-03 18:18:03.967800: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 505ms/step - loss: 0.4948 - accuracy: 0.8295 - categorical_crossentropy: 0.4948 - val_loss: 0.4233 - val_accuracy: 0.8409 - val_categorical_crossentropy: 0.4233\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4517 - accuracy: 0.8429 - categorical_crossentropy: 0.45172020-05-03 18:19:34.896075: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 91s 494ms/step - loss: 0.4518 - accuracy: 0.8417 - categorical_crossentropy: 0.4518 - val_loss: 0.3082 - val_accuracy: 0.8750 - val_categorical_crossentropy: 0.3082\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4646 - accuracy: 0.8538 - categorical_crossentropy: 0.46462020-05-03 18:21:08.597166: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 510ms/step - loss: 0.4648 - accuracy: 0.8533 - categorical_crossentropy: 0.4648 - val_loss: 0.2582 - val_accuracy: 0.9091 - val_categorical_crossentropy: 0.2582\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4605 - accuracy: 0.8395 - categorical_crossentropy: 0.46052020-05-03 18:22:43.949885: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 519ms/step - loss: 0.4588 - accuracy: 0.8404 - categorical_crossentropy: 0.4588 - val_loss: 0.2815 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.2815\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4055 - accuracy: 0.8566 - categorical_crossentropy: 0.40552020-05-03 18:24:17.628048: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 509ms/step - loss: 0.4037 - accuracy: 0.8573 - categorical_crossentropy: 0.4037 - val_loss: 0.2828 - val_accuracy: 0.9091 - val_categorical_crossentropy: 0.2828\n",
      "Epoch 26/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3322 - accuracy: 0.8818 - categorical_crossentropy: 0.33222020-05-03 18:25:50.493782: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 505ms/step - loss: 0.3307 - accuracy: 0.8825 - categorical_crossentropy: 0.3307 - val_loss: 0.3208 - val_accuracy: 0.8693 - val_categorical_crossentropy: 0.3208\n",
      "Epoch 27/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8641 - categorical_crossentropy: 0.38102020-05-03 18:27:23.577803: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 508ms/step - loss: 0.3792 - accuracy: 0.8648 - categorical_crossentropy: 0.3792 - val_loss: 0.3229 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.3229\n",
      "Epoch 28/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4187 - accuracy: 0.8600 - categorical_crossentropy: 0.41872020-05-03 18:28:55.584472: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 500ms/step - loss: 0.4166 - accuracy: 0.8607 - categorical_crossentropy: 0.4166 - val_loss: 0.2313 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.2313\n",
      "Epoch 29/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2949 - accuracy: 0.8975 - categorical_crossentropy: 0.29492020-05-03 18:30:27.282742: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 499ms/step - loss: 0.2945 - accuracy: 0.8974 - categorical_crossentropy: 0.2945 - val_loss: 0.2699 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.2699\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.8948 - categorical_crossentropy: 0.33292020-05-03 18:31:58.477830: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 91s 495ms/step - loss: 0.3312 - accuracy: 0.8954 - categorical_crossentropy: 0.3312 - val_loss: 0.4019 - val_accuracy: 0.8580 - val_categorical_crossentropy: 0.4019\n",
      "Epoch 31/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3224 - accuracy: 0.8934 - categorical_crossentropy: 0.32242020-05-03 18:33:34.629053: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 521ms/step - loss: 0.3234 - accuracy: 0.8933 - categorical_crossentropy: 0.3234 - val_loss: 0.2600 - val_accuracy: 0.8920 - val_categorical_crossentropy: 0.2600\n",
      "Epoch 32/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2975 - accuracy: 0.9030 - categorical_crossentropy: 0.29752020-05-03 18:35:09.854121: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 95s 517ms/step - loss: 0.2999 - accuracy: 0.9015 - categorical_crossentropy: 0.2999 - val_loss: 0.2086 - val_accuracy: 0.9034 - val_categorical_crossentropy: 0.2086\n",
      "Epoch 33/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3085 - accuracy: 0.8975 - categorical_crossentropy: 0.30852020-05-03 18:36:43.041895: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 507ms/step - loss: 0.3087 - accuracy: 0.8974 - categorical_crossentropy: 0.3087 - val_loss: 0.3093 - val_accuracy: 0.9205 - val_categorical_crossentropy: 0.3093\n",
      "Epoch 34/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2903 - accuracy: 0.8996 - categorical_crossentropy: 0.29032020-05-03 18:38:30.193884: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 107s 583ms/step - loss: 0.2939 - accuracy: 0.8988 - categorical_crossentropy: 0.2939 - val_loss: 0.2787 - val_accuracy: 0.9034 - val_categorical_crossentropy: 0.2787\n",
      "Epoch 35/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3095 - accuracy: 0.8907 - categorical_crossentropy: 0.30952020-05-03 18:40:02.319869: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 501ms/step - loss: 0.3080 - accuracy: 0.8913 - categorical_crossentropy: 0.3080 - val_loss: 0.3136 - val_accuracy: 0.8977 - val_categorical_crossentropy: 0.3136\n",
      "Epoch 36/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2891 - accuracy: 0.8948 - categorical_crossentropy: 0.28912020-05-03 18:41:36.990505: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 95s 515ms/step - loss: 0.2880 - accuracy: 0.8954 - categorical_crossentropy: 0.2880 - val_loss: 0.1334 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.1334\n",
      "Epoch 37/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.9085 - categorical_crossentropy: 0.29012020-05-03 18:43:04.476826: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 87s 475ms/step - loss: 0.2914 - accuracy: 0.9076 - categorical_crossentropy: 0.2914 - val_loss: 0.2488 - val_accuracy: 0.9091 - val_categorical_crossentropy: 0.2488\n",
      "Epoch 38/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.9112 - categorical_crossentropy: 0.27312020-05-03 18:44:41.537090: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 527ms/step - loss: 0.2758 - accuracy: 0.9103 - categorical_crossentropy: 0.2758 - val_loss: 0.2899 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.2899\n",
      "Epoch 39/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2966 - accuracy: 0.9051 - categorical_crossentropy: 0.29662020-05-03 18:46:16.597745: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 519ms/step - loss: 0.2953 - accuracy: 0.9056 - categorical_crossentropy: 0.2953 - val_loss: 0.1887 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1887\n",
      "Epoch 40/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2357 - accuracy: 0.9290 - categorical_crossentropy: 0.23572020-05-03 18:47:47.036519: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 90s 488ms/step - loss: 0.2373 - accuracy: 0.9280 - categorical_crossentropy: 0.2373 - val_loss: 0.2035 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.2035\n",
      "Epoch 41/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2642 - accuracy: 0.9133 - categorical_crossentropy: 0.26422020-05-03 18:49:20.301110: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 507ms/step - loss: 0.2674 - accuracy: 0.9117 - categorical_crossentropy: 0.2674 - val_loss: 0.1668 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1668\n",
      "Epoch 42/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.9208 - categorical_crossentropy: 0.23602020-05-03 18:50:49.639457: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 486ms/step - loss: 0.2349 - accuracy: 0.9212 - categorical_crossentropy: 0.2349 - val_loss: 0.1883 - val_accuracy: 0.9375 - val_categorical_crossentropy: 0.1883\n",
      "Epoch 43/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2019 - accuracy: 0.9296 - categorical_crossentropy: 0.20192020-05-03 18:52:25.567571: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 522ms/step - loss: 0.2019 - accuracy: 0.9300 - categorical_crossentropy: 0.2019 - val_loss: 0.2205 - val_accuracy: 0.9318 - val_categorical_crossentropy: 0.2205\n",
      "Epoch 44/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2239 - accuracy: 0.9249 - categorical_crossentropy: 0.22392020-05-03 18:53:52.366988: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 87s 470ms/step - loss: 0.2228 - accuracy: 0.9253 - categorical_crossentropy: 0.2228 - val_loss: 0.1716 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.1716\n",
      "Epoch 45/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9180 - categorical_crossentropy: 0.23062020-05-03 18:55:30.627729: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 98s 534ms/step - loss: 0.2302 - accuracy: 0.9185 - categorical_crossentropy: 0.2302 - val_loss: 0.1841 - val_accuracy: 0.9318 - val_categorical_crossentropy: 0.1841\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.1934 - accuracy: 0.9385 - categorical_crossentropy: 0.19342020-05-03 18:57:05.145310: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 95s 515ms/step - loss: 0.1926 - accuracy: 0.9389 - categorical_crossentropy: 0.1926 - val_loss: 0.2946 - val_accuracy: 0.8864 - val_categorical_crossentropy: 0.2946\n",
      "Epoch 47/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9214 - categorical_crossentropy: 0.24622020-05-03 18:58:34.633061: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 486ms/step - loss: 0.2485 - accuracy: 0.9212 - categorical_crossentropy: 0.2485 - val_loss: 0.1635 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1635\n",
      "Epoch 48/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2234 - accuracy: 0.9214 - categorical_crossentropy: 0.22342020-05-03 19:00:08.087381: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 505ms/step - loss: 0.2226 - accuracy: 0.9219 - categorical_crossentropy: 0.2226 - val_loss: 0.1920 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1920\n",
      "Epoch 49/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9214 - categorical_crossentropy: 0.24622020-05-03 19:01:40.092230: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 503ms/step - loss: 0.2449 - accuracy: 0.9219 - categorical_crossentropy: 0.2449 - val_loss: 0.1676 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1676\n",
      "Epoch 50/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1994 - accuracy: 0.9276 - categorical_crossentropy: 0.19942020-05-03 19:03:13.199048: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 506ms/step - loss: 0.1993 - accuracy: 0.9273 - categorical_crossentropy: 0.1993 - val_loss: 0.1898 - val_accuracy: 0.9375 - val_categorical_crossentropy: 0.1898\n",
      "Epoch 51/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9324 - categorical_crossentropy: 0.21612020-05-03 19:04:47.050780: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 509ms/step - loss: 0.2185 - accuracy: 0.9321 - categorical_crossentropy: 0.2185 - val_loss: 0.2358 - val_accuracy: 0.8977 - val_categorical_crossentropy: 0.2358\n",
      "Epoch 52/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2036 - accuracy: 0.9290 - categorical_crossentropy: 0.20362020-05-03 19:06:25.501203: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 98s 534ms/step - loss: 0.2028 - accuracy: 0.9293 - categorical_crossentropy: 0.2028 - val_loss: 0.2039 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.2039\n",
      "Epoch 53/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1712 - accuracy: 0.9419 - categorical_crossentropy: 0.17122020-05-03 19:08:04.004588: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 99s 540ms/step - loss: 0.1712 - accuracy: 0.9416 - categorical_crossentropy: 0.1712 - val_loss: 0.1210 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.1210\n",
      "Epoch 54/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1776 - accuracy: 0.9447 - categorical_crossentropy: 0.17762020-05-03 19:09:35.279461: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 91s 495ms/step - loss: 0.1784 - accuracy: 0.9443 - categorical_crossentropy: 0.1784 - val_loss: 0.3264 - val_accuracy: 0.8977 - val_categorical_crossentropy: 0.3264\n",
      "Epoch 55/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2169 - accuracy: 0.9296 - categorical_crossentropy: 0.21692020-05-03 19:11:12.398628: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 525ms/step - loss: 0.2159 - accuracy: 0.9300 - categorical_crossentropy: 0.2159 - val_loss: 0.1461 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1461\n",
      "Epoch 56/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9413 - categorical_crossentropy: 0.17162020-05-03 19:12:48.630844: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 524ms/step - loss: 0.1708 - accuracy: 0.9416 - categorical_crossentropy: 0.1708 - val_loss: 0.1857 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.1857\n",
      "Epoch 57/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9392 - categorical_crossentropy: 0.16662020-05-03 19:14:20.839284: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 502ms/step - loss: 0.1683 - accuracy: 0.9389 - categorical_crossentropy: 0.1683 - val_loss: 0.1141 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1141\n",
      "Epoch 58/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1718 - accuracy: 0.9419 - categorical_crossentropy: 0.17182020-05-03 19:15:53.724399: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 505ms/step - loss: 0.1709 - accuracy: 0.9423 - categorical_crossentropy: 0.1709 - val_loss: 0.1172 - val_accuracy: 0.9659 - val_categorical_crossentropy: 0.1172\n",
      "Epoch 59/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2087 - accuracy: 0.9276 - categorical_crossentropy: 0.20872020-05-03 19:17:33.979250: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 100s 543ms/step - loss: 0.2079 - accuracy: 0.9280 - categorical_crossentropy: 0.2079 - val_loss: 0.2006 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.2006\n",
      "Epoch 60/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1783 - accuracy: 0.9433 - categorical_crossentropy: 0.17832020-05-03 19:19:09.273799: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 520ms/step - loss: 0.1783 - accuracy: 0.9429 - categorical_crossentropy: 0.1783 - val_loss: 0.2197 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.2197\n",
      "Epoch 61/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1877 - accuracy: 0.9433 - categorical_crossentropy: 0.18772020-05-03 19:20:37.933400: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 481ms/step - loss: 0.1905 - accuracy: 0.9429 - categorical_crossentropy: 0.1905 - val_loss: 0.0890 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.0890\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.1893 - accuracy: 0.9440 - categorical_crossentropy: 0.18932020-05-03 19:22:09.821908: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 499ms/step - loss: 0.1883 - accuracy: 0.9443 - categorical_crossentropy: 0.1883 - val_loss: 0.1470 - val_accuracy: 0.9205 - val_categorical_crossentropy: 0.1470\n",
      "Epoch 63/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1674 - accuracy: 0.9406 - categorical_crossentropy: 0.16742020-05-03 19:23:44.126164: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 512ms/step - loss: 0.1671 - accuracy: 0.9409 - categorical_crossentropy: 0.1671 - val_loss: 0.1622 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.1622\n",
      "Epoch 64/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9508 - categorical_crossentropy: 0.14152020-05-03 19:25:13.206291: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 89s 483ms/step - loss: 0.1468 - accuracy: 0.9497 - categorical_crossentropy: 0.1468 - val_loss: 0.1277 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.1277\n",
      "Epoch 65/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9447 - categorical_crossentropy: 0.15482020-05-03 19:26:48.420757: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 95s 517ms/step - loss: 0.1551 - accuracy: 0.9443 - categorical_crossentropy: 0.1551 - val_loss: 0.2119 - val_accuracy: 0.9375 - val_categorical_crossentropy: 0.2119\n",
      "Epoch 66/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1655 - accuracy: 0.9440 - categorical_crossentropy: 0.16552020-05-03 19:28:20.586687: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 501ms/step - loss: 0.1648 - accuracy: 0.9443 - categorical_crossentropy: 0.1648 - val_loss: 0.1190 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1190\n",
      "Epoch 67/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1397 - accuracy: 0.9536 - categorical_crossentropy: 0.13972020-05-03 19:29:49.996684: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 90s 488ms/step - loss: 0.1408 - accuracy: 0.9531 - categorical_crossentropy: 0.1408 - val_loss: 0.0798 - val_accuracy: 0.9659 - val_categorical_crossentropy: 0.0798\n",
      "Epoch 68/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.1482 - accuracy: 0.9577 - categorical_crossentropy: 0.14822020-05-03 19:31:19.947632: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 90s 487ms/step - loss: 0.1487 - accuracy: 0.9572 - categorical_crossentropy: 0.1487 - val_loss: 0.1299 - val_accuracy: 0.9375 - val_categorical_crossentropy: 0.1299\n",
      "2020-05-03 19:31:23.632801: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-03 19:31:23.643066: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-03 19:31:28.665503: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.677005: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.685335: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.691836: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.697776: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.704274: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.712255: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.718764: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.723763: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.729203: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.743271: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.748982: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 19:31:28.754626: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.760436: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.770232: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.775692: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.784651: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.796240: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.804461: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.821631: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.834739: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.842983: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.851875: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.880249: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.893636: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.904294: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.912936: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.920111: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.925593: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.941152: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.947392: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.952950: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:28.964278: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 19:31:29.034795: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.060606: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.082531: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.107562: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.113179: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.119145: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.141064: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.156806: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.164238: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.173184: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.181324: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.189599: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.195593: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.203326: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.209436: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.216411: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.222522: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.227501: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.235805: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.241926: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.248265: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.258579: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 19:31:29.268609: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.275074: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.281706: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.287208: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.295936: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.300503: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.306697: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.313820: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.321200: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.326775: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.331782: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.339375: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 19:31:29.344907: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Riproviamo l'exp 2 ma con unfreeze di tutti i layer di batch normalization. L'overfitting è SCOMPARSO!.\n",
    "# Tutti gli esperimenti d'ora in poi faranno l'unfreeze della batch normalization.\n",
    "!python train.py \\\n",
    "--exp=7 \\\n",
    "--weights=\"imagenet\" \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 19:36:01.418151: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-03 19:36:01.448768: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200035000 Hz\n",
      "2020-05-03 19:36:01.449420: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5600a7438810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-03 19:36:01.449513: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-03 19:36:01.449990: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-03 19:36:10.651524: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 125s 678ms/step - loss: 2.5851 - accuracy: 0.1420 - categorical_crossentropy: 2.5851 - val_loss: 2.4336 - val_accuracy: 0.2102 - val_categorical_crossentropy: 2.4336\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.2517 - accuracy: 0.2439 - categorical_crossentropy: 2.25172020-05-03 19:40:18.083271: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 134s 731ms/step - loss: 2.2489 - accuracy: 0.2446 - categorical_crossentropy: 2.2489 - val_loss: 2.2343 - val_accuracy: 0.3125 - val_categorical_crossentropy: 2.2343\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9768 - accuracy: 0.3245 - categorical_crossentropy: 1.97682020-05-03 19:42:25.027331: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 127s 689ms/step - loss: 1.9741 - accuracy: 0.3247 - categorical_crossentropy: 1.9741 - val_loss: 2.5488 - val_accuracy: 0.4148 - val_categorical_crossentropy: 2.5488\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7954 - accuracy: 0.4023 - categorical_crossentropy: 1.79542020-05-03 19:44:33.137534: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 128s 694ms/step - loss: 1.7957 - accuracy: 0.4015 - categorical_crossentropy: 1.7957 - val_loss: 1.8102 - val_accuracy: 0.4091 - val_categorical_crossentropy: 1.8102\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.5961 - accuracy: 0.4672 - categorical_crossentropy: 1.59612020-05-03 19:46:43.167071: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 131s 710ms/step - loss: 1.5985 - accuracy: 0.4654 - categorical_crossentropy: 1.5985 - val_loss: 1.2164 - val_accuracy: 0.5852 - val_categorical_crossentropy: 1.2164\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.4002 - accuracy: 0.5171 - categorical_crossentropy: 1.40022020-05-03 19:48:47.034549: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 124s 672ms/step - loss: 1.4001 - accuracy: 0.5170 - categorical_crossentropy: 1.4001 - val_loss: 0.9936 - val_accuracy: 0.6875 - val_categorical_crossentropy: 0.9936\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.3115 - accuracy: 0.5704 - categorical_crossentropy: 1.31152020-05-03 19:50:50.033773: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 122s 665ms/step - loss: 1.3087 - accuracy: 0.5713 - categorical_crossentropy: 1.3087 - val_loss: 1.0116 - val_accuracy: 0.6364 - val_categorical_crossentropy: 1.0116\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.2262 - accuracy: 0.5888 - categorical_crossentropy: 1.22622020-05-03 19:52:47.343674: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 117s 638ms/step - loss: 1.2238 - accuracy: 0.5890 - categorical_crossentropy: 1.2238 - val_loss: 1.0621 - val_accuracy: 0.6534 - val_categorical_crossentropy: 1.0621\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0733 - accuracy: 0.6428 - categorical_crossentropy: 1.07332020-05-03 19:54:51.592516: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 125s 678ms/step - loss: 1.0722 - accuracy: 0.6433 - categorical_crossentropy: 1.0722 - val_loss: 0.8592 - val_accuracy: 0.7159 - val_categorical_crossentropy: 0.8592\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0203 - accuracy: 0.6571 - categorical_crossentropy: 1.02032020-05-03 19:56:55.743462: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 124s 673ms/step - loss: 1.0169 - accuracy: 0.6583 - categorical_crossentropy: 1.0169 - val_loss: 0.8764 - val_accuracy: 0.6875 - val_categorical_crossentropy: 0.8764\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9016 - accuracy: 0.6960 - categorical_crossentropy: 0.90162020-05-03 19:59:04.679071: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 129s 702ms/step - loss: 0.9027 - accuracy: 0.6943 - categorical_crossentropy: 0.9027 - val_loss: 0.8346 - val_accuracy: 0.6648 - val_categorical_crossentropy: 0.8346\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8340 - accuracy: 0.7138 - categorical_crossentropy: 0.83402020-05-03 20:01:21.816936: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 137s 745ms/step - loss: 0.8352 - accuracy: 0.7133 - categorical_crossentropy: 0.8352 - val_loss: 0.7836 - val_accuracy: 0.7386 - val_categorical_crossentropy: 0.7836\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7975 - accuracy: 0.7234 - categorical_crossentropy: 0.79752020-05-03 20:03:17.042692: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 116s 629ms/step - loss: 0.7947 - accuracy: 0.7242 - categorical_crossentropy: 0.7947 - val_loss: 0.5744 - val_accuracy: 0.8182 - val_categorical_crossentropy: 0.5744\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.7116 - accuracy: 0.7616 - categorical_crossentropy: 0.71162020-05-03 20:05:09.899432: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 113s 612ms/step - loss: 0.7125 - accuracy: 0.7609 - categorical_crossentropy: 0.7125 - val_loss: 0.6271 - val_accuracy: 0.8011 - val_categorical_crossentropy: 0.6271\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7173 - accuracy: 0.7466 - categorical_crossentropy: 0.71732020-05-03 20:07:28.328849: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 138s 750ms/step - loss: 0.7217 - accuracy: 0.7452 - categorical_crossentropy: 0.7217 - val_loss: 0.5829 - val_accuracy: 0.8011 - val_categorical_crossentropy: 0.5829\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.6969 - accuracy: 0.7643 - categorical_crossentropy: 0.69692020-05-03 20:09:26.726025: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 119s 647ms/step - loss: 0.6954 - accuracy: 0.7649 - categorical_crossentropy: 0.6954 - val_loss: 0.5814 - val_accuracy: 0.8068 - val_categorical_crossentropy: 0.5814\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.6474 - accuracy: 0.7794 - categorical_crossentropy: 0.64742020-05-03 20:11:23.145007: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 116s 630ms/step - loss: 0.6488 - accuracy: 0.7779 - categorical_crossentropy: 0.6488 - val_loss: 0.5582 - val_accuracy: 0.8295 - val_categorical_crossentropy: 0.5582\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5682 - accuracy: 0.8108 - categorical_crossentropy: 0.56822020-05-03 20:13:31.637203: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 129s 700ms/step - loss: 0.5662 - accuracy: 0.8111 - categorical_crossentropy: 0.5662 - val_loss: 0.5558 - val_accuracy: 0.8636 - val_categorical_crossentropy: 0.5558\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4981 - accuracy: 0.8292 - categorical_crossentropy: 0.49812020-05-03 20:15:30.073842: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 118s 641ms/step - loss: 0.4964 - accuracy: 0.8302 - categorical_crossentropy: 0.4964 - val_loss: 0.5174 - val_accuracy: 0.8125 - val_categorical_crossentropy: 0.5174\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5232 - accuracy: 0.8169 - categorical_crossentropy: 0.52322020-05-03 20:17:25.800297: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 116s 629ms/step - loss: 0.5216 - accuracy: 0.8173 - categorical_crossentropy: 0.5216 - val_loss: 0.4591 - val_accuracy: 0.8523 - val_categorical_crossentropy: 0.4590\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.8361 - categorical_crossentropy: 0.49552020-05-03 20:19:26.428650: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 121s 658ms/step - loss: 0.4945 - accuracy: 0.8363 - categorical_crossentropy: 0.4945 - val_loss: 0.3471 - val_accuracy: 0.8920 - val_categorical_crossentropy: 0.3471\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4732 - accuracy: 0.8347 - categorical_crossentropy: 0.47322020-05-03 20:21:25.220677: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 118s 642ms/step - loss: 0.4708 - accuracy: 0.8356 - categorical_crossentropy: 0.4708 - val_loss: 0.3560 - val_accuracy: 0.8750 - val_categorical_crossentropy: 0.3560\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5088 - accuracy: 0.8340 - categorical_crossentropy: 0.50882020-05-03 20:23:32.140873: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 127s 690ms/step - loss: 0.5102 - accuracy: 0.8329 - categorical_crossentropy: 0.5102 - val_loss: 0.4285 - val_accuracy: 0.8636 - val_categorical_crossentropy: 0.4285\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4333 - accuracy: 0.8586 - categorical_crossentropy: 0.43332020-05-03 20:25:30.725652: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 119s 645ms/step - loss: 0.4316 - accuracy: 0.8594 - categorical_crossentropy: 0.4316 - val_loss: 0.4278 - val_accuracy: 0.8636 - val_categorical_crossentropy: 0.4278\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4378 - accuracy: 0.8607 - categorical_crossentropy: 0.43782020-05-03 20:27:38.728003: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 128s 697ms/step - loss: 0.4409 - accuracy: 0.8594 - categorical_crossentropy: 0.4409 - val_loss: 0.3664 - val_accuracy: 0.8693 - val_categorical_crossentropy: 0.3664\n",
      "Epoch 26/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3719 - accuracy: 0.8743 - categorical_crossentropy: 0.37192020-05-03 20:29:40.659722: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 122s 664ms/step - loss: 0.3701 - accuracy: 0.8750 - categorical_crossentropy: 0.3701 - val_loss: 0.2735 - val_accuracy: 0.9034 - val_categorical_crossentropy: 0.2735\n",
      "Epoch 27/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3786 - accuracy: 0.8757 - categorical_crossentropy: 0.37862020-05-03 20:31:47.830400: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 127s 689ms/step - loss: 0.3770 - accuracy: 0.8764 - categorical_crossentropy: 0.3770 - val_loss: 0.1942 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.1942\n",
      "Epoch 28/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8805 - categorical_crossentropy: 0.38672020-05-03 20:33:58.066310: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 130s 709ms/step - loss: 0.3848 - accuracy: 0.8811 - categorical_crossentropy: 0.3848 - val_loss: 0.4616 - val_accuracy: 0.8068 - val_categorical_crossentropy: 0.4616\n",
      "Epoch 29/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3680 - accuracy: 0.8716 - categorical_crossentropy: 0.36802020-05-03 20:36:12.159311: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 134s 728ms/step - loss: 0.3674 - accuracy: 0.8709 - categorical_crossentropy: 0.3674 - val_loss: 0.3706 - val_accuracy: 0.8807 - val_categorical_crossentropy: 0.3706\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.3686 - accuracy: 0.8839 - categorical_crossentropy: 0.36862020-05-03 20:38:21.640593: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 130s 705ms/step - loss: 0.3701 - accuracy: 0.8825 - categorical_crossentropy: 0.3701 - val_loss: 0.3840 - val_accuracy: 0.8693 - val_categorical_crossentropy: 0.3840\n",
      "Epoch 31/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3462 - accuracy: 0.8880 - categorical_crossentropy: 0.34622020-05-03 20:40:28.053217: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 126s 684ms/step - loss: 0.3472 - accuracy: 0.8872 - categorical_crossentropy: 0.3472 - val_loss: 0.3177 - val_accuracy: 0.8864 - val_categorical_crossentropy: 0.3177\n",
      "Epoch 32/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3428 - accuracy: 0.8941 - categorical_crossentropy: 0.34282020-05-03 20:42:39.957479: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 133s 720ms/step - loss: 0.3415 - accuracy: 0.8947 - categorical_crossentropy: 0.3415 - val_loss: 0.2898 - val_accuracy: 0.9091 - val_categorical_crossentropy: 0.2898\n",
      "Epoch 33/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3149 - accuracy: 0.8955 - categorical_crossentropy: 0.31492020-05-03 20:44:42.736166: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 122s 664ms/step - loss: 0.3153 - accuracy: 0.8954 - categorical_crossentropy: 0.3153 - val_loss: 0.2137 - val_accuracy: 0.9205 - val_categorical_crossentropy: 0.2137\n",
      "Epoch 34/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.3591 - accuracy: 0.8859 - categorical_crossentropy: 0.35912020-05-03 20:46:45.353096: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 123s 667ms/step - loss: 0.3581 - accuracy: 0.8859 - categorical_crossentropy: 0.3581 - val_loss: 0.2300 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.2300\n",
      "Epoch 35/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.8989 - categorical_crossentropy: 0.28972020-05-03 20:48:34.430111: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 110s 596ms/step - loss: 0.2927 - accuracy: 0.8981 - categorical_crossentropy: 0.2927 - val_loss: 0.2083 - val_accuracy: 0.9318 - val_categorical_crossentropy: 0.2083\n",
      "Epoch 36/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2494 - accuracy: 0.9153 - categorical_crossentropy: 0.24942020-05-03 20:50:38.568984: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 124s 674ms/step - loss: 0.2497 - accuracy: 0.9144 - categorical_crossentropy: 0.2497 - val_loss: 0.1472 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.1472\n",
      "Epoch 37/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2863 - accuracy: 0.9071 - categorical_crossentropy: 0.28632020-05-03 20:52:44.670196: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 125s 682ms/step - loss: 0.2850 - accuracy: 0.9076 - categorical_crossentropy: 0.2850 - val_loss: 0.4163 - val_accuracy: 0.8920 - val_categorical_crossentropy: 0.4163\n",
      "Epoch 38/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2736 - accuracy: 0.9064 - categorical_crossentropy: 0.27362020-05-03 20:54:58.232012: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 133s 726ms/step - loss: 0.2735 - accuracy: 0.9062 - categorical_crossentropy: 0.2735 - val_loss: 0.2695 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.2695\n",
      "Epoch 39/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2414 - accuracy: 0.9255 - categorical_crossentropy: 0.24142020-05-03 20:57:09.498956: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 131s 714ms/step - loss: 0.2403 - accuracy: 0.9260 - categorical_crossentropy: 0.2403 - val_loss: 0.2222 - val_accuracy: 0.9261 - val_categorical_crossentropy: 0.2222\n",
      "Epoch 40/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.8989 - categorical_crossentropy: 0.27312020-05-03 20:59:35.209646: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 146s 793ms/step - loss: 0.2722 - accuracy: 0.8995 - categorical_crossentropy: 0.2722 - val_loss: 0.1622 - val_accuracy: 0.9318 - val_categorical_crossentropy: 0.1622\n",
      "Epoch 41/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9187 - categorical_crossentropy: 0.23332020-05-03 21:01:50.745028: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 136s 742ms/step - loss: 0.2329 - accuracy: 0.9192 - categorical_crossentropy: 0.2329 - val_loss: 0.2421 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.2421\n",
      "Epoch 42/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.9092 - categorical_crossentropy: 0.28552020-05-03 21:04:02.373756: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 131s 713ms/step - loss: 0.2842 - accuracy: 0.9096 - categorical_crossentropy: 0.2842 - val_loss: 0.1715 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1715\n",
      "Epoch 43/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2428 - accuracy: 0.9194 - categorical_crossentropy: 0.24282020-05-03 21:06:17.416424: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 134s 731ms/step - loss: 0.2417 - accuracy: 0.9198 - categorical_crossentropy: 0.2417 - val_loss: 0.2283 - val_accuracy: 0.9205 - val_categorical_crossentropy: 0.2283\n",
      "Epoch 44/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2270 - accuracy: 0.9317 - categorical_crossentropy: 0.22702020-05-03 21:08:21.687094: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 124s 676ms/step - loss: 0.2265 - accuracy: 0.9321 - categorical_crossentropy: 0.2265 - val_loss: 0.1330 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.1330\n",
      "Epoch 45/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.2451 - accuracy: 0.9249 - categorical_crossentropy: 0.24512020-05-03 21:10:34.362949: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 133s 721ms/step - loss: 0.2439 - accuracy: 0.9253 - categorical_crossentropy: 0.2439 - val_loss: 0.1801 - val_accuracy: 0.9375 - val_categorical_crossentropy: 0.1801\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.2232 - accuracy: 0.9214 - categorical_crossentropy: 0.22322020-05-03 21:12:43.200947: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 129s 701ms/step - loss: 0.2221 - accuracy: 0.9219 - categorical_crossentropy: 0.2221 - val_loss: 0.1689 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1689\n",
      "2020-05-03 21:12:48.225544: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-03 21:12:48.227167: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-03 21:12:52.100387: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.107804: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.114143: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.120668: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.125788: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.130435: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.135437: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.140960: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.153135: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.164132: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.170871: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.177277: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.183261: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.192127: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.196927: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.202860: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.260688: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.267956: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.277140: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.283009: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.292135: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.297159: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 21:12:52.303286: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.315321: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.321941: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.327022: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.334526: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.339950: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.344506: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.350340: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.354854: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.359532: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.371311: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.377853: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.383903: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.388651: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.396354: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.401705: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.409297: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.414702: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.424306: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.431396: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.437498: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.442290: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-03 21:12:52.447877: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-03 21:12:52.452501: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n"
     ]
    }
   ],
   "source": [
    "# Riproviamo l'exp 7 ma con Adam.\n",
    "!python train.py \\\n",
    "--exp=8 \\\n",
    "--weights=\"imagenet\" \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"adam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-04 00:28:57.959007: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-04 00:28:57.991985: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199810000 Hz\n",
      "2020-05-04 00:28:57.992515: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56176daa51a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-04 00:28:57.992533: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-04 00:28:57.993543: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-04 00:29:06.809651: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 107s 582ms/step - loss: 2.6869 - accuracy: 0.0645 - categorical_crossentropy: 2.6869 - val_loss: 2.6719 - val_accuracy: 0.0682 - val_categorical_crossentropy: 2.6719\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6813 - accuracy: 0.0635 - categorical_crossentropy: 2.68132020-05-04 00:32:34.087479: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 111s 601ms/step - loss: 2.6824 - accuracy: 0.0639 - categorical_crossentropy: 2.6824 - val_loss: 2.6578 - val_accuracy: 0.0795 - val_categorical_crossentropy: 2.6578\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6873 - accuracy: 0.0697 - categorical_crossentropy: 2.68732020-05-04 00:34:14.432198: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 99s 540ms/step - loss: 2.6866 - accuracy: 0.0707 - categorical_crossentropy: 2.6866 - val_loss: 3.2828 - val_accuracy: 0.0511 - val_categorical_crossentropy: 3.2828\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6787 - accuracy: 0.0704 - categorical_crossentropy: 2.67872020-05-04 00:35:51.247171: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 97s 528ms/step - loss: 2.6788 - accuracy: 0.0707 - categorical_crossentropy: 2.6788 - val_loss: 2.9113 - val_accuracy: 0.0739 - val_categorical_crossentropy: 2.9113\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6887 - accuracy: 0.0779 - categorical_crossentropy: 2.68872020-05-04 00:37:26.300105: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 96s 519ms/step - loss: 2.6885 - accuracy: 0.0774 - categorical_crossentropy: 2.6885 - val_loss: 2.6636 - val_accuracy: 0.0852 - val_categorical_crossentropy: 2.6636\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6759 - accuracy: 0.0601 - categorical_crossentropy: 2.67592020-05-04 00:38:58.801621: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 502ms/step - loss: 2.6762 - accuracy: 0.0605 - categorical_crossentropy: 2.6762 - val_loss: 2.7720 - val_accuracy: 0.1023 - val_categorical_crossentropy: 2.7720\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6785 - accuracy: 0.0710 - categorical_crossentropy: 2.67852020-05-04 00:40:33.472945: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 512ms/step - loss: 2.6786 - accuracy: 0.0707 - categorical_crossentropy: 2.6786 - val_loss: 2.7902 - val_accuracy: 0.0739 - val_categorical_crossentropy: 2.7902\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6773 - accuracy: 0.0751 - categorical_crossentropy: 2.67732020-05-04 00:42:04.137859: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 91s 495ms/step - loss: 2.6770 - accuracy: 0.0747 - categorical_crossentropy: 2.6770 - val_loss: 3.8274 - val_accuracy: 0.0739 - val_categorical_crossentropy: 3.8274\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6803 - accuracy: 0.0779 - categorical_crossentropy: 2.68032020-05-04 00:43:38.400347: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 512ms/step - loss: 2.6799 - accuracy: 0.0774 - categorical_crossentropy: 2.6799 - val_loss: 3.5134 - val_accuracy: 0.0909 - val_categorical_crossentropy: 3.5134\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6789 - accuracy: 0.0751 - categorical_crossentropy: 2.67892020-05-04 00:45:12.007040: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 94s 511ms/step - loss: 2.6781 - accuracy: 0.0761 - categorical_crossentropy: 2.6781 - val_loss: 4.6077 - val_accuracy: 0.0966 - val_categorical_crossentropy: 4.6077\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6766 - accuracy: 0.0799 - categorical_crossentropy: 2.67662020-05-04 00:46:47.671568: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 95s 518ms/step - loss: 2.6764 - accuracy: 0.0795 - categorical_crossentropy: 2.6764 - val_loss: 2.9064 - val_accuracy: 0.0852 - val_categorical_crossentropy: 2.9064\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6714 - accuracy: 0.0635 - categorical_crossentropy: 2.67142020-05-04 00:48:21.064251: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 93s 508ms/step - loss: 2.6722 - accuracy: 0.0632 - categorical_crossentropy: 2.6722 - val_loss: 2.8367 - val_accuracy: 0.0625 - val_categorical_crossentropy: 2.8367\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6705 - accuracy: 0.0813 - categorical_crossentropy: 2.67052020-05-04 00:49:53.467691: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 500ms/step - loss: 2.6703 - accuracy: 0.0808 - categorical_crossentropy: 2.6703 - val_loss: 3.7069 - val_accuracy: 0.0511 - val_categorical_crossentropy: 3.7069\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 2.6762 - accuracy: 0.0731 - categorical_crossentropy: 2.67622020-05-04 00:51:25.018231: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 499ms/step - loss: 2.6756 - accuracy: 0.0734 - categorical_crossentropy: 2.6756 - val_loss: 2.7949 - val_accuracy: 0.0625 - val_categorical_crossentropy: 2.7949\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6682 - accuracy: 0.0922 - categorical_crossentropy: 2.66822020-05-04 00:52:57.031750: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 499ms/step - loss: 2.6677 - accuracy: 0.0931 - categorical_crossentropy: 2.6677 - val_loss: 3.5559 - val_accuracy: 0.0682 - val_categorical_crossentropy: 3.5559\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.6703 - accuracy: 0.0717 - categorical_crossentropy: 2.67032020-05-04 00:54:29.126778: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 92s 502ms/step - loss: 2.6706 - accuracy: 0.0713 - categorical_crossentropy: 2.6706 - val_loss: 2.9893 - val_accuracy: 0.1023 - val_categorical_crossentropy: 2.9893\n",
      "2020-05-04 00:54:33.193249: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-04 00:54:33.193722: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-04 00:54:33.602965: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.608184: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.612819: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.617316: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.625028: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.630508: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.635785: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.643862: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.648187: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.653004: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.665929: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.670855: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.678574: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.684008: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.687951: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 00:54:33.692592: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Riproviamo l'exp 7 ma con Adadelta.\n",
    "!python train.py \\\n",
    "--exp=9 \\\n",
    "--weights=\"imagenet\" \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"adadelta\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-04 00:54:36.799170: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-04 00:54:36.824057: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199810000 Hz\n",
      "2020-05-04 00:54:36.824385: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562d4961b1a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-04 00:54:36.824425: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-04 00:54:36.824547: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-04 00:54:47.199836: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 142s 772ms/step - loss: 2.5818 - accuracy: 0.1474 - categorical_crossentropy: 2.5818 - val_loss: 2.4162 - val_accuracy: 0.2102 - val_categorical_crossentropy: 2.4162\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 2.2711 - accuracy: 0.2377 - categorical_crossentropy: 2.27112020-05-04 00:59:05.302192: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 129s 703ms/step - loss: 2.2709 - accuracy: 0.2378 - categorical_crossentropy: 2.2709 - val_loss: 2.2732 - val_accuracy: 0.2784 - val_categorical_crossentropy: 2.2732\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.9952 - accuracy: 0.3299 - categorical_crossentropy: 1.99522020-05-04 01:01:07.493402: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 122s 664ms/step - loss: 1.9929 - accuracy: 0.3308 - categorical_crossentropy: 1.9929 - val_loss: 2.5076 - val_accuracy: 0.3636 - val_categorical_crossentropy: 2.5076\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.7851 - accuracy: 0.4023 - categorical_crossentropy: 1.78512020-05-04 01:03:24.546768: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 137s 743ms/step - loss: 1.7841 - accuracy: 0.4022 - categorical_crossentropy: 1.7841 - val_loss: 1.8216 - val_accuracy: 0.4034 - val_categorical_crossentropy: 1.8216\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.6210 - accuracy: 0.4563 - categorical_crossentropy: 1.62102020-05-04 01:05:37.961860: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 133s 723ms/step - loss: 1.6235 - accuracy: 0.4558 - categorical_crossentropy: 1.6235 - val_loss: 2.7359 - val_accuracy: 0.3920 - val_categorical_crossentropy: 2.7359\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.5069 - accuracy: 0.4822 - categorical_crossentropy: 1.50692020-05-04 01:07:56.451458: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 139s 754ms/step - loss: 1.5054 - accuracy: 0.4823 - categorical_crossentropy: 1.5054 - val_loss: 1.7421 - val_accuracy: 0.5170 - val_categorical_crossentropy: 1.7421\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.3508 - accuracy: 0.5417 - categorical_crossentropy: 1.35082020-05-04 01:10:16.810588: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 141s 766ms/step - loss: 1.3471 - accuracy: 0.5435 - categorical_crossentropy: 1.3471 - val_loss: 1.5867 - val_accuracy: 0.5568 - val_categorical_crossentropy: 1.5867\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.2230 - accuracy: 0.5758 - categorical_crossentropy: 1.22302020-05-04 01:12:30.357468: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 133s 724ms/step - loss: 1.2222 - accuracy: 0.5754 - categorical_crossentropy: 1.2222 - val_loss: 1.9099 - val_accuracy: 0.5909 - val_categorical_crossentropy: 1.9099\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.1558 - accuracy: 0.6202 - categorical_crossentropy: 1.15582020-05-04 01:15:01.196476: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 151s 818ms/step - loss: 1.1543 - accuracy: 0.6209 - categorical_crossentropy: 1.1543 - val_loss: 1.4891 - val_accuracy: 0.5795 - val_categorical_crossentropy: 1.4891\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 1.0674 - accuracy: 0.6441 - categorical_crossentropy: 1.06742020-05-04 01:17:15.013662: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 134s 728ms/step - loss: 1.0649 - accuracy: 0.6440 - categorical_crossentropy: 1.0649 - val_loss: 1.3784 - val_accuracy: 0.6364 - val_categorical_crossentropy: 1.3784\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.9958 - accuracy: 0.6701 - categorical_crossentropy: 0.99582020-05-04 01:19:11.469688: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 116s 633ms/step - loss: 0.9936 - accuracy: 0.6712 - categorical_crossentropy: 0.9936 - val_loss: 1.1146 - val_accuracy: 0.6648 - val_categorical_crossentropy: 1.1146\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8806 - accuracy: 0.6967 - categorical_crossentropy: 0.88062020-05-04 01:21:15.214005: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 124s 674ms/step - loss: 0.8802 - accuracy: 0.6963 - categorical_crossentropy: 0.8802 - val_loss: 1.2246 - val_accuracy: 0.6534 - val_categorical_crossentropy: 1.2246\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.8156 - accuracy: 0.7288 - categorical_crossentropy: 0.81562020-05-04 01:23:18.980546: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 124s 673ms/step - loss: 0.8200 - accuracy: 0.7269 - categorical_crossentropy: 0.8200 - val_loss: 1.0302 - val_accuracy: 0.6932 - val_categorical_crossentropy: 1.0302\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 0s - loss: 0.7542 - accuracy: 0.7425 - categorical_crossentropy: 0.75422020-05-04 01:25:19.770577: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 121s 656ms/step - loss: 0.7522 - accuracy: 0.7432 - categorical_crossentropy: 0.7522 - val_loss: 0.9562 - val_accuracy: 0.7614 - val_categorical_crossentropy: 0.9562\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7512 - accuracy: 0.7425 - categorical_crossentropy: 0.75122020-05-04 01:27:29.149809: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 129s 702ms/step - loss: 0.7497 - accuracy: 0.7432 - categorical_crossentropy: 0.7497 - val_loss: 0.8325 - val_accuracy: 0.7386 - val_categorical_crossentropy: 0.8325\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.7050 - accuracy: 0.7555 - categorical_crossentropy: 0.70502020-05-04 01:29:33.991054: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 125s 679ms/step - loss: 0.7050 - accuracy: 0.7554 - categorical_crossentropy: 0.7050 - val_loss: 0.6128 - val_accuracy: 0.7784 - val_categorical_crossentropy: 0.6128\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.6874 - accuracy: 0.7712 - categorical_crossentropy: 0.68742020-05-04 01:31:37.532503: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 123s 670ms/step - loss: 0.6846 - accuracy: 0.7717 - categorical_crossentropy: 0.6846 - val_loss: 0.5028 - val_accuracy: 0.8352 - val_categorical_crossentropy: 0.5028\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.6322 - accuracy: 0.7896 - categorical_crossentropy: 0.63222020-05-04 01:33:53.413895: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 136s 738ms/step - loss: 0.6308 - accuracy: 0.7901 - categorical_crossentropy: 0.6308 - val_loss: 0.7135 - val_accuracy: 0.7727 - val_categorical_crossentropy: 0.7135\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.6057 - accuracy: 0.7896 - categorical_crossentropy: 0.60572020-05-04 01:36:03.664596: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 131s 711ms/step - loss: 0.6123 - accuracy: 0.7880 - categorical_crossentropy: 0.6123 - val_loss: 1.2284 - val_accuracy: 0.7045 - val_categorical_crossentropy: 1.2284\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.6044 - accuracy: 0.8026 - categorical_crossentropy: 0.60442020-05-04 01:38:12.520510: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 128s 697ms/step - loss: 0.6023 - accuracy: 0.8030 - categorical_crossentropy: 0.6023 - val_loss: 0.6483 - val_accuracy: 0.8125 - val_categorical_crossentropy: 0.6483\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5610 - accuracy: 0.8149 - categorical_crossentropy: 0.56102020-05-04 01:40:16.571579: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 124s 676ms/step - loss: 0.5615 - accuracy: 0.8152 - categorical_crossentropy: 0.5615 - val_loss: 0.6944 - val_accuracy: 0.7955 - val_categorical_crossentropy: 0.6944\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5275 - accuracy: 0.8258 - categorical_crossentropy: 0.52752020-05-04 01:42:19.331598: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 123s 666ms/step - loss: 0.5260 - accuracy: 0.8268 - categorical_crossentropy: 0.5260 - val_loss: 0.7758 - val_accuracy: 0.8011 - val_categorical_crossentropy: 0.7758\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5080 - accuracy: 0.8265 - categorical_crossentropy: 0.50802020-05-04 01:44:17.843145: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 119s 645ms/step - loss: 0.5066 - accuracy: 0.8268 - categorical_crossentropy: 0.5067 - val_loss: 0.8967 - val_accuracy: 0.7898 - val_categorical_crossentropy: 0.8967\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.5214 - accuracy: 0.8258 - categorical_crossentropy: 0.52142020-05-04 01:46:36.635204: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 139s 754ms/step - loss: 0.5218 - accuracy: 0.8247 - categorical_crossentropy: 0.5218 - val_loss: 0.9484 - val_accuracy: 0.7670 - val_categorical_crossentropy: 0.9484\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4595 - accuracy: 0.8381 - categorical_crossentropy: 0.45952020-05-04 01:48:39.945137: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 123s 671ms/step - loss: 0.4584 - accuracy: 0.8383 - categorical_crossentropy: 0.4584 - val_loss: 0.8355 - val_accuracy: 0.8068 - val_categorical_crossentropy: 0.8355\n",
      "Epoch 26/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4450 - accuracy: 0.8552 - categorical_crossentropy: 0.44502020-05-04 01:50:55.549853: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 136s 737ms/step - loss: 0.4501 - accuracy: 0.8539 - categorical_crossentropy: 0.4501 - val_loss: 1.0492 - val_accuracy: 0.7898 - val_categorical_crossentropy: 1.0492\n",
      "Epoch 27/1000\n",
      "183/184 [============================>.] - ETA: 0s - loss: 0.4801 - accuracy: 0.8429 - categorical_crossentropy: 0.48012020-05-04 01:53:08.674712: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 133s 723ms/step - loss: 0.4777 - accuracy: 0.8438 - categorical_crossentropy: 0.4777 - val_loss: 0.7485 - val_accuracy: 0.8068 - val_categorical_crossentropy: 0.7485\n",
      "2020-05-04 01:53:13.751484: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-04 01:53:13.751964: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-04 01:53:14.280924: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.287775: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.293311: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.297513: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.301306: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.305427: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.309288: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.312937: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.316558: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.322764: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-04 01:53:14.333918: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.339415: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.345894: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.355958: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.361837: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.367754: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.372917: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.378231: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.385094: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.391059: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.395878: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.403583: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.408930: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.414524: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.427125: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.433679: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-04 01:53:14.439367: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Riproviamo l'exp 7 ma con RMSProp.\n",
    "!python train.py \\\n",
    "--exp=10 \\\n",
    "--weights=\"imagenet\" \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"rmsprop\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-04 01:53:17.734673: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-04 01:53:17.760054: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199810000 Hz\n",
      "2020-05-04 01:53:17.760383: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564e912c7750 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-04 01:53:17.760421: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-04 01:53:17.760554: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-04 01:53:34.201059: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 817s 4s/step - loss: 2.5451 - accuracy: 0.1406 - categorical_crossentropy: 2.5451 - val_loss: 2.4726 - val_accuracy: 0.1307 - val_categorical_crossentropy: 2.4726\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 2.1039 - accuracy: 0.3217 - categorical_crossentropy: 2.10392020-05-04 02:19:43.821354: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 793s 4s/step - loss: 2.1022 - accuracy: 0.3213 - categorical_crossentropy: 2.1022 - val_loss: 1.6521 - val_accuracy: 0.4659 - val_categorical_crossentropy: 1.6521\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 1.5791 - accuracy: 0.4795 - categorical_crossentropy: 1.57912020-05-04 02:32:52.974556: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 789s 4s/step - loss: 1.5790 - accuracy: 0.4796 - categorical_crossentropy: 1.5790 - val_loss: 1.2687 - val_accuracy: 0.5568 - val_categorical_crossentropy: 1.2687\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 1.2016 - accuracy: 0.6018 - categorical_crossentropy: 1.20162020-05-04 02:46:02.104838: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 790s 4s/step - loss: 1.1972 - accuracy: 0.6033 - categorical_crossentropy: 1.1972 - val_loss: 0.8431 - val_accuracy: 0.6932 - val_categorical_crossentropy: 0.8431\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.9188 - accuracy: 0.6913 - categorical_crossentropy: 0.91882020-05-04 02:59:06.700148: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 784s 4s/step - loss: 0.9174 - accuracy: 0.6923 - categorical_crossentropy: 0.9174 - val_loss: 0.6191 - val_accuracy: 0.7727 - val_categorical_crossentropy: 0.6191\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.7947 - accuracy: 0.7322 - categorical_crossentropy: 0.79472020-05-04 03:12:10.719099: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 784s 4s/step - loss: 0.7949 - accuracy: 0.7330 - categorical_crossentropy: 0.7949 - val_loss: 0.5231 - val_accuracy: 0.8295 - val_categorical_crossentropy: 0.5231\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.6400 - accuracy: 0.7937 - categorical_crossentropy: 0.64002020-05-04 03:25:13.972406: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 783s 4s/step - loss: 0.6394 - accuracy: 0.7942 - categorical_crossentropy: 0.6394 - val_loss: 0.4745 - val_accuracy: 0.8580 - val_categorical_crossentropy: 0.4745\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.5921 - accuracy: 0.8217 - categorical_crossentropy: 0.59212020-05-04 03:38:15.771188: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 782s 4s/step - loss: 0.5907 - accuracy: 0.8220 - categorical_crossentropy: 0.5907 - val_loss: 0.4750 - val_accuracy: 0.8466 - val_categorical_crossentropy: 0.4750\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.4782 - accuracy: 0.8518 - categorical_crossentropy: 0.47822020-05-04 03:51:11.407636: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 776s 4s/step - loss: 0.4788 - accuracy: 0.8512 - categorical_crossentropy: 0.4788 - val_loss: 0.3849 - val_accuracy: 0.8807 - val_categorical_crossentropy: 0.3849\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.4544 - accuracy: 0.8518 - categorical_crossentropy: 0.45442020-05-04 04:04:24.057109: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 793s 4s/step - loss: 0.4525 - accuracy: 0.8526 - categorical_crossentropy: 0.4525 - val_loss: 0.3569 - val_accuracy: 0.8864 - val_categorical_crossentropy: 0.3569\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.3934 - accuracy: 0.8716 - categorical_crossentropy: 0.39342020-05-04 04:17:22.105721: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 778s 4s/step - loss: 0.3951 - accuracy: 0.8709 - categorical_crossentropy: 0.3951 - val_loss: 0.1933 - val_accuracy: 0.9205 - val_categorical_crossentropy: 0.1933\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.3466 - accuracy: 0.8900 - categorical_crossentropy: 0.34662020-05-04 04:30:30.646153: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 789s 4s/step - loss: 0.3453 - accuracy: 0.8906 - categorical_crossentropy: 0.3453 - val_loss: 0.2648 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.2648\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.3253 - accuracy: 0.9037 - categorical_crossentropy: 0.32532020-05-04 04:43:40.340977: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 790s 4s/step - loss: 0.3239 - accuracy: 0.9042 - categorical_crossentropy: 0.3239 - val_loss: 0.2607 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.2607\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 4s - loss: 0.2696 - accuracy: 0.9085 - categorical_crossentropy: 0.26962020-05-04 04:57:03.962711: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 804s 4s/step - loss: 0.2686 - accuracy: 0.9090 - categorical_crossentropy: 0.2686 - val_loss: 0.1527 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.1527\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.2622 - accuracy: 0.9167 - categorical_crossentropy: 0.26222020-05-04 05:10:15.283194: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 791s 4s/step - loss: 0.2631 - accuracy: 0.9164 - categorical_crossentropy: 0.2631 - val_loss: 0.1854 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.1854\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.2231 - accuracy: 0.9262 - categorical_crossentropy: 0.22312020-05-04 05:23:18.229832: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 783s 4s/step - loss: 0.2223 - accuracy: 0.9266 - categorical_crossentropy: 0.2223 - val_loss: 0.1092 - val_accuracy: 0.9773 - val_categorical_crossentropy: 0.1092\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1941 - accuracy: 0.9433 - categorical_crossentropy: 0.19412020-05-04 05:36:26.994429: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 789s 4s/step - loss: 0.1963 - accuracy: 0.9429 - categorical_crossentropy: 0.1963 - val_loss: 0.2610 - val_accuracy: 0.8977 - val_categorical_crossentropy: 0.2610\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1868 - accuracy: 0.9426 - categorical_crossentropy: 0.18682020-05-04 05:49:43.473283: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 797s 4s/step - loss: 0.1871 - accuracy: 0.9423 - categorical_crossentropy: 0.1871 - val_loss: 0.1122 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1122\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1903 - accuracy: 0.9426 - categorical_crossentropy: 0.19032020-05-04 06:02:57.056817: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 793s 4s/step - loss: 0.1915 - accuracy: 0.9423 - categorical_crossentropy: 0.1915 - val_loss: 0.0842 - val_accuracy: 0.9773 - val_categorical_crossentropy: 0.0842\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1529 - accuracy: 0.9563 - categorical_crossentropy: 0.15292020-05-04 06:16:06.841706: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 790s 4s/step - loss: 0.1537 - accuracy: 0.9558 - categorical_crossentropy: 0.1537 - val_loss: 0.0735 - val_accuracy: 0.9886 - val_categorical_crossentropy: 0.0735\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1747 - accuracy: 0.9440 - categorical_crossentropy: 0.17472020-05-04 06:29:29.200277: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 802s 4s/step - loss: 0.1740 - accuracy: 0.9443 - categorical_crossentropy: 0.1740 - val_loss: 0.0781 - val_accuracy: 0.9716 - val_categorical_crossentropy: 0.0781\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1496 - accuracy: 0.9488 - categorical_crossentropy: 0.14962020-05-04 06:42:33.912112: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 785s 4s/step - loss: 0.1488 - accuracy: 0.9490 - categorical_crossentropy: 0.1488 - val_loss: 0.1087 - val_accuracy: 0.9659 - val_categorical_crossentropy: 0.1087\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1350 - accuracy: 0.9590 - categorical_crossentropy: 0.13502020-05-04 06:55:28.667187: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 775s 4s/step - loss: 0.1342 - accuracy: 0.9592 - categorical_crossentropy: 0.1342 - val_loss: 0.0974 - val_accuracy: 0.9659 - val_categorical_crossentropy: 0.0974\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1287 - accuracy: 0.9556 - categorical_crossentropy: 0.12872020-05-04 07:08:41.656886: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 793s 4s/step - loss: 0.1282 - accuracy: 0.9558 - categorical_crossentropy: 0.1282 - val_loss: 0.0880 - val_accuracy: 0.9773 - val_categorical_crossentropy: 0.0880\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1170 - accuracy: 0.9611 - categorical_crossentropy: 0.11702020-05-04 07:21:46.675298: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 785s 4s/step - loss: 0.1181 - accuracy: 0.9599 - categorical_crossentropy: 0.1181 - val_loss: 0.0779 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.0779\n",
      "Epoch 26/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1031 - accuracy: 0.9679 - categorical_crossentropy: 0.10312020-05-04 07:35:04.657321: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 798s 4s/step - loss: 0.1026 - accuracy: 0.9681 - categorical_crossentropy: 0.1026 - val_loss: 0.1068 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1068\n",
      "Epoch 27/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1266 - accuracy: 0.9577 - categorical_crossentropy: 0.12662020-05-04 07:48:25.288059: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 801s 4s/step - loss: 0.1261 - accuracy: 0.9579 - categorical_crossentropy: 0.1261 - val_loss: 0.0461 - val_accuracy: 0.9943 - val_categorical_crossentropy: 0.0461\n",
      "Epoch 28/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1039 - accuracy: 0.9652 - categorical_crossentropy: 0.10392020-05-04 08:01:35.755465: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 790s 4s/step - loss: 0.1043 - accuracy: 0.9647 - categorical_crossentropy: 0.1043 - val_loss: 0.0804 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.0804\n",
      "Epoch 29/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1058 - accuracy: 0.9583 - categorical_crossentropy: 0.10582020-05-04 08:14:51.772240: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 796s 4s/step - loss: 0.1054 - accuracy: 0.9586 - categorical_crossentropy: 0.1054 - val_loss: 0.0479 - val_accuracy: 0.9830 - val_categorical_crossentropy: 0.0479\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 4s - loss: 0.0945 - accuracy: 0.9686 - categorical_crossentropy: 0.09452020-05-04 08:28:02.839508: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 791s 4s/step - loss: 0.0942 - accuracy: 0.9688 - categorical_crossentropy: 0.0942 - val_loss: 0.0589 - val_accuracy: 0.9830 - val_categorical_crossentropy: 0.0589\n",
      "Epoch 31/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0930 - accuracy: 0.9686 - categorical_crossentropy: 0.09302020-05-04 08:41:11.311179: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 789s 4s/step - loss: 0.0925 - accuracy: 0.9688 - categorical_crossentropy: 0.0925 - val_loss: 0.0565 - val_accuracy: 0.9886 - val_categorical_crossentropy: 0.0565\n",
      "Epoch 32/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.1050 - accuracy: 0.9658 - categorical_crossentropy: 0.10502020-05-04 08:54:30.964084: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 802s 4s/step - loss: 0.1044 - accuracy: 0.9660 - categorical_crossentropy: 0.1044 - val_loss: 0.0346 - val_accuracy: 0.9886 - val_categorical_crossentropy: 0.0346\n",
      "Epoch 33/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0968 - accuracy: 0.9699 - categorical_crossentropy: 0.09682020-05-04 09:08:25.561727: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 833s 5s/step - loss: 0.0966 - accuracy: 0.9701 - categorical_crossentropy: 0.0966 - val_loss: 0.0444 - val_accuracy: 0.9773 - val_categorical_crossentropy: 0.0444\n",
      "Epoch 34/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0804 - accuracy: 0.9747 - categorical_crossentropy: 0.08042020-05-04 09:22:01.177120: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 816s 4s/step - loss: 0.0800 - accuracy: 0.9749 - categorical_crossentropy: 0.0800 - val_loss: 0.0196 - val_accuracy: 1.0000 - val_categorical_crossentropy: 0.0196\n",
      "Epoch 35/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0922 - accuracy: 0.9686 - categorical_crossentropy: 0.09222020-05-04 09:35:28.484134: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 807s 4s/step - loss: 0.0917 - accuracy: 0.9688 - categorical_crossentropy: 0.0917 - val_loss: 0.0460 - val_accuracy: 0.9830 - val_categorical_crossentropy: 0.0460\n",
      "Epoch 36/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0838 - accuracy: 0.9727 - categorical_crossentropy: 0.08382020-05-04 09:48:57.810990: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 810s 4s/step - loss: 0.0835 - accuracy: 0.9728 - categorical_crossentropy: 0.0835 - val_loss: 0.0424 - val_accuracy: 0.9886 - val_categorical_crossentropy: 0.0424\n",
      "Epoch 37/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0768 - accuracy: 0.9720 - categorical_crossentropy: 0.07682020-05-04 10:02:09.843076: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 791s 4s/step - loss: 0.0772 - accuracy: 0.9715 - categorical_crossentropy: 0.0772 - val_loss: 0.0375 - val_accuracy: 0.9830 - val_categorical_crossentropy: 0.0375\n",
      "Epoch 38/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0783 - accuracy: 0.9775 - categorical_crossentropy: 0.07832020-05-04 10:15:28.715158: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 799s 4s/step - loss: 0.0784 - accuracy: 0.9769 - categorical_crossentropy: 0.0784 - val_loss: 0.0147 - val_accuracy: 0.9943 - val_categorical_crossentropy: 0.0147\n",
      "Epoch 39/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0555 - accuracy: 0.9822 - categorical_crossentropy: 0.05552020-05-04 10:28:55.306838: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 806s 4s/step - loss: 0.0553 - accuracy: 0.9823 - categorical_crossentropy: 0.0553 - val_loss: 0.0243 - val_accuracy: 0.9943 - val_categorical_crossentropy: 0.0243\n",
      "Epoch 40/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0734 - accuracy: 0.9754 - categorical_crossentropy: 0.07342020-05-04 10:42:16.517416: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 802s 4s/step - loss: 0.0732 - accuracy: 0.9755 - categorical_crossentropy: 0.0732 - val_loss: 0.0584 - val_accuracy: 0.9716 - val_categorical_crossentropy: 0.0584\n",
      "Epoch 41/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0681 - accuracy: 0.9809 - categorical_crossentropy: 0.06812020-05-04 10:55:44.926270: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 808s 4s/step - loss: 0.0678 - accuracy: 0.9810 - categorical_crossentropy: 0.0678 - val_loss: 0.0307 - val_accuracy: 0.9943 - val_categorical_crossentropy: 0.0307\n",
      "Epoch 42/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0703 - accuracy: 0.9802 - categorical_crossentropy: 0.07032020-05-04 11:09:12.037204: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 807s 4s/step - loss: 0.0699 - accuracy: 0.9803 - categorical_crossentropy: 0.0699 - val_loss: 0.0381 - val_accuracy: 0.9943 - val_categorical_crossentropy: 0.0381\n",
      "Epoch 43/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0526 - accuracy: 0.9829 - categorical_crossentropy: 0.05262020-05-04 11:22:39.398385: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 808s 4s/step - loss: 0.0524 - accuracy: 0.9830 - categorical_crossentropy: 0.0524 - val_loss: 0.0196 - val_accuracy: 0.9943 - val_categorical_crossentropy: 0.0196\n",
      "Epoch 44/1000\n",
      "183/184 [============================>.] - ETA: 4s - loss: 0.0499 - accuracy: 0.9863 - categorical_crossentropy: 0.0499"
     ]
    }
   ],
   "source": [
    "# Proviamo come va con unfreeze di batchnorm e dimensione fissa. Cominciamo con nadam e poi provo anche gli altri.\n",
    "!python train.py \\\n",
    "--exp=11 \\\n",
    "--size=299 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-07 01:06:48.987618: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-07 01:06:49.020118: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199925000 Hz\n",
      "2020-05-07 01:06:49.020717: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558a98396750 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-07 01:06:49.020754: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-07 01:06:49.021813: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-07 01:07:00.257518: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 551s 3s/step - loss: 2.5561 - accuracy: 0.1447 - categorical_crossentropy: 2.5561 - val_loss: 2.3801 - val_accuracy: 0.1875 - val_categorical_crossentropy: 2.3801\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 1.9899 - accuracy: 0.3443 - categorical_crossentropy: 1.98992020-05-07 01:24:22.013399: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 520s 3s/step - loss: 1.9860 - accuracy: 0.3458 - categorical_crossentropy: 1.9860 - val_loss: 1.4602 - val_accuracy: 0.6023 - val_categorical_crossentropy: 1.4602\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 1.4670 - accuracy: 0.5171 - categorical_crossentropy: 1.46702020-05-07 01:34:00.455505: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 588s 3s/step - loss: 1.4665 - accuracy: 0.5170 - categorical_crossentropy: 1.4665 - val_loss: 1.1285 - val_accuracy: 0.6307 - val_categorical_crossentropy: 1.1285\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 1.1799 - accuracy: 0.6223 - categorical_crossentropy: 1.17992020-05-07 01:42:56.362565: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 526s 3s/step - loss: 1.1790 - accuracy: 0.6236 - categorical_crossentropy: 1.1790 - val_loss: 0.9913 - val_accuracy: 0.7102 - val_categorical_crossentropy: 0.9913\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.8890 - accuracy: 0.7077 - categorical_crossentropy: 0.88902020-05-07 01:51:42.594973: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 526s 3s/step - loss: 0.8875 - accuracy: 0.7079 - categorical_crossentropy: 0.8875 - val_loss: 0.7801 - val_accuracy: 0.7443 - val_categorical_crossentropy: 0.7801\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.7439 - accuracy: 0.7575 - categorical_crossentropy: 0.74392020-05-07 02:00:28.481843: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 526s 3s/step - loss: 0.7461 - accuracy: 0.7568 - categorical_crossentropy: 0.7461 - val_loss: 0.4313 - val_accuracy: 0.8523 - val_categorical_crossentropy: 0.4313\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.5799 - accuracy: 0.8183 - categorical_crossentropy: 0.57992020-05-07 02:09:07.513194: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 519s 3s/step - loss: 0.5782 - accuracy: 0.8193 - categorical_crossentropy: 0.5782 - val_loss: 0.3742 - val_accuracy: 0.8864 - val_categorical_crossentropy: 0.3742\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.5207 - accuracy: 0.8299 - categorical_crossentropy: 0.52072020-05-07 02:17:49.031214: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 521s 3s/step - loss: 0.5186 - accuracy: 0.8308 - categorical_crossentropy: 0.5186 - val_loss: 0.3600 - val_accuracy: 0.8977 - val_categorical_crossentropy: 0.3600\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.4189 - accuracy: 0.8641 - categorical_crossentropy: 0.41892020-05-07 02:26:24.136271: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 515s 3s/step - loss: 0.4182 - accuracy: 0.8648 - categorical_crossentropy: 0.4182 - val_loss: 0.3613 - val_accuracy: 0.8580 - val_categorical_crossentropy: 0.3613\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.3919 - accuracy: 0.8770 - categorical_crossentropy: 0.39192020-05-07 02:35:03.810516: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 520s 3s/step - loss: 0.3909 - accuracy: 0.8777 - categorical_crossentropy: 0.3909 - val_loss: 0.1886 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1886\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.3536 - accuracy: 0.8839 - categorical_crossentropy: 0.35362020-05-07 02:43:45.418043: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 521s 3s/step - loss: 0.3521 - accuracy: 0.8845 - categorical_crossentropy: 0.3521 - val_loss: 0.2169 - val_accuracy: 0.9375 - val_categorical_crossentropy: 0.2169\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.3320 - accuracy: 0.8969 - categorical_crossentropy: 0.33202020-05-07 02:52:24.815874: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 519s 3s/step - loss: 0.3305 - accuracy: 0.8974 - categorical_crossentropy: 0.3305 - val_loss: 0.2846 - val_accuracy: 0.9205 - val_categorical_crossentropy: 0.2846\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.2739 - accuracy: 0.9187 - categorical_crossentropy: 0.27392020-05-07 03:01:00.492536: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 516s 3s/step - loss: 0.2736 - accuracy: 0.9185 - categorical_crossentropy: 0.2736 - val_loss: 0.1472 - val_accuracy: 0.9773 - val_categorical_crossentropy: 0.1472\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 2s - loss: 0.2516 - accuracy: 0.9249 - categorical_crossentropy: 0.25162020-05-07 03:09:41.264224: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 521s 3s/step - loss: 0.2505 - accuracy: 0.9253 - categorical_crossentropy: 0.2505 - val_loss: 0.1242 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1242\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.2724 - accuracy: 0.9030 - categorical_crossentropy: 0.27242020-05-07 03:18:23.746838: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 522s 3s/step - loss: 0.2738 - accuracy: 0.9015 - categorical_crossentropy: 0.2738 - val_loss: 0.1173 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.1173\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.2196 - accuracy: 0.9276 - categorical_crossentropy: 0.21962020-05-07 03:27:03.664462: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 520s 3s/step - loss: 0.2194 - accuracy: 0.9273 - categorical_crossentropy: 0.2194 - val_loss: 0.1369 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.1369\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1926 - accuracy: 0.9365 - categorical_crossentropy: 0.19262020-05-07 03:35:47.237282: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 524s 3s/step - loss: 0.1922 - accuracy: 0.9368 - categorical_crossentropy: 0.1922 - val_loss: 0.1150 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1150\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1814 - accuracy: 0.9467 - categorical_crossentropy: 0.18142020-05-07 03:44:27.727469: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 520s 3s/step - loss: 0.1813 - accuracy: 0.9470 - categorical_crossentropy: 0.1813 - val_loss: 0.0683 - val_accuracy: 0.9830 - val_categorical_crossentropy: 0.0683\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1673 - accuracy: 0.9454 - categorical_crossentropy: 0.16732020-05-07 03:53:09.467526: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 522s 3s/step - loss: 0.1676 - accuracy: 0.9450 - categorical_crossentropy: 0.1676 - val_loss: 0.1321 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1321\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1487 - accuracy: 0.9536 - categorical_crossentropy: 0.14872020-05-07 04:01:48.195911: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 519s 3s/step - loss: 0.1482 - accuracy: 0.9538 - categorical_crossentropy: 0.1482 - val_loss: 0.0995 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.0995\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1286 - accuracy: 0.9556 - categorical_crossentropy: 0.12862020-05-07 04:10:24.219976: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 516s 3s/step - loss: 0.1280 - accuracy: 0.9558 - categorical_crossentropy: 0.1280 - val_loss: 0.0305 - val_accuracy: 1.0000 - val_categorical_crossentropy: 0.0305\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1252 - accuracy: 0.9556 - categorical_crossentropy: 0.12522020-05-07 04:19:04.215889: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 519s 3s/step - loss: 0.1246 - accuracy: 0.9558 - categorical_crossentropy: 0.1246 - val_loss: 0.1010 - val_accuracy: 0.9659 - val_categorical_crossentropy: 0.1010\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1369 - accuracy: 0.9542 - categorical_crossentropy: 0.13692020-05-07 04:27:40.655223: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 516s 3s/step - loss: 0.1365 - accuracy: 0.9545 - categorical_crossentropy: 0.1365 - val_loss: 0.0717 - val_accuracy: 0.9830 - val_categorical_crossentropy: 0.0717\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1165 - accuracy: 0.9624 - categorical_crossentropy: 0.11652020-05-07 04:36:18.116484: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 517s 3s/step - loss: 0.1164 - accuracy: 0.9626 - categorical_crossentropy: 0.1164 - val_loss: 0.0270 - val_accuracy: 0.9943 - val_categorical_crossentropy: 0.0270\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1195 - accuracy: 0.9604 - categorical_crossentropy: 0.11952020-05-07 04:44:56.560150: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 519s 3s/step - loss: 0.1193 - accuracy: 0.9606 - categorical_crossentropy: 0.1193 - val_loss: 0.0581 - val_accuracy: 0.9773 - val_categorical_crossentropy: 0.0581\n",
      "Epoch 26/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1053 - accuracy: 0.9672 - categorical_crossentropy: 0.10532020-05-07 04:53:33.434441: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 517s 3s/step - loss: 0.1068 - accuracy: 0.9667 - categorical_crossentropy: 0.1068 - val_loss: 0.0586 - val_accuracy: 0.9886 - val_categorical_crossentropy: 0.0586\n",
      "Epoch 27/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1216 - accuracy: 0.9563 - categorical_crossentropy: 0.12162020-05-07 05:02:12.392539: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 519s 3s/step - loss: 0.1211 - accuracy: 0.9565 - categorical_crossentropy: 0.1211 - val_loss: 0.0627 - val_accuracy: 0.9773 - val_categorical_crossentropy: 0.0627\n",
      "Epoch 28/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1095 - accuracy: 0.9638 - categorical_crossentropy: 0.10952020-05-07 05:10:53.891051: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 521s 3s/step - loss: 0.1100 - accuracy: 0.9633 - categorical_crossentropy: 0.1100 - val_loss: 0.0515 - val_accuracy: 0.9886 - val_categorical_crossentropy: 0.0515\n",
      "Epoch 29/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.0993 - accuracy: 0.9611 - categorical_crossentropy: 0.09932020-05-07 05:19:30.667923: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 517s 3s/step - loss: 0.0989 - accuracy: 0.9613 - categorical_crossentropy: 0.0989 - val_loss: 0.1470 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.1470\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 2s - loss: 0.0717 - accuracy: 0.9727 - categorical_crossentropy: 0.07172020-05-07 05:27:59.994973: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 509s 3s/step - loss: 0.0718 - accuracy: 0.9728 - categorical_crossentropy: 0.0718 - val_loss: 0.0267 - val_accuracy: 0.9886 - val_categorical_crossentropy: 0.0267\n",
      "Epoch 31/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.0798 - accuracy: 0.9734 - categorical_crossentropy: 0.07982020-05-07 05:36:35.969246: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 516s 3s/step - loss: 0.0820 - accuracy: 0.9728 - categorical_crossentropy: 0.0820 - val_loss: 0.0165 - val_accuracy: 0.9943 - val_categorical_crossentropy: 0.0165\n",
      "2020-05-07 05:36:55.720760: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-07 05:36:55.721940: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-07 05:36:56.152733: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.159390: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.162773: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.167105: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.170460: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.174314: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.178777: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.182519: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.186207: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.189540: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.192802: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.197098: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.200288: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.210559: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.214083: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.217826: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.221201: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.224980: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.228900: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.232835: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.238074: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.241725: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.245575: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.250312: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 05:36:56.254490: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-07 05:36:56.258527: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-05-07 05:36:56.262187: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-05-07 05:36:56.266256: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-05-07 05:36:56.270553: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-05-07 05:36:56.274318: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n",
      "2020-05-07 05:36:56.278062: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\r\n"
     ]
    }
   ],
   "source": [
    "# Riproviamo l'exp 11 ma con Adam.\n",
    "!python train.py \\\n",
    "--exp=12 \\\n",
    "--size=299 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"adam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-07 05:36:59.692499: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-07 05:36:59.724167: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199925000 Hz\n",
      "2020-05-07 05:36:59.724763: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cf0af04890 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-07 05:36:59.724784: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-07 05:36:59.725211: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-07 05:37:11.461935: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 752s 4s/step - loss: 2.7022 - accuracy: 0.0666 - categorical_crossentropy: 2.7022 - val_loss: 2.7777 - val_accuracy: 0.0455 - val_categorical_crossentropy: 2.7777\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 2.6891 - accuracy: 0.0642 - categorical_crossentropy: 2.68912020-05-07 06:01:36.495135: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 748s 4s/step - loss: 2.6889 - accuracy: 0.0645 - categorical_crossentropy: 2.6889 - val_loss: 2.6982 - val_accuracy: 0.0739 - val_categorical_crossentropy: 2.6982\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 2.6932 - accuracy: 0.0710 - categorical_crossentropy: 2.69322020-05-07 06:14:10.255300: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 754s 4s/step - loss: 2.6930 - accuracy: 0.0707 - categorical_crossentropy: 2.6930 - val_loss: 2.7489 - val_accuracy: 0.0795 - val_categorical_crossentropy: 2.7489\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 2.7002 - accuracy: 0.0546 - categorical_crossentropy: 2.70022020-05-07 06:26:48.776255: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 758s 4s/step - loss: 2.7008 - accuracy: 0.0543 - categorical_crossentropy: 2.7008 - val_loss: 2.7005 - val_accuracy: 0.0398 - val_categorical_crossentropy: 2.7005\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 2.6760 - accuracy: 0.0779 - categorical_crossentropy: 2.67602020-05-07 06:39:20.158396: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 751s 4s/step - loss: 2.6767 - accuracy: 0.0774 - categorical_crossentropy: 2.6767 - val_loss: 2.6889 - val_accuracy: 0.0511 - val_categorical_crossentropy: 2.6889\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 2.6755 - accuracy: 0.0615 - categorical_crossentropy: 2.67552020-05-07 06:51:54.667430: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 755s 4s/step - loss: 2.6763 - accuracy: 0.0611 - categorical_crossentropy: 2.6763 - val_loss: 2.6789 - val_accuracy: 0.0739 - val_categorical_crossentropy: 2.6789\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 2.6911 - accuracy: 0.0642 - categorical_crossentropy: 2.69112020-05-07 07:04:26.175835: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 751s 4s/step - loss: 2.6906 - accuracy: 0.0639 - categorical_crossentropy: 2.6906 - val_loss: 2.7144 - val_accuracy: 0.0455 - val_categorical_crossentropy: 2.7144\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 2.6769 - accuracy: 0.0683 - categorical_crossentropy: 2.67692020-05-07 07:16:58.387256: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 752s 4s/step - loss: 2.6758 - accuracy: 0.0693 - categorical_crossentropy: 2.6758 - val_loss: 2.7245 - val_accuracy: 0.0398 - val_categorical_crossentropy: 2.7245\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 2.6689 - accuracy: 0.0717 - categorical_crossentropy: 2.66892020-05-07 07:29:28.334775: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 750s 4s/step - loss: 2.6688 - accuracy: 0.0713 - categorical_crossentropy: 2.6688 - val_loss: 2.7022 - val_accuracy: 0.0511 - val_categorical_crossentropy: 2.7022\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 2.6745 - accuracy: 0.0669 - categorical_crossentropy: 2.67452020-05-07 07:42:06.742610: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 758s 4s/step - loss: 2.6743 - accuracy: 0.0666 - categorical_crossentropy: 2.6743 - val_loss: 2.6541 - val_accuracy: 0.0682 - val_categorical_crossentropy: 2.6541\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 2.6567 - accuracy: 0.0895 - categorical_crossentropy: 2.65672020-05-07 07:54:40.116778: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 754s 4s/step - loss: 2.6567 - accuracy: 0.0890 - categorical_crossentropy: 2.6567 - val_loss: 2.6905 - val_accuracy: 0.0625 - val_categorical_crossentropy: 2.6905\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 2.6603 - accuracy: 0.0786 - categorical_crossentropy: 2.66032020-05-07 08:07:11.024419: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 751s 4s/step - loss: 2.6599 - accuracy: 0.0781 - categorical_crossentropy: 2.6599 - val_loss: 2.6837 - val_accuracy: 0.0739 - val_categorical_crossentropy: 2.6837\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 3s - loss: 2.6705 - accuracy: 0.0704 - categorical_crossentropy: 2.67052020-05-07 08:19:41.943525: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 751s 4s/step - loss: 2.6702 - accuracy: 0.0700 - categorical_crossentropy: 2.6702 - val_loss: 2.6955 - val_accuracy: 0.0455 - val_categorical_crossentropy: 2.6955\n",
      "2020-05-07 08:20:07.482662: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-07 08:20:07.483120: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-07 08:20:07.943296: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:07.946503: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:07.950781: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:07.954096: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:07.958629: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:07.963028: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:07.966254: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:07.969749: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:08.005067: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:08.008271: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:08.014167: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:08.016875: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:08.019422: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 08:20:08.022132: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Riproviamo l'exp 11 ma con Adadelta.\n",
    "!python train.py \\\n",
    "--exp=13 \\\n",
    "--size=299 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"adadelta\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-07 18:37:21.781127: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-07 18:37:21.814550: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199870000 Hz\n",
      "2020-05-07 18:37:21.815273: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c1512a9890 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-07 18:37:21.815310: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-07 18:37:21.816820: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 184 steps, validate for 22 steps\n",
      "Epoch 1/1000\n",
      "2020-05-07 18:37:34.680682: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "184/184 [==============================] - 527s 3s/step - loss: 2.5856 - accuracy: 0.1243 - categorical_crossentropy: 2.5856 - val_loss: 2.3793 - val_accuracy: 0.1705 - val_categorical_crossentropy: 2.3793\n",
      "Epoch 2/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 2.1266 - accuracy: 0.2951 - categorical_crossentropy: 2.12662020-05-07 18:54:24.767898: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 513s 3s/step - loss: 2.1255 - accuracy: 0.2948 - categorical_crossentropy: 2.1255 - val_loss: 1.8121 - val_accuracy: 0.4091 - val_categorical_crossentropy: 1.8121\n",
      "Epoch 3/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 1.7103 - accuracy: 0.4392 - categorical_crossentropy: 1.71032020-05-07 19:02:56.285661: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 511s 3s/step - loss: 1.7062 - accuracy: 0.4416 - categorical_crossentropy: 1.7062 - val_loss: 1.3653 - val_accuracy: 0.5625 - val_categorical_crossentropy: 1.3653\n",
      "Epoch 4/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 1.3399 - accuracy: 0.5417 - categorical_crossentropy: 1.33992020-05-07 19:11:34.879795: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 519s 3s/step - loss: 1.3397 - accuracy: 0.5421 - categorical_crossentropy: 1.3397 - val_loss: 1.2557 - val_accuracy: 0.5909 - val_categorical_crossentropy: 1.2557\n",
      "Epoch 5/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 1.1070 - accuracy: 0.6352 - categorical_crossentropy: 1.10702020-05-07 19:20:10.694698: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 516s 3s/step - loss: 1.1082 - accuracy: 0.6345 - categorical_crossentropy: 1.1082 - val_loss: 0.9156 - val_accuracy: 0.7102 - val_categorical_crossentropy: 0.9156\n",
      "Epoch 6/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.9413 - accuracy: 0.6803 - categorical_crossentropy: 0.94132020-05-07 19:28:49.045804: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 518s 3s/step - loss: 0.9446 - accuracy: 0.6787 - categorical_crossentropy: 0.9446 - val_loss: 0.7896 - val_accuracy: 0.7102 - val_categorical_crossentropy: 0.7896\n",
      "Epoch 7/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.8038 - accuracy: 0.7357 - categorical_crossentropy: 0.80382020-05-07 19:37:26.642492: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 518s 3s/step - loss: 0.8057 - accuracy: 0.7351 - categorical_crossentropy: 0.8057 - val_loss: 0.4756 - val_accuracy: 0.8693 - val_categorical_crossentropy: 0.4756\n",
      "Epoch 8/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.6298 - accuracy: 0.7903 - categorical_crossentropy: 0.62982020-05-07 19:46:00.958117: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 514s 3s/step - loss: 0.6276 - accuracy: 0.7914 - categorical_crossentropy: 0.6276 - val_loss: 0.4149 - val_accuracy: 0.8636 - val_categorical_crossentropy: 0.4149\n",
      "Epoch 9/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.5878 - accuracy: 0.7923 - categorical_crossentropy: 0.58782020-05-07 19:54:33.495165: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 512s 3s/step - loss: 0.5869 - accuracy: 0.7928 - categorical_crossentropy: 0.5869 - val_loss: 0.3711 - val_accuracy: 0.8693 - val_categorical_crossentropy: 0.3711\n",
      "Epoch 10/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.5337 - accuracy: 0.8327 - categorical_crossentropy: 0.53372020-05-07 20:03:09.622820: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 516s 3s/step - loss: 0.5349 - accuracy: 0.8329 - categorical_crossentropy: 0.5349 - val_loss: 0.3741 - val_accuracy: 0.8807 - val_categorical_crossentropy: 0.3741\n",
      "Epoch 11/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.4629 - accuracy: 0.8381 - categorical_crossentropy: 0.46292020-05-07 20:11:41.230377: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 511s 3s/step - loss: 0.4614 - accuracy: 0.8390 - categorical_crossentropy: 0.4614 - val_loss: 0.3020 - val_accuracy: 0.8977 - val_categorical_crossentropy: 0.3020\n",
      "Epoch 12/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.3910 - accuracy: 0.8730 - categorical_crossentropy: 0.39102020-05-07 20:20:14.727151: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 513s 3s/step - loss: 0.3916 - accuracy: 0.8723 - categorical_crossentropy: 0.3916 - val_loss: 0.3198 - val_accuracy: 0.9148 - val_categorical_crossentropy: 0.3198\n",
      "Epoch 13/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.3623 - accuracy: 0.8702 - categorical_crossentropy: 0.36232020-05-07 20:28:47.895524: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 513s 3s/step - loss: 0.3683 - accuracy: 0.8696 - categorical_crossentropy: 0.3683 - val_loss: 0.2183 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.2183\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/184 [============================>.] - ETA: 2s - loss: 0.3494 - accuracy: 0.8716 - categorical_crossentropy: 0.34942020-05-07 20:37:25.679683: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 518s 3s/step - loss: 0.3475 - accuracy: 0.8723 - categorical_crossentropy: 0.3475 - val_loss: 0.1979 - val_accuracy: 0.9375 - val_categorical_crossentropy: 0.1979\n",
      "Epoch 15/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.2814 - accuracy: 0.8989 - categorical_crossentropy: 0.28142020-05-07 20:45:59.446500: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 513s 3s/step - loss: 0.2822 - accuracy: 0.8988 - categorical_crossentropy: 0.2822 - val_loss: 0.2732 - val_accuracy: 0.8977 - val_categorical_crossentropy: 0.2732\n",
      "Epoch 16/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.3046 - accuracy: 0.9010 - categorical_crossentropy: 0.30462020-05-07 20:54:36.500531: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 517s 3s/step - loss: 0.3061 - accuracy: 0.9001 - categorical_crossentropy: 0.3061 - val_loss: 0.1220 - val_accuracy: 0.9545 - val_categorical_crossentropy: 0.1220\n",
      "Epoch 17/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.2418 - accuracy: 0.9173 - categorical_crossentropy: 0.24182020-05-07 21:03:11.968404: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 515s 3s/step - loss: 0.2416 - accuracy: 0.9171 - categorical_crossentropy: 0.2416 - val_loss: 0.0979 - val_accuracy: 0.9830 - val_categorical_crossentropy: 0.0979\n",
      "Epoch 18/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.2109 - accuracy: 0.9214 - categorical_crossentropy: 0.21092020-05-07 21:11:46.508147: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 515s 3s/step - loss: 0.2099 - accuracy: 0.9219 - categorical_crossentropy: 0.2099 - val_loss: 0.2067 - val_accuracy: 0.9432 - val_categorical_crossentropy: 0.2067\n",
      "Epoch 19/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.2042 - accuracy: 0.9290 - categorical_crossentropy: 0.20422020-05-07 21:20:23.100600: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 516s 3s/step - loss: 0.2031 - accuracy: 0.9293 - categorical_crossentropy: 0.2031 - val_loss: 0.0634 - val_accuracy: 0.9773 - val_categorical_crossentropy: 0.0634\n",
      "Epoch 20/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.2011 - accuracy: 0.9317 - categorical_crossentropy: 0.20112020-05-07 21:28:53.597122: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 511s 3s/step - loss: 0.2008 - accuracy: 0.9321 - categorical_crossentropy: 0.2008 - val_loss: 0.1336 - val_accuracy: 0.9489 - val_categorical_crossentropy: 0.1336\n",
      "Epoch 21/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.2174 - accuracy: 0.9296 - categorical_crossentropy: 0.21742020-05-07 21:37:24.915227: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 512s 3s/step - loss: 0.2180 - accuracy: 0.9293 - categorical_crossentropy: 0.2180 - val_loss: 0.0894 - val_accuracy: 0.9659 - val_categorical_crossentropy: 0.0894\n",
      "Epoch 22/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1815 - accuracy: 0.9392 - categorical_crossentropy: 0.18152020-05-07 21:45:55.513054: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 510s 3s/step - loss: 0.1806 - accuracy: 0.9395 - categorical_crossentropy: 0.1806 - val_loss: 0.1209 - val_accuracy: 0.9659 - val_categorical_crossentropy: 0.1209\n",
      "Epoch 23/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1611 - accuracy: 0.9413 - categorical_crossentropy: 0.16112020-05-07 21:54:29.007788: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 513s 3s/step - loss: 0.1616 - accuracy: 0.9416 - categorical_crossentropy: 0.1616 - val_loss: 0.0864 - val_accuracy: 0.9716 - val_categorical_crossentropy: 0.0864\n",
      "Epoch 24/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1749 - accuracy: 0.9447 - categorical_crossentropy: 0.17492020-05-07 22:03:05.391532: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 523s 3s/step - loss: 0.1740 - accuracy: 0.9450 - categorical_crossentropy: 0.1740 - val_loss: 0.0727 - val_accuracy: 0.9659 - val_categorical_crossentropy: 0.0727\n",
      "Epoch 25/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1478 - accuracy: 0.9529 - categorical_crossentropy: 0.14782020-05-07 22:11:46.350070: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 514s 3s/step - loss: 0.1490 - accuracy: 0.9524 - categorical_crossentropy: 0.1490 - val_loss: 0.0855 - val_accuracy: 0.9716 - val_categorical_crossentropy: 0.0855\n",
      "Epoch 26/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1167 - accuracy: 0.9638 - categorical_crossentropy: 0.11672020-05-07 22:20:15.727813: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 510s 3s/step - loss: 0.1193 - accuracy: 0.9633 - categorical_crossentropy: 0.1193 - val_loss: 0.1385 - val_accuracy: 0.9602 - val_categorical_crossentropy: 0.1385\n",
      "Epoch 27/1000\n",
      "183/184 [============================>.] - ETA: 2s - loss: 0.1509 - accuracy: 0.9556 - categorical_crossentropy: 0.15092020-05-07 22:28:46.678070: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "184/184 [==============================] - 511s 3s/step - loss: 0.1501 - accuracy: 0.9558 - categorical_crossentropy: 0.1501 - val_loss: 0.0963 - val_accuracy: 0.9773 - val_categorical_crossentropy: 0.0963\n",
      "2020-05-07 22:29:06.689876: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-07 22:29:06.690632: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-07 22:29:07.107832: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.112609: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.116176: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.120141: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.124070: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.128809: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.131847: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.135405: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.138552: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-07 22:29:07.142935: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.152586: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.156002: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.160584: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.164442: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.167945: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.171017: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.174018: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.179454: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.183341: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.188563: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.192856: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.198334: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.202177: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.205842: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.210788: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.214747: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-07 22:29:07.219121: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Riproviamo l'exp 11 ma con RMSProp.\n",
    "!python train.py \\\n",
    "--exp=14 \\\n",
    "--size=299 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"rmsprop\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-09 00:13:37.288740: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-09 00:13:37.322471: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200145000 Hz\n",
      "2020-05-09 00:13:37.323042: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e89366ba40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-09 00:13:37.323063: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-09 00:13:37.324134: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 411 steps, validate for 51 steps\n",
      "Epoch 1/1000\n",
      "2020-05-09 00:13:53.303228: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "411/411 [==============================] - 1181s 3s/step - loss: 3.0155 - accuracy: 0.1648 - categorical_crossentropy: 3.0155 - val_loss: 2.2711 - val_accuracy: 0.3627 - val_categorical_crossentropy: 2.2711\n",
      "Epoch 2/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 1.8101 - accuracy: 0.4741 - categorical_crossentropy: 1.81012020-05-09 00:51:35.138665: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1141s 3s/step - loss: 1.8082 - accuracy: 0.4748 - categorical_crossentropy: 1.8082 - val_loss: 1.4439 - val_accuracy: 0.5662 - val_categorical_crossentropy: 1.4439\n",
      "Epoch 3/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 1.2177 - accuracy: 0.6314 - categorical_crossentropy: 1.21772020-05-09 01:10:31.783932: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1136s 3s/step - loss: 1.2168 - accuracy: 0.6314 - categorical_crossentropy: 1.2168 - val_loss: 0.8754 - val_accuracy: 0.7328 - val_categorical_crossentropy: 0.8754\n",
      "Epoch 4/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.8433 - accuracy: 0.7402 - categorical_crossentropy: 0.84332020-05-09 01:29:40.828668: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1149s 3s/step - loss: 0.8434 - accuracy: 0.7403 - categorical_crossentropy: 0.8434 - val_loss: 0.6573 - val_accuracy: 0.7770 - val_categorical_crossentropy: 0.6573\n",
      "Epoch 5/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.6725 - accuracy: 0.7912 - categorical_crossentropy: 0.67252020-05-09 01:48:40.656767: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1140s 3s/step - loss: 0.6721 - accuracy: 0.7914 - categorical_crossentropy: 0.6721 - val_loss: 0.3886 - val_accuracy: 0.8873 - val_categorical_crossentropy: 0.3886\n",
      "Epoch 6/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.5325 - accuracy: 0.8274 - categorical_crossentropy: 0.53252020-05-09 02:07:48.478067: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1147s 3s/step - loss: 0.5315 - accuracy: 0.8279 - categorical_crossentropy: 0.5315 - val_loss: 0.3135 - val_accuracy: 0.9093 - val_categorical_crossentropy: 0.3135\n",
      "Epoch 7/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.4509 - accuracy: 0.8512 - categorical_crossentropy: 0.45092020-05-09 02:26:56.105651: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1147s 3s/step - loss: 0.4514 - accuracy: 0.8513 - categorical_crossentropy: 0.4514 - val_loss: 0.3314 - val_accuracy: 0.9069 - val_categorical_crossentropy: 0.3314\n",
      "Epoch 8/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.3775 - accuracy: 0.8811 - categorical_crossentropy: 0.37752020-05-09 02:45:53.706760: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1138s 3s/step - loss: 0.3769 - accuracy: 0.8814 - categorical_crossentropy: 0.3769 - val_loss: 0.3019 - val_accuracy: 0.8995 - val_categorical_crossentropy: 0.3019\n",
      "Epoch 9/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.3202 - accuracy: 0.8997 - categorical_crossentropy: 0.32022020-05-09 03:05:00.645647: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1147s 3s/step - loss: 0.3195 - accuracy: 0.8999 - categorical_crossentropy: 0.3195 - val_loss: 0.1676 - val_accuracy: 0.9559 - val_categorical_crossentropy: 0.1676\n",
      "Epoch 10/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.2761 - accuracy: 0.9128 - categorical_crossentropy: 0.27612020-05-09 03:24:12.439879: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1152s 3s/step - loss: 0.2766 - accuracy: 0.9124 - categorical_crossentropy: 0.2766 - val_loss: 0.1692 - val_accuracy: 0.9485 - val_categorical_crossentropy: 0.1692\n",
      "Epoch 11/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.2469 - accuracy: 0.9238 - categorical_crossentropy: 0.24692020-05-09 03:43:20.242381: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1148s 3s/step - loss: 0.2469 - accuracy: 0.9240 - categorical_crossentropy: 0.2469 - val_loss: 0.2042 - val_accuracy: 0.9412 - val_categorical_crossentropy: 0.2042\n",
      "Epoch 12/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.2162 - accuracy: 0.9360 - categorical_crossentropy: 0.21622020-05-09 04:02:23.486688: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1143s 3s/step - loss: 0.2176 - accuracy: 0.9358 - categorical_crossentropy: 0.2176 - val_loss: 0.1566 - val_accuracy: 0.9485 - val_categorical_crossentropy: 0.1566\n",
      "Epoch 13/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.2220 - accuracy: 0.9280 - categorical_crossentropy: 0.22202020-05-09 04:21:28.231624: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1145s 3s/step - loss: 0.2224 - accuracy: 0.9279 - categorical_crossentropy: 0.2224 - val_loss: 0.1500 - val_accuracy: 0.9583 - val_categorical_crossentropy: 0.1500\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410/411 [============================>.] - ETA: 2s - loss: 0.1785 - accuracy: 0.9451 - categorical_crossentropy: 0.17852020-05-09 04:40:28.657256: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1140s 3s/step - loss: 0.1785 - accuracy: 0.9453 - categorical_crossentropy: 0.1785 - val_loss: 0.1132 - val_accuracy: 0.9706 - val_categorical_crossentropy: 0.1132\n",
      "Epoch 15/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.1523 - accuracy: 0.9549 - categorical_crossentropy: 0.15232020-05-09 04:59:37.261538: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1149s 3s/step - loss: 0.1523 - accuracy: 0.9547 - categorical_crossentropy: 0.1523 - val_loss: 0.1047 - val_accuracy: 0.9706 - val_categorical_crossentropy: 0.1047\n",
      "Epoch 16/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.1571 - accuracy: 0.9509 - categorical_crossentropy: 0.15712020-05-09 05:18:33.128498: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1136s 3s/step - loss: 0.1568 - accuracy: 0.9510 - categorical_crossentropy: 0.1568 - val_loss: 0.1260 - val_accuracy: 0.9608 - val_categorical_crossentropy: 0.1260\n",
      "Epoch 17/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.1475 - accuracy: 0.9524 - categorical_crossentropy: 0.14752020-05-09 05:37:32.479538: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1139s 3s/step - loss: 0.1474 - accuracy: 0.9526 - categorical_crossentropy: 0.1474 - val_loss: 0.0742 - val_accuracy: 0.9730 - val_categorical_crossentropy: 0.0742\n",
      "Epoch 18/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.1286 - accuracy: 0.9567 - categorical_crossentropy: 0.12862020-05-09 05:56:30.504826: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1138s 3s/step - loss: 0.1286 - accuracy: 0.9565 - categorical_crossentropy: 0.1286 - val_loss: 0.0909 - val_accuracy: 0.9730 - val_categorical_crossentropy: 0.0909\n",
      "Epoch 19/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.1208 - accuracy: 0.9579 - categorical_crossentropy: 0.12082020-05-09 06:15:38.608354: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1150s 3s/step - loss: 0.1208 - accuracy: 0.9580 - categorical_crossentropy: 0.1208 - val_loss: 0.0829 - val_accuracy: 0.9657 - val_categorical_crossentropy: 0.0829\n",
      "Epoch 20/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.1307 - accuracy: 0.9567 - categorical_crossentropy: 0.13072020-05-09 06:34:41.736106: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1141s 3s/step - loss: 0.1305 - accuracy: 0.9568 - categorical_crossentropy: 0.1305 - val_loss: 0.0675 - val_accuracy: 0.9877 - val_categorical_crossentropy: 0.0675\n",
      "Epoch 21/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.1144 - accuracy: 0.9625 - categorical_crossentropy: 0.11442020-05-09 06:53:37.655158: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1136s 3s/step - loss: 0.1141 - accuracy: 0.9626 - categorical_crossentropy: 0.1141 - val_loss: 0.0822 - val_accuracy: 0.9730 - val_categorical_crossentropy: 0.0822\n",
      "Epoch 22/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.1003 - accuracy: 0.9689 - categorical_crossentropy: 0.10032020-05-09 07:12:36.056482: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1139s 3s/step - loss: 0.1003 - accuracy: 0.9690 - categorical_crossentropy: 0.1003 - val_loss: 0.0426 - val_accuracy: 0.9877 - val_categorical_crossentropy: 0.0426\n",
      "Epoch 23/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.1050 - accuracy: 0.9628 - categorical_crossentropy: 0.10502020-05-09 07:31:40.642044: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1144s 3s/step - loss: 0.1048 - accuracy: 0.9629 - categorical_crossentropy: 0.1048 - val_loss: 0.0281 - val_accuracy: 0.9902 - val_categorical_crossentropy: 0.0281\n",
      "Epoch 24/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.0832 - accuracy: 0.9753 - categorical_crossentropy: 0.08322020-05-09 07:50:47.714532: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1147s 3s/step - loss: 0.0833 - accuracy: 0.9751 - categorical_crossentropy: 0.0833 - val_loss: 0.0641 - val_accuracy: 0.9804 - val_categorical_crossentropy: 0.0641\n",
      "Epoch 25/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.1019 - accuracy: 0.9659 - categorical_crossentropy: 0.10192020-05-09 08:09:59.182823: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1152s 3s/step - loss: 0.1026 - accuracy: 0.9653 - categorical_crossentropy: 0.1026 - val_loss: 0.1108 - val_accuracy: 0.9730 - val_categorical_crossentropy: 0.1108\n",
      "Epoch 26/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.1088 - accuracy: 0.9637 - categorical_crossentropy: 0.10882020-05-09 08:29:08.440845: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1149s 3s/step - loss: 0.1092 - accuracy: 0.9635 - categorical_crossentropy: 0.1092 - val_loss: 0.0577 - val_accuracy: 0.9828 - val_categorical_crossentropy: 0.0577\n",
      "Epoch 27/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.0835 - accuracy: 0.9732 - categorical_crossentropy: 0.08352020-05-09 08:48:33.592214: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1165s 3s/step - loss: 0.0836 - accuracy: 0.9732 - categorical_crossentropy: 0.0836 - val_loss: 0.0622 - val_accuracy: 0.9804 - val_categorical_crossentropy: 0.0622\n",
      "Epoch 28/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.0942 - accuracy: 0.9716 - categorical_crossentropy: 0.09422020-05-09 09:07:46.321986: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1152s 3s/step - loss: 0.0940 - accuracy: 0.9717 - categorical_crossentropy: 0.0940 - val_loss: 0.0354 - val_accuracy: 0.9853 - val_categorical_crossentropy: 0.0354\n",
      "Epoch 29/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.0729 - accuracy: 0.9768 - categorical_crossentropy: 0.07292020-05-09 09:27:27.832610: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1198s 3s/step - loss: 0.0730 - accuracy: 0.9766 - categorical_crossentropy: 0.0730 - val_loss: 0.0267 - val_accuracy: 0.9926 - val_categorical_crossentropy: 0.0267\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410/411 [============================>.] - ETA: 2s - loss: 0.0747 - accuracy: 0.9747 - categorical_crossentropy: 0.07472020-05-09 09:46:54.289901: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1150s 3s/step - loss: 0.0745 - accuracy: 0.9748 - categorical_crossentropy: 0.0745 - val_loss: 0.0294 - val_accuracy: 0.9926 - val_categorical_crossentropy: 0.0294\n",
      "Epoch 31/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.0686 - accuracy: 0.9820 - categorical_crossentropy: 0.06862020-05-09 10:05:59.216310: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1145s 3s/step - loss: 0.0687 - accuracy: 0.9821 - categorical_crossentropy: 0.0687 - val_loss: 0.0662 - val_accuracy: 0.9828 - val_categorical_crossentropy: 0.0662\n",
      "Epoch 32/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.0659 - accuracy: 0.9796 - categorical_crossentropy: 0.06592020-05-09 10:25:12.830853: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1154s 3s/step - loss: 0.0659 - accuracy: 0.9796 - categorical_crossentropy: 0.0659 - val_loss: 0.0288 - val_accuracy: 0.9902 - val_categorical_crossentropy: 0.0288\n",
      "Epoch 33/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.0791 - accuracy: 0.9759 - categorical_crossentropy: 0.07912020-05-09 10:44:49.901820: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1177s 3s/step - loss: 0.0789 - accuracy: 0.9760 - categorical_crossentropy: 0.0789 - val_loss: 0.0356 - val_accuracy: 0.9902 - val_categorical_crossentropy: 0.0356\n",
      "Epoch 34/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.0618 - accuracy: 0.9802 - categorical_crossentropy: 0.06182020-05-09 11:04:06.843870: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1157s 3s/step - loss: 0.0617 - accuracy: 0.9802 - categorical_crossentropy: 0.0617 - val_loss: 0.0826 - val_accuracy: 0.9779 - val_categorical_crossentropy: 0.0826\n",
      "Epoch 35/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.0601 - accuracy: 0.9787 - categorical_crossentropy: 0.06012020-05-09 11:23:22.041842: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1155s 3s/step - loss: 0.0604 - accuracy: 0.9787 - categorical_crossentropy: 0.0604 - val_loss: 0.0334 - val_accuracy: 0.9877 - val_categorical_crossentropy: 0.0334\n",
      "Epoch 36/1000\n",
      "410/411 [============================>.] - ETA: 3s - loss: 0.0487 - accuracy: 0.9854 - categorical_crossentropy: 0.04872020-05-09 11:46:02.524454: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1369s 3s/step - loss: 0.0489 - accuracy: 0.9854 - categorical_crossentropy: 0.0489 - val_loss: 0.0183 - val_accuracy: 0.9926 - val_categorical_crossentropy: 0.0183\n",
      "Epoch 37/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.0563 - accuracy: 0.9817 - categorical_crossentropy: 0.05632020-05-09 12:06:51.631965: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1241s 3s/step - loss: 0.0562 - accuracy: 0.9818 - categorical_crossentropy: 0.0562 - val_loss: 0.0495 - val_accuracy: 0.9853 - val_categorical_crossentropy: 0.0495\n",
      "Epoch 38/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.0657 - accuracy: 0.9774 - categorical_crossentropy: 0.06572020-05-09 12:26:14.422400: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1162s 3s/step - loss: 0.0655 - accuracy: 0.9775 - categorical_crossentropy: 0.0655 - val_loss: 0.0522 - val_accuracy: 0.9853 - val_categorical_crossentropy: 0.0522\n",
      "Epoch 39/1000\n",
      "410/411 [============================>.] - ETA: 2s - loss: 0.0561 - accuracy: 0.9799 - categorical_crossentropy: 0.05612020-05-09 12:45:36.199368: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "411/411 [==============================] - 1162s 3s/step - loss: 0.0560 - accuracy: 0.9799 - categorical_crossentropy: 0.0560 - val_loss: 0.0543 - val_accuracy: 0.9706 - val_categorical_crossentropy: 0.0543\n",
      "2020-05-09 12:46:22.582439: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-09 12:46:22.584337: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-09 12:46:23.319026: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.327049: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.333641: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.339088: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.344487: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.350841: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.357764: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-09 12:46:23.364142: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.371644: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.378680: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.385254: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.391929: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.402312: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.408914: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.414679: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.423606: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.429501: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.436753: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.443325: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.451020: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.469839: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.476419: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.482091: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.488809: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.495255: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.506235: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.512787: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-09 12:46:23.519697: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.530411: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.535974: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.541877: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.552397: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.559010: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.568051: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.574312: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.581750: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.587765: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.593322: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-09 12:46:23.598415: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Riproviamo l'exp 11 ma con più classi (30)\n",
    "!python train.py \\\n",
    "--exp=15 \\\n",
    "--size=299 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--class_names_file=\"class_names_30.txt\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-10 00:34:34.512819: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-10 00:34:34.535927: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199975000 Hz\n",
      "2020-05-10 00:34:34.536224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555aa8b13a40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-10 00:34:34.536251: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-10 00:34:34.536355: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 839 steps, validate for 104 steps\n",
      "Epoch 1/1000\n",
      "2020-05-10 00:34:51.408294: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "839/839 [==============================] - 3518s 4s/step - loss: 3.4717 - accuracy: 0.1482 - categorical_crossentropy: 3.4717 - val_loss: 2.2672 - val_accuracy: 0.3834 - val_categorical_crossentropy: 2.2672\n",
      "Epoch 2/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 1.7990 - accuracy: 0.4884 - categorical_crossentropy: 1.79902020-05-10 02:30:30.831099: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3557s 4s/step - loss: 1.7993 - accuracy: 0.4881 - categorical_crossentropy: 1.7993 - val_loss: 1.2079 - val_accuracy: 0.6298 - val_categorical_crossentropy: 1.2079\n",
      "Epoch 3/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 1.1305 - accuracy: 0.6699 - categorical_crossentropy: 1.13052020-05-10 03:29:43.029646: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3552s 4s/step - loss: 1.1303 - accuracy: 0.6698 - categorical_crossentropy: 1.1303 - val_loss: 0.7132 - val_accuracy: 0.7873 - val_categorical_crossentropy: 0.7132\n",
      "Epoch 4/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.7795 - accuracy: 0.7582 - categorical_crossentropy: 0.77952020-05-10 04:29:14.239989: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3571s 4s/step - loss: 0.7795 - accuracy: 0.7582 - categorical_crossentropy: 0.7795 - val_loss: 0.5039 - val_accuracy: 0.8341 - val_categorical_crossentropy: 0.5039\n",
      "Epoch 5/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.5909 - accuracy: 0.8201 - categorical_crossentropy: 0.59092020-05-10 05:28:27.168079: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3553s 4s/step - loss: 0.5911 - accuracy: 0.8199 - categorical_crossentropy: 0.5911 - val_loss: 0.3378 - val_accuracy: 0.8870 - val_categorical_crossentropy: 0.3378\n",
      "Epoch 6/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.4649 - accuracy: 0.8586 - categorical_crossentropy: 0.46492020-05-10 06:27:54.606105: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3568s 4s/step - loss: 0.4646 - accuracy: 0.8588 - categorical_crossentropy: 0.4646 - val_loss: 0.2461 - val_accuracy: 0.9267 - val_categorical_crossentropy: 0.2461\n",
      "Epoch 7/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.3908 - accuracy: 0.8772 - categorical_crossentropy: 0.39082020-05-10 07:27:40.671443: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3586s 4s/step - loss: 0.3909 - accuracy: 0.8771 - categorical_crossentropy: 0.3909 - val_loss: 0.2294 - val_accuracy: 0.9291 - val_categorical_crossentropy: 0.2294\n",
      "Epoch 8/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.3336 - accuracy: 0.8983 - categorical_crossentropy: 0.33362020-05-10 08:27:35.383549: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3594s 4s/step - loss: 0.3333 - accuracy: 0.8984 - categorical_crossentropy: 0.3333 - val_loss: 0.2144 - val_accuracy: 0.9291 - val_categorical_crossentropy: 0.2144\n",
      "Epoch 9/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.2999 - accuracy: 0.9024 - categorical_crossentropy: 0.29992020-05-10 09:27:26.706679: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3592s 4s/step - loss: 0.2998 - accuracy: 0.9026 - categorical_crossentropy: 0.2998 - val_loss: 0.1423 - val_accuracy: 0.9555 - val_categorical_crossentropy: 0.1423\n",
      "Epoch 10/1000\n",
      "194/839 [=====>........................] - ETA: 45:30 - loss: 0.2854 - accuracy: 0.9079 - categorical_crossentropy: 0.2854"
     ]
    }
   ],
   "source": [
    "# Riproviamo l'exp 11 ma con più classi (62)\n",
    "!python train.py \\\n",
    "--exp=16 \\\n",
    "--size=299 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--class_names_file=\"class_names_62.txt\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-10 22:49:47.555627: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-10 22:49:47.580652: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199925000 Hz\n",
      "2020-05-10 22:49:47.580967: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5596f71789d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-10 22:49:47.581011: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-10 22:49:47.581120: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 839 steps, validate for 104 steps\n",
      "Epoch 10/1000\n",
      "2020-05-10 22:50:04.959039: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "839/839 [==============================] - 3653s 4s/step - loss: 0.2307 - accuracy: 0.9324 - categorical_crossentropy: 0.2307 - val_loss: 0.1366 - val_accuracy: 0.9579 - val_categorical_crossentropy: 0.1366\n",
      "Epoch 11/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.2322 - accuracy: 0.9268 - categorical_crossentropy: 0.23222020-05-11 00:48:35.159492: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3592s 4s/step - loss: 0.2321 - accuracy: 0.9267 - categorical_crossentropy: 0.2321 - val_loss: 0.1381 - val_accuracy: 0.9555 - val_categorical_crossentropy: 0.1381\n",
      "Epoch 12/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.2045 - accuracy: 0.9320 - categorical_crossentropy: 0.20452020-05-11 01:48:01.269079: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3567s 4s/step - loss: 0.2049 - accuracy: 0.9318 - categorical_crossentropy: 0.2049 - val_loss: 0.1469 - val_accuracy: 0.9435 - val_categorical_crossentropy: 0.1469\n",
      "Epoch 13/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.1866 - accuracy: 0.9400 - categorical_crossentropy: 0.18662020-05-11 02:47:52.032491: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3591s 4s/step - loss: 0.1869 - accuracy: 0.9397 - categorical_crossentropy: 0.1869 - val_loss: 0.1773 - val_accuracy: 0.9435 - val_categorical_crossentropy: 0.1773\n",
      "Epoch 14/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.1610 - accuracy: 0.9479 - categorical_crossentropy: 0.16102020-05-11 03:48:06.250915: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3614s 4s/step - loss: 0.1611 - accuracy: 0.9479 - categorical_crossentropy: 0.1611 - val_loss: 0.1189 - val_accuracy: 0.9712 - val_categorical_crossentropy: 0.1189\n",
      "Epoch 15/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.1677 - accuracy: 0.9484 - categorical_crossentropy: 0.16772020-05-11 04:47:28.696905: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3562s 4s/step - loss: 0.1676 - accuracy: 0.9485 - categorical_crossentropy: 0.1676 - val_loss: 0.0964 - val_accuracy: 0.9724 - val_categorical_crossentropy: 0.0964\n",
      "Epoch 16/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.1549 - accuracy: 0.9506 - categorical_crossentropy: 0.15492020-05-11 05:47:19.619707: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3591s 4s/step - loss: 0.1548 - accuracy: 0.9507 - categorical_crossentropy: 0.1548 - val_loss: 0.0823 - val_accuracy: 0.9748 - val_categorical_crossentropy: 0.0823\n",
      "Epoch 17/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.1475 - accuracy: 0.9541 - categorical_crossentropy: 0.14752020-05-11 06:47:13.432670: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3594s 4s/step - loss: 0.1474 - accuracy: 0.9541 - categorical_crossentropy: 0.1474 - val_loss: 0.1027 - val_accuracy: 0.9675 - val_categorical_crossentropy: 0.1027\n",
      "Epoch 18/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.1506 - accuracy: 0.9527 - categorical_crossentropy: 0.15062020-05-11 07:47:54.615996: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3642s 4s/step - loss: 0.1507 - accuracy: 0.9526 - categorical_crossentropy: 0.1507 - val_loss: 0.0926 - val_accuracy: 0.9724 - val_categorical_crossentropy: 0.0926\n",
      "Epoch 19/1000\n",
      "838/839 [============================>.] - ETA: 4s - loss: 0.1198 - accuracy: 0.9649 - categorical_crossentropy: 0.11982020-05-11 08:48:30.734057: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 3636s 4s/step - loss: 0.1196 - accuracy: 0.9650 - categorical_crossentropy: 0.1196 - val_loss: 0.0618 - val_accuracy: 0.9820 - val_categorical_crossentropy: 0.0618\n",
      "Epoch 20/1000\n",
      "  4/839 [..............................] - ETA: 50:45 - loss: 0.1025 - accuracy: 0.9688 - categorical_crossentropy: 0.1025^C\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--exp=16 \\\n",
    "--size=299 \\\n",
    "--weights=\"checkpoints/exp16/best_weights.ckpt\" \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--class_names_file=\"class_names_62.txt\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000 \\\n",
    "--patience=4 \\\n",
    "--initial_epoch=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-12 09:07:12.327873: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-12 09:07:12.359896: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199905000 Hz\n",
      "2020-05-12 09:07:12.360617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56024fe41780 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-12 09:07:12.360656: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-12 09:07:12.361734: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 839 steps, validate for 104 steps\n",
      "Epoch 20/1000\n",
      "2020-05-12 09:07:29.317032: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "839/839 [==============================] - 2416s 3s/step - loss: 0.1083 - accuracy: 0.9648 - categorical_crossentropy: 0.1083 - val_loss: 0.0605 - val_accuracy: 0.9796 - val_categorical_crossentropy: 0.0605\n",
      "Epoch 21/1000\n",
      "838/839 [============================>.] - ETA: 2s - loss: 0.1045 - accuracy: 0.9666 - categorical_crossentropy: 0.10452020-05-12 10:25:50.758766: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 2394s 3s/step - loss: 0.1046 - accuracy: 0.9665 - categorical_crossentropy: 0.1046 - val_loss: 0.0689 - val_accuracy: 0.9748 - val_categorical_crossentropy: 0.0689\n",
      "Epoch 22/1000\n",
      "838/839 [============================>.] - ETA: 2s - loss: 0.0964 - accuracy: 0.9682 - categorical_crossentropy: 0.09642020-05-12 11:06:17.182369: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 2427s 3s/step - loss: 0.0965 - accuracy: 0.9681 - categorical_crossentropy: 0.0965 - val_loss: 0.0806 - val_accuracy: 0.9748 - val_categorical_crossentropy: 0.0806\n",
      "Epoch 23/1000\n",
      "838/839 [============================>.] - ETA: 2s - loss: 0.0942 - accuracy: 0.9714 - categorical_crossentropy: 0.09422020-05-12 11:45:26.875446: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 2349s 3s/step - loss: 0.0941 - accuracy: 0.9714 - categorical_crossentropy: 0.0941 - val_loss: 0.0602 - val_accuracy: 0.9772 - val_categorical_crossentropy: 0.0602\n",
      "Epoch 24/1000\n",
      "838/839 [============================>.] - ETA: 2s - loss: 0.0987 - accuracy: 0.9682 - categorical_crossentropy: 0.09872020-05-12 12:26:06.220154: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "839/839 [==============================] - 2440s 3s/step - loss: 0.0986 - accuracy: 0.9683 - categorical_crossentropy: 0.0986 - val_loss: 0.0493 - val_accuracy: 0.9820 - val_categorical_crossentropy: 0.0493\n",
      "Epoch 25/1000\n",
      "  6/839 [..............................] - ETA: 41:06 - loss: 0.1782 - accuracy: 0.9583 - categorical_crossentropy: 0.1782^C\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--exp=16 \\\n",
    "--size=299 \\\n",
    "--weights=\"checkpoints/exp16/best_weights.ckpt\" \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--class_names_file=\"class_names_62.txt\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000 \\\n",
    "--patience=4 \\\n",
    "--initial_epoch=19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-14 15:36:01.349210: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-14 15:36:01.383446: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200060000 Hz\n",
      "2020-05-14 15:36:01.384093: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b2e538a320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-14 15:36:01.384119: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-14 15:36:01.384999: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 356 steps, validate for 277 steps\n",
      "Epoch 1/1000\n",
      "2020-05-14 15:36:18.828994: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "356/356 [==============================] - 1847s 5s/step - loss: 3.7956 - accuracy: 0.1099 - categorical_crossentropy: 3.7956 - val_loss: 3.8473 - val_accuracy: 0.1038 - val_categorical_crossentropy: 3.8473\n",
      "Epoch 2/1000\n",
      "355/356 [============================>.] - ETA: 4s - loss: 2.3025 - accuracy: 0.3662 - categorical_crossentropy: 2.30252020-05-14 16:32:08.425304: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "356/356 [==============================] - 1843s 5s/step - loss: 2.3006 - accuracy: 0.3666 - categorical_crossentropy: 2.3006 - val_loss: 3.5258 - val_accuracy: 0.2464 - val_categorical_crossentropy: 3.5258\n",
      "Epoch 3/1000\n",
      "355/356 [============================>.] - ETA: 4s - loss: 1.4278 - accuracy: 0.5831 - categorical_crossentropy: 1.42782020-05-14 17:02:44.046674: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "356/356 [==============================] - 1836s 5s/step - loss: 1.4276 - accuracy: 0.5825 - categorical_crossentropy: 1.4276 - val_loss: 3.4476 - val_accuracy: 0.3421 - val_categorical_crossentropy: 3.4476\n",
      "Epoch 4/1000\n",
      "355/356 [============================>.] - ETA: 4s - loss: 1.0226 - accuracy: 0.6912 - categorical_crossentropy: 1.02262020-05-14 17:33:26.371831: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "356/356 [==============================] - 1845s 5s/step - loss: 1.0226 - accuracy: 0.6910 - categorical_crossentropy: 1.0226 - val_loss: 3.3333 - val_accuracy: 0.3782 - val_categorical_crossentropy: 3.3333\n",
      "Epoch 5/1000\n",
      " 17/356 [>.............................] - ETA: 24:19 - loss: 1.1068 - accuracy: 0.6765 - categorical_crossentropy: 1.1068^C\n"
     ]
    }
   ],
   "source": [
    "# Ripetiamo l'exp 16 col dataset originale (split in base al vestiario).\n",
    "!python train.py \\\n",
    "--exp=17 \\\n",
    "--size=299 \\\n",
    "--weights=imagenet \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--dataset=\"data/casia_gait/DatasetB_split\" \\\n",
    "--class_names_file=\"class_names_62.txt\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000 \\\n",
    "--patience=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-14 23:59:09.103983: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-05-14 23:59:09.127919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200060000 Hz\n",
      "2020-05-14 23:59:09.128252: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ded9cdd360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-14 23:59:09.128281: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-14 23:59:09.128384: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "block1_conv1_bn\n",
      "block1_conv2_bn\n",
      "block2_sepconv1_bn\n",
      "block2_sepconv2_bn\n",
      "batch_normalization\n",
      "block3_sepconv1_bn\n",
      "block3_sepconv2_bn\n",
      "batch_normalization_1\n",
      "block4_sepconv1_bn\n",
      "block4_sepconv2_bn\n",
      "batch_normalization_2\n",
      "block5_sepconv1_bn\n",
      "block5_sepconv2_bn\n",
      "block5_sepconv3_bn\n",
      "block6_sepconv1_bn\n",
      "block6_sepconv2_bn\n",
      "block6_sepconv3_bn\n",
      "block7_sepconv1_bn\n",
      "block7_sepconv2_bn\n",
      "block7_sepconv3_bn\n",
      "block8_sepconv1_bn\n",
      "block8_sepconv2_bn\n",
      "block8_sepconv3_bn\n",
      "block9_sepconv1_bn\n",
      "block9_sepconv2_bn\n",
      "block9_sepconv3_bn\n",
      "block10_sepconv1_bn\n",
      "block10_sepconv2_bn\n",
      "block10_sepconv3_bn\n",
      "block11_sepconv1_bn\n",
      "block11_sepconv2_bn\n",
      "block11_sepconv3_bn\n",
      "block12_sepconv1_bn\n",
      "block12_sepconv2_bn\n",
      "block12_sepconv3_bn\n",
      "block13_sepconv1_bn\n",
      "block13_sepconv2_bn\n",
      "batch_normalization_3\n",
      "block14_sepconv1_bn\n",
      "block14_sepconv2_bn\n",
      "output\n",
      "Train for 356 steps, validate for 277 steps\n",
      "Epoch 5/1000\n",
      "2020-05-14 23:59:26.908350: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "356/356 [==============================] - 1820s 5s/step - loss: 0.7516 - accuracy: 0.7644 - categorical_crossentropy: 0.7516 - val_loss: 3.4429 - val_accuracy: 0.3953 - val_categorical_crossentropy: 3.4429\n",
      "Epoch 6/1000\n",
      "355/356 [============================>.] - ETA: 4s - loss: 0.6295 - accuracy: 0.8039 - categorical_crossentropy: 0.62952020-05-15 00:54:30.996111: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "356/356 [==============================] - 1823s 5s/step - loss: 0.6301 - accuracy: 0.8034 - categorical_crossentropy: 0.6301 - val_loss: 3.1616 - val_accuracy: 0.4463 - val_categorical_crossentropy: 3.1616\n",
      "Epoch 7/1000\n",
      "355/356 [============================>.] - ETA: 4s - loss: 0.5267 - accuracy: 0.8352 - categorical_crossentropy: 0.52672020-05-15 01:24:46.112676: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "356/356 [==============================] - 1815s 5s/step - loss: 0.5266 - accuracy: 0.8353 - categorical_crossentropy: 0.5266 - val_loss: 3.2110 - val_accuracy: 0.4296 - val_categorical_crossentropy: 3.2110\n",
      "Epoch 8/1000\n",
      "355/356 [============================>.] - ETA: 4s - loss: 0.4530 - accuracy: 0.8683 - categorical_crossentropy: 0.45302020-05-15 01:55:05.237373: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "356/356 [==============================] - 1820s 5s/step - loss: 0.4540 - accuracy: 0.8676 - categorical_crossentropy: 0.4540 - val_loss: 3.8408 - val_accuracy: 0.4206 - val_categorical_crossentropy: 3.8408\n",
      "Epoch 9/1000\n",
      "355/356 [============================>.] - ETA: 4s - loss: 0.4169 - accuracy: 0.8771 - categorical_crossentropy: 0.41692020-05-15 02:25:30.902996: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "356/356 [==============================] - 1825s 5s/step - loss: 0.4162 - accuracy: 0.8775 - categorical_crossentropy: 0.4162 - val_loss: 3.7634 - val_accuracy: 0.4436 - val_categorical_crossentropy: 3.7634\n",
      "Epoch 10/1000\n",
      "355/356 [============================>.] - ETA: 4s - loss: 0.3334 - accuracy: 0.8958 - categorical_crossentropy: 0.33342020-05-15 02:56:10.980594: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "356/356 [==============================] - 1839s 5s/step - loss: 0.3331 - accuracy: 0.8961 - categorical_crossentropy: 0.3331 - val_loss: 4.0693 - val_accuracy: 0.4287 - val_categorical_crossentropy: 4.0693\n",
      "2020-05-15 03:01:34.012110: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-15 03:01:34.012679: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2020-05-15 03:01:34.565101: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-15 03:01:34.604902: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-15 03:01:34.637332: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-15 03:01:34.670098: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-15 03:01:34.744719: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-15 03:01:34.770831: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2020-05-15 03:01:34.794941: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--exp=17 \\\n",
    "--size=299 \\\n",
    "--weights=\"checkpoints/exp17/best_weights.ckpt\" \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--dataset=\"data/casia_gait/DatasetB_split\" \\\n",
    "--class_names_file=\"class_names_62.txt\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000 \\\n",
    "--patience=4 \\\n",
    "--initial_epoch=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runnato da terminale perché su Jupyter non viene mostrata la confusion matrix.\n",
    "!python classification_report.py \\\n",
    "--size=299 \\\n",
    "--weights=\"checkpoints/exp16/best_weights.ckpt\" \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--class_names_file=\"class_names_62.txt\" \\\n",
    "--batch_size=32 \\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
