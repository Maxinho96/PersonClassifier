{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-25 17:36:01.755840: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-04-25 17:36:01.784323: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200115000 Hz\n",
      "2020-04-25 17:36:01.784554: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563dcceff6e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-25 17:36:01.784570: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-25 17:36:01.784651: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "output\n",
      "Train for 2058 steps, validate for 50 steps\n",
      "Epoch 1/1000\n",
      "2020-04-25 17:36:12.309460: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "2058/2058 [==============================] - 445s 216ms/step - loss: 1.0217 - accuracy: 0.4854 - val_loss: 1.3749 - val_accuracy: 0.2975\n",
      "Epoch 2/1000\n",
      "2057/2058 [============================>.] - ETA: 0s - loss: 0.9870 - accuracy: 0.51802020-04-25 17:50:34.203752: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2058/2058 [==============================] - 433s 211ms/step - loss: 0.9871 - accuracy: 0.5179 - val_loss: 1.6647 - val_accuracy: 0.3275\n",
      "2020-04-25 17:50:43.507291: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--exp=1 \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-25 19:36:57.387534: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-04-25 19:36:57.428322: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200115000 Hz\n",
      "2020-04-25 19:36:57.429003: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556404ca9470 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-25 19:36:57.429037: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-25 19:36:57.430443: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "output\n",
      "Train for 2058 steps, validate for 50 steps\n",
      "Epoch 1/1000\n",
      "2020-04-25 19:37:15.984907: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Filling up shuffle buffer (this may take a while): 647 of 1000\n",
      "2020-04-25 19:37:21.086310: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:199] Shuffle buffer filled.\n",
      "2020-04-25 19:37:22.344284: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "2058/2058 [==============================] - 2098s 1s/step - loss: 0.7389 - accuracy: 0.6713 - val_loss: 1.8582 - val_accuracy: 0.3200\n",
      "Epoch 2/1000\n",
      "2057/2058 [============================>.] - ETA: 1s - loss: 0.6102 - accuracy: 0.74202020-04-25 20:50:06.777417: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2058/2058 [==============================] - 2332s 1s/step - loss: 0.6100 - accuracy: 0.7422 - val_loss: 2.3580 - val_accuracy: 0.3175\n",
      "2020-04-25 20:50:54.054929: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--exp=2 \\\n",
    "--size=299 \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-26 08:55:19.785245: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-04-26 08:55:19.808404: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200070000 Hz\n",
      "2020-04-26 08:55:19.808683: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dabd9c8e10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-26 08:55:19.808706: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-26 08:55:19.808801: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Trainable layers:\n",
      "output\n",
      "Train for 102 steps, validate for 32 steps\n",
      "Epoch 1/1000\n",
      "2020-04-26 08:55:30.654614: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      " 30/102 [=======>......................] - ETA: 36s - loss: 1.1217 - accuracy: 0.3000 - categorical_crossentropy: 1.1217^C\n",
      " 31/102 [========>.....................] - ETA: 35s - loss: 1.1217 - accuracy: 0.3000 - categorical_crossentropy: 1.1217WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "W0426 08:55:39.021569 139796066404160 callbacks.py:1018] Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,categorical_crossentropy\n",
      "W0426 08:55:39.021796 139796066404160 callbacks.py:1286] Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,categorical_crossentropy\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 112, in <module>\n",
      "    app.run(main)\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"train.py\", line 108, in main\n",
      "    validation_steps=val_length // 20 // FLAGS.batch_size)\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 342, in fit\n",
      "    total_epochs=epochs)\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 128, in run_one_epoch\n",
      "    batch_outs = execution_function(iterator)\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 98, in execution_function\n",
      "    distributed_function(input_fn))\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 599, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2363, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1611, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1692, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 545, in call\n",
      "    ctx=ctx)\n",
      "  File \"/home/max/anaconda3/envs/personclassifier/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--exp=3 \\\n",
    "--size=299 \\\n",
    "--trainable_layers=1 \\\n",
    "--optimizer=\"nadam\" \\\n",
    "--batch_size=8 \\\n",
    "--epochs=1000 \\\n",
    "--cache_train=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
